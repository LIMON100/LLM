{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T10:53:16.853577Z","iopub.status.busy":"2024-06-28T10:53:16.853120Z","iopub.status.idle":"2024-06-28T10:53:17.229502Z","shell.execute_reply":"2024-06-28T10:53:17.228172Z","shell.execute_reply.started":"2024-06-28T10:53:16.853537Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ce00908580a74c77b84c80fbf510da6a","version_major":2,"version_minor":0},"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"]},"metadata":{},"output_type":"display_data"}],"source":["from huggingface_hub import notebook_login\n","notebook_login()"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T09:28:48.202678Z","iopub.status.busy":"2024-06-28T09:28:48.202328Z","iopub.status.idle":"2024-06-28T09:29:18.624713Z","shell.execute_reply":"2024-06-28T09:29:18.623503Z","shell.execute_reply.started":"2024-06-28T09:28:48.202635Z"},"trusted":true},"outputs":[],"source":["!pip install transformers bitsandbytes sentencepiece accelerate guidance --upgrade -qq"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T09:29:18.628080Z","iopub.status.busy":"2024-06-28T09:29:18.627204Z","iopub.status.idle":"2024-06-28T09:30:57.022546Z","shell.execute_reply":"2024-06-28T09:30:57.021601Z","shell.execute_reply.started":"2024-06-28T09:29:18.628036Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.31.0)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\n","Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.23.2)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12.1)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.31.0)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\n","Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.23.2)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12.1)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Collecting groq\n","  Downloading groq-0.9.0-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from groq) (4.2.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from groq) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from groq) (0.27.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from groq) (2.5.3)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from groq) (1.3.0)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from groq) (4.9.0)\n","Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq) (3.6)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq) (1.2.0)\n","Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq) (2024.2.2)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq) (1.0.5)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq) (2.14.6)\n","Downloading groq-0.9.0-py3-none-any.whl (103 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m0m\n","\u001b[?25hInstalling collected packages: groq\n","Successfully installed groq-0.9.0\n","Collecting bert_score\n","  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.1.2)\n","Requirement already satisfied: pandas>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.2.1)\n","Requirement already satisfied: transformers>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from bert_score) (4.42.2)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bert_score) (1.26.4)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.32.3)\n","Requirement already satisfied: tqdm>=4.31.1 in /opt/conda/lib/python3.10/site-packages (from bert_score) (4.66.4)\n","Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert_score) (3.7.5)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from bert_score) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->bert_score) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2023.4)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.13.1)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (1.12.1)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (2024.3.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (2023.12.25)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.4.3)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.19.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (4.47.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (9.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (2024.2.2)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.3)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\n","Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m919.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m--:--\u001b[0m\n","\u001b[?25hInstalling collected packages: bert_score\n","Successfully installed bert_score-0.3.13\n"]}],"source":["!pip install --upgrade transformers -qq\n","!pip install accelerate\n","!pip install -q -U google-generativeai\n","!pip install --upgrade transformers -qq\n","!pip install accelerate\n","!pip install groq\n","!pip install bert_score"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T09:30:57.024167Z","iopub.status.busy":"2024-06-28T09:30:57.023901Z","iopub.status.idle":"2024-06-28T09:31:01.293536Z","shell.execute_reply":"2024-06-28T09:31:01.292698Z","shell.execute_reply.started":"2024-06-28T09:30:57.024142Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["--2024-06-28 09:30:57--  https://people.eecs.berkeley.edu/~hendrycks/data.tar\n","Resolving people.eecs.berkeley.edu (people.eecs.berkeley.edu)... 128.32.244.190\n","Connecting to people.eecs.berkeley.edu (people.eecs.berkeley.edu)|128.32.244.190|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 166184960 (158M) [application/x-tar]\n","Saving to: 'data.tar'\n","\n","data.tar            100%[===================>] 158.49M  53.5MB/s    in 3.0s    \n","\n","2024-06-28 09:31:01 (53.5 MB/s) - 'data.tar' saved [166184960/166184960]\n","\n"]}],"source":["!wget -nc https://people.eecs.berkeley.edu/~hendrycks/data.tar"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T09:31:01.296124Z","iopub.status.busy":"2024-06-28T09:31:01.295815Z","iopub.status.idle":"2024-06-28T09:31:01.300222Z","shell.execute_reply":"2024-06-28T09:31:01.299390Z","shell.execute_reply.started":"2024-06-28T09:31:01.296096Z"},"trusted":true},"outputs":[],"source":["# import tarfile\n","# unzip_path = '.'\n","# tar = tarfile.open('data.tar')\n","# tar.extractall(path=unzip_path)\n","# tar.close()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T09:31:01.302203Z","iopub.status.busy":"2024-06-28T09:31:01.301484Z","iopub.status.idle":"2024-06-28T09:31:06.605272Z","shell.execute_reply":"2024-06-28T09:31:06.604323Z","shell.execute_reply.started":"2024-06-28T09:31:01.302171Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","df_reasoning = pd.read_parquet(\"hf://datasets/livebench/reasoning/data/test-00000-of-00001.parquet\")\n","df_math = pd.read_parquet(\"hf://datasets/livebench/math/data/test-00000-of-00001.parquet\")\n","df_coding = pd.read_parquet(\"hf://datasets/livebench/coding/data/test-00000-of-00001.parquet\")\n","df_language = pd.read_parquet(\"hf://datasets/livebench/language/data/test-00000-of-00001.parquet\")\n","df_data_analysis = pd.read_parquet(\"hf://datasets/livebench/data_analysis/data/test-00000-of-00001.parquet\")\n","# df_instruction = pd.read_parquet(\"hf://datasets/livebench/instruction_following/data/test-00000-of-00001.parquet\")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T09:31:06.607666Z","iopub.status.busy":"2024-06-28T09:31:06.606731Z","iopub.status.idle":"2024-06-28T09:31:14.069890Z","shell.execute_reply":"2024-06-28T09:31:14.069114Z","shell.execute_reply.started":"2024-06-28T09:31:06.607608Z"},"trusted":true},"outputs":[],"source":["df_reasoning.to_csv('reasoning_dev.csv', index=False)\n","df_math.to_csv('math_dev.csv', index=False)\n","df_language.to_csv('language_dev.csv', index=False)\n","df_data_analysis.to_csv('data_analysis_dev.csv', index=False)\n","df_coding.to_csv('coding_dev.csv', index=False)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T09:31:14.071214Z","iopub.status.busy":"2024-06-28T09:31:14.070932Z","iopub.status.idle":"2024-06-28T09:31:14.076378Z","shell.execute_reply":"2024-06-28T09:31:14.075456Z","shell.execute_reply.started":"2024-06-28T09:31:14.071190Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(100, 5)\n","(232, 9)\n","(88, 13)\n","(140, 10)\n","(150, 5)\n"]}],"source":["print(df_reasoning.shape)\n","print(df_math.shape)\n","print(df_coding.shape)\n","print(df_language.shape)\n","print(df_data_analysis.shape)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T09:31:14.078107Z","iopub.status.busy":"2024-06-28T09:31:14.077793Z","iopub.status.idle":"2024-06-28T09:31:14.084445Z","shell.execute_reply":"2024-06-28T09:31:14.083701Z","shell.execute_reply.started":"2024-06-28T09:31:14.078077Z"},"trusted":true},"outputs":[],"source":["import os\n","\n","dev_folder_path = '/kaggle/working/dev'\n","os.makedirs(dev_folder_path, exist_ok=True)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T09:31:14.086306Z","iopub.status.busy":"2024-06-28T09:31:14.085727Z","iopub.status.idle":"2024-06-28T09:31:14.093914Z","shell.execute_reply":"2024-06-28T09:31:14.093029Z","shell.execute_reply.started":"2024-06-28T09:31:14.086280Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Moved 'data_analysis_dev.csv' to '/kaggle/working/dev'\n","Moved 'language_dev.csv' to '/kaggle/working/dev'\n","Moved 'coding_dev.csv' to '/kaggle/working/dev'\n","Moved 'math_dev.csv' to '/kaggle/working/dev'\n","Moved 'reasoning_dev.csv' to '/kaggle/working/dev'\n"]}],"source":["import os\n","import shutil\n","\n","source_folder = '/kaggle/working/'\n","destination_folder = '/kaggle/working/dev'\n","\n","files = os.listdir(source_folder)\n","csv_files = [file for file in files if file.endswith('.csv')]\n","\n","for file in csv_files:\n","    source_file_path = os.path.join(source_folder, file)\n","    destination_file_path = os.path.join(destination_folder, file)\n","    shutil.move(source_file_path, destination_file_path)\n","    print(f\"Moved '{file}' to '{destination_folder}'\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T09:31:14.097252Z","iopub.status.busy":"2024-06-28T09:31:14.096990Z","iopub.status.idle":"2024-06-28T09:31:29.468552Z","shell.execute_reply":"2024-06-28T09:31:29.467788Z","shell.execute_reply.started":"2024-06-28T09:31:14.097230Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-06-28 09:31:18.954207: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-06-28 09:31:18.954328: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-06-28 09:31:19.068744: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["import torch\n","import numpy as np\n","from sklearn.isotonic import IsotonicRegression\n","from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification, pipeline\n","from transformers import BitsAndBytesConfig\n","import torch.nn.functional as F\n","from transformers import pipeline\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pathlib\n","import textwrap\n","import google.generativeai as genai\n","from IPython.display import display\n","from IPython.display import Markdown\n","import google.generativeai as genai\n","from bert_score import score\n","import os\n","from groq import Groq\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","\n","import json\n","import re\n","import concurrent.futures\n","from tqdm import tqdm\n","from yaml import safe_load\n","from nltk.metrics import edit_distance"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T09:31:29.470737Z","iopub.status.busy":"2024-06-28T09:31:29.469813Z","iopub.status.idle":"2024-06-28T09:31:29.633165Z","shell.execute_reply":"2024-06-28T09:31:29.632299Z","shell.execute_reply.started":"2024-06-28T09:31:29.470697Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["import pathlib\n","import textwrap\n","import google.generativeai as genai\n","from IPython.display import display\n","from IPython.display import Markdown\n","import google.generativeai as genai\n","import os\n","import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","\n","\n","def to_markdown(text):\n","  text = text.replace('•', '  *')\n","  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n","\n","\n","os.environ['GOOGLE_API_KEY']=\"\"\n","genai.configure(api_key=os.environ['GOOGLE_API_KEY'])"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T09:31:29.634505Z","iopub.status.busy":"2024-06-28T09:31:29.634236Z","iopub.status.idle":"2024-06-28T09:31:29.642509Z","shell.execute_reply":"2024-06-28T09:31:29.641595Z","shell.execute_reply.started":"2024-06-28T09:31:29.634481Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["nltk.download('punkt')\n","nltk.download('stopwords')\n","stop_words = set(stopwords.words('english'))"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T09:31:29.644172Z","iopub.status.busy":"2024-06-28T09:31:29.643755Z","iopub.status.idle":"2024-06-28T09:31:29.649558Z","shell.execute_reply":"2024-06-28T09:31:29.648626Z","shell.execute_reply.started":"2024-06-28T09:31:29.644141Z"},"trusted":true},"outputs":[],"source":["def preprocess_text(text):\n","    tokens = word_tokenize(text.lower())\n","    stop_words = set(stopwords.words('english'))\n","    filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n","    return ' '.join(filtered_tokens)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T09:31:29.651726Z","iopub.status.busy":"2024-06-28T09:31:29.650891Z","iopub.status.idle":"2024-06-28T09:31:31.913672Z","shell.execute_reply":"2024-06-28T09:31:31.912597Z","shell.execute_reply.started":"2024-06-28T09:31:29.651689Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["What a profound and timely set of questions!\n","\n","**What is the meaning of life?**\n","\n","The meaning of life is a question that has puzzled philosophers, theologians, scientists, and everyday people for centuries. There is no one definitive answer, as it is a subjective and personal query that can vary greatly from individual to individual. Here are a few perspectives:\n","\n","1. **Biological perspective**: From a biological standpoint, the meaning of life might be to survive and reproduce, ensuring the continuation of our species.\n","2. **Philosophical perspective**: Philosophers have proposed various answers, such as:\n","\t* **Hedonism**: The pursuit of pleasure and happiness is the primary goal of life.\n","\t* **Eudaimonia**: Living a virtuous, fulfilling life, cultivating one's strengths and talents, is the key to a meaningful existence.\n","\t* **Existentialism**: Life has no inherent meaning, and we must create our own purpose and significance.\n","3. **Religious perspective**: Religious beliefs often provide a framework for understanding the meaning of life, such as:\n","\t* **Christianity**: Life's purpose is to love and serve God, and to achieve salvation.\n","\t* **Buddhism**: The goal of life is to attain enlightenment, or Nirvana, through the Eightfold Path.\n","4. **Personal perspective**: Ultimately, the meaning of life is a highly personal and subjective question, influenced by individual experiences, values, and beliefs. It may involve finding purpose, happiness, or fulfillment through relationships, personal growth, or contributions to society.\n","\n","**How modern AI is affecting real life**\n","\n","Artificial Intelligence (AI) is transforming various aspects of our lives, with both positive and negative consequences:\n","\n","1. **Automation and job displacement**: AI-powered automation is replacing certain jobs, particularly those that involve repetitive tasks, potentially leading to unemployment and social unrest.\n","2. **Enhanced productivity and efficiency**: AI is streamlining processes, increasing accuracy, and freeing up time for more creative and strategic tasks.\n","3. **Improved healthcare and medicine**: AI is helping to analyze medical data, diagnose diseases, and develop personalized treatment plans.\n","4. **Personalized experiences**: AI-driven recommendation systems are influencing our online experiences, from shopping to entertainment, often blurring the lines between personalization and surveillance.\n","5. **Cybersecurity concerns**: As AI becomes more prevalent, it also introduces new risks, such as AI-powered cyber attacks and AI-generated deep fakes.\n","\n","**AI outcomes in the future**\n","\n","As AI continues to evolve, we can expect:\n","\n","1. **Increased adoption in various industries**: AI will become more pervasive in sectors like education, finance, transportation, and energy.\n","2. **Job market shift**: While AI may displace some jobs, it will also create new ones, such as AI ethicist, AI trainer, and AI researcher.\n","3. **AI-human collaboration**: AI will augment human capabilities, enabling us to tackle complex problems and make more informed decisions.\n","4. **Ethical considerations**: The development of AI will raise important ethical questions, such as accountability, transparency, and bias in decision-making systems.\n","5. **Potential risks and challenges**: AI could exacerbate existing social inequalities, create unintended consequences, or even pose an existential risk if not developed and managed responsibly.\n","\n","In conclusion, the meaning of life is a deeply personal and philosophical question, while AI is undoubtedly transforming our world. As we move forward, it's essential to consider the implications of AI on our lives, ensuring that its development and deployment align with our values and promote the well-being of humanity.\n"]}],"source":["client = Groq(api_key=\"\")\n","\n","chat_completion = client.chat.completions.create(\n","    messages=[\n","        {\n","            \"role\": \"user\",\n","            \"content\": \"What is the meaning of life? How modern Ai is affeting the real life and what will be the Ai outcomes in future?\",\n","        }\n","\n","    ],\n","    model=\"llama3-70b-8192\",\n",")\n"," \n","print(chat_completion.choices[0].message.content)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T09:31:31.916154Z","iopub.status.busy":"2024-06-28T09:31:31.915538Z","iopub.status.idle":"2024-06-28T09:31:31.920413Z","shell.execute_reply":"2024-06-28T09:31:31.919305Z","shell.execute_reply.started":"2024-06-28T09:31:31.916125Z"},"trusted":true},"outputs":[],"source":["gemini_model = genai.GenerativeModel('gemini-pro')"]},{"cell_type":"markdown","metadata":{},"source":["### Pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class EvaluationPipeline:\n","    def __init__(self, api_key, judge_model, regex_pattern, temperature=0.8, max_tokens=300, pairwise=True):\n","        self.api_key = api_key\n","        self.judge_model = judge_model\n","        self.regex_pattern = re.compile(regex_pattern)\n","        self.temperature = temperature\n","        self.max_tokens = max_tokens\n","        self.pairwise = pairwise\n","        self.prompts = []\n","        self.responses = []\n","        self.references = []\n","        self.confidences = []\n","        self.accuracies = []\n","\n","    def get_mistral_answer(self, prompt, include_stopwords=True):\n","        inputs = tokenizer_mistral.encode_plus(\n","            prompt, return_tensors='pt', max_length=1024, truncation=True, padding='max_length'\n","        ).to(mistral_model.device)\n","\n","        outputs = mistral_model.generate(\n","            inputs['input_ids'], attention_mask=inputs['attention_mask'],\n","            max_new_tokens=300, num_return_sequences=1, temperature=0.8,\n","            do_sample=True, output_scores=True, return_dict_in_generate=True\n","        )\n","\n","        response_ids = outputs.sequences[0]\n","        response_text = tokenizer_mistral.decode(response_ids, skip_special_tokens=True)\n","\n","        logits = outputs.scores  # Logits of the generated tokens\n","        softmax_probs = torch.softmax(torch.stack(logits), dim=-1)\n","\n","        tokens = tokenizer_mistral.convert_ids_to_tokens(response_ids)\n","        if include_stopwords:\n","            token_confidences = [prob.max().item() for prob in softmax_probs]\n","        else:\n","            token_confidences = [prob.max().item() for prob, token in zip(softmax_probs, tokens) if token.lower() not in stop_words]\n","\n","        mean_confidence = np.mean(token_confidences)\n","\n","        return response_text, mean_confidence\n","\n","    def judge_answer(self, response, prompt):\n","        chat_completion = client.chat.completions.create(\n","            messages=[\n","                {\n","                    \"role\": \"user\",\n","                    \"content\": f\"\"\"\n","                        Review the user’s question and the corresponding response using the binary scoring system described below.\n","                        - 0 points: The response is incorrect or does not address the user’s question.\n","                        - 1 point: The response is correct and addresses the user’s question.\n","\n","                        User: {prompt}\n","                        Response: {response}\n","                        \"\"\"\n","                }\n","            ],\n","            model=\"llama3-70b-8192\",\n","        )\n","\n","        llama3_response = chat_completion.choices[0].message.content.strip()\n","        return llama3_response\n","\n","    def parse_evaluation(self, evaluation):\n","        if \"1 point\" in evaluation:\n","            return 1\n","        return 0\n","\n","    def generate_reference_text(self, prompt):\n","        inputs = tokenizer_mistral.encode_plus(\n","            prompt, return_tensors='pt', max_length=1024, truncation=True, padding='max_length'\n","        ).to(mistral_model.device)\n","\n","        outputs = mistral_model.generate(\n","            inputs['input_ids'], attention_mask=inputs['attention_mask'],\n","            max_new_tokens=300, num_return_sequences=1, temperature=0.8, do_sample=True\n","        )\n","\n","        reference_text = tokenizer_mistral.decode(outputs[0], skip_special_tokens=True)\n","        return reference_text\n","\n","    def calculate_bertscore(self, references, candidates):\n","        P, R, F1 = score(candidates, references, lang=\"en\", model_type=\"bert-base-uncased\")\n","        return P.mean().item(), R.mean().item(), F1.mean().item()\n","\n","    def evaluate(self, prompts):\n","        self.prompts = prompts  # Ensure prompts are stored\n","        for prompt in prompts:\n","            response, confidence = self.get_mistral_answer(prompt)\n","            self.responses.append(response)\n","            self.confidences.append(confidence)\n","            reference_text = self.generate_reference_text(prompt)\n","            self.references.append(reference_text)\n","            judgement = self.judge_answer(response, prompt)\n","            accuracy = self.parse_evaluation(judgement)\n","            self.accuracies.append(accuracy)\n","\n","        precision, recall, f1 = self.calculate_bertscore(self.references, self.responses)\n","        print(f\"BERTScore - Precision: {precision}, Recall: {recall}, F1: {f1}\")\n","\n","    def calculate_ece(self):\n","        # Ensure all lists have the same length\n","        if len(self.prompts) == len(self.responses) == len(self.confidences) == len(self.accuracies):\n","            data = pd.DataFrame({\n","                'prompt': self.prompts,\n","                'response': self.responses,\n","                'confidence': self.confidences,\n","                'rating': self.accuracies\n","            })\n","        else:\n","            raise ValueError(\"All arrays must be of the same length\")\n","\n","        # Normalize confidence scores\n","        data['confidence_normalized'] = data['confidence'] / data['confidence'].max()\n","\n","        # Bin the normalized confidence scores\n","        bins = np.linspace(0, 1, 11)\n","        data['bin'] = pd.cut(data['confidence_normalized'], bins=bins, labels=False, include_lowest=True)\n","\n","        # Calculate accuracy for each bin\n","        bin_accuracies = data.groupby('bin')['rating'].mean()\n","        bin_proportions = data['bin'].value_counts(normalize=True)\n","\n","        # Drop bins with NaN values\n","        valid_bins = bin_accuracies.dropna().index\n","        bin_accuracies = bin_accuracies[valid_bins]\n","        bin_proportions = bin_proportions[valid_bins]\n","        bin_confidences = (bins[:-1] + bins[1:]) / 2\n","        bin_confidences = bin_confidences[valid_bins]\n","\n","        # Ensure lengths match\n","        bin_confidences = bin_confidences[:len(bin_accuracies)]\n","\n","        # Compute ECE\n","        ece = np.sum(np.abs(bin_accuracies - bin_confidences) * bin_proportions)\n","        print(f\"Expected Calibration Error (ECE): {ece}\")\n","\n","        return data, bins, bin_accuracies\n","\n","    def plot_reliability_diagram(self, bins, bin_accuracies):\n","        plt.figure(figsize=(10, 6))\n","        plt.plot((bins[:-1] + bins[1:]) / 2, bin_accuracies, marker='o', label='Accuracy per bin')\n","        plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfect calibration')\n","        plt.xlabel('Confidence')\n","        plt.ylabel('Accuracy')\n","        plt.title('Reliability Diagram')\n","        plt.legend()\n","        plt.grid(True)\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["pipeline = EvaluationPipeline(api_key=\"Your_api_key\", judge_model=\"llama3-70b-8192\", regex_pattern=r\"(correct|incorrect)\")\n","prompts = [\"What is nuclear fusion?\", \"Tell me about the current AI situation in the world?\", \"How does a combustion engine work?\"]\n","pipeline.evaluate(prompts)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data, bins, bin_accuracies = pipeline.calculate_ece()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["few_shot_examples = \"\"\"\n","Q: What is nuclear fusion?\n","A: Nuclear fusion is a reaction in which two atomic nuclei combine to form a heavier nucleus, releasing energy in the process.\n","\n","Q: How does a combustion engine work?\n","A: A combustion engine works by burning fuel in a combustion chamber to produce mechanical energy that drives the engine.\n","\"\"\"\n","\n","def get_mistral_answer_few_shot(prompt):\n","    few_shot_prompt = few_shot_examples + f\"\\nQ: {prompt}\\nA:\"\n","    response, confidence = get_mistral_answer(few_shot_prompt)\n","    return response, confidence\n","\n","# Example usage:\n","few_shot_response, few_shot_confidence = get_mistral_answer_few_shot(\"Tell me about the current AI situation in the world.\")\n","print(f\"Few-shot response: {few_shot_response}\")\n","print(f\"Few-shot confidence: {few_shot_confidence}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["### Class pipeline for mmlu dataset"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T08:12:56.503553Z","iopub.status.busy":"2024-06-13T08:12:56.502458Z","iopub.status.idle":"2024-06-13T08:12:56.509797Z","shell.execute_reply":"2024-06-13T08:12:56.508765Z","shell.execute_reply.started":"2024-06-13T08:12:56.503510Z"},"trusted":true},"outputs":[],"source":["class Tokenizer:\n","    def __init__(self, model_name):\n","        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n","        self.tokenizer.pad_token = self.tokenizer.eos_token\n","\n","    def encode(self, text, max_length=1024):\n","        return self.tokenizer.encode_plus(text, return_tensors='pt', max_length=max_length, truncation=True)\n","\n","    def decode(self, tokens):\n","        return self.tokenizer.decode(tokens, skip_special_tokens=True)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T08:07:10.112626Z","iopub.status.busy":"2024-06-12T08:07:10.112179Z","iopub.status.idle":"2024-06-12T08:07:10.159604Z","shell.execute_reply":"2024-06-12T08:07:10.158497Z","shell.execute_reply.started":"2024-06-12T08:07:10.112590Z"},"trusted":true},"outputs":[],"source":["  class EvaluationPipeline:\n","    def __init__(self, api_key, judge_model_name, smaller_model_name, temperature=0.8, max_tokens=300):\n","        self.api_key = api_key\n","        self.judge_model_name = judge_model_name\n","        self.temperature = temperature\n","        self.max_tokens = max_tokens\n","\n","\n","        self.tokenizer = Tokenizer(smaller_model_name)\n","        \n","        bnb_config = BitsAndBytesConfig(\n","            load_in_4bit=True,\n","            bnb_4bit_quant_type=\"nf4\",\n","            bnb_4bit_compute_dtype=torch.float16\n","        )\n","\n","        self.main_model = AutoModelForCausalLM.from_pretrained(\n","            smaller_model_name,\n","            torch_dtype=torch.float16,\n","            quantization_config=bnb_config,\n","            low_cpu_mem_usage=True,\n","            device_map=\"auto\",\n","        )\n","\n","        self.categories = {\n","            \"abstract_algebra\": [\"math\"],\n","            \"anatomy\": [\"health\"],\n","            \"astronomy\": [\"physics\"],\n","            \"business_ethics\": [\"business\"],\n","            \"clinical_knowledge\": [\"health\"],\n","            \"college_biology\": [\"biology\"],\n","            \"college_chemistry\": [\"chemistry\"],\n","            \"college_computer_science\": [\"computer science\"],\n","            \"college_mathematics\": [\"math\"],\n","            \"college_medicine\": [\"health\"],\n","            \"college_physics\": [\"physics\"],\n","            \"computer_security\": [\"computer science\"],\n","            \"conceptual_physics\": [\"physics\"],\n","            \"econometrics\": [\"economics\"],\n","            \"electrical_engineering\": [\"engineering\"],\n","            \"elementary_mathematics\": [\"math\"],\n","            \"formal_logic\": [\"philosophy\"],\n","            \"global_facts\": [\"other\"],\n","            \"high_school_biology\": [\"biology\"],\n","            \"high_school_chemistry\": [\"chemistry\"],\n","            \"high_school_computer_science\": [\"computer science\"],\n","            \"high_school_european_history\": [\"history\"],\n","            \"high_school_geography\": [\"geography\"],\n","            \"high_school_government_and_politics\": [\"politics\"],\n","            \"high_school_macroeconomics\": [\"economics\"],\n","            \"high_school_mathematics\": [\"math\"],\n","            \"high_school_microeconomics\": [\"economics\"],\n","            \"high_school_physics\": [\"physics\"],\n","            \"high_school_psychology\": [\"psychology\"],\n","            \"high_school_statistics\": [\"math\"],\n","            \"high_school_us_history\": [\"history\"],\n","            \"high_school_world_history\": [\"history\"],\n","            \"human_aging\": [\"health\"],\n","            \"human_sexuality\": [\"culture\"],\n","            \"international_law\": [\"law\"],\n","            \"jurisprudence\": [\"law\"],\n","            \"logical_fallacies\": [\"philosophy\"],\n","            \"machine_learning\": [\"computer science\"],\n","            \"management\": [\"business\"],\n","            \"marketing\": [\"business\"],\n","            \"medical_genetics\": [\"health\"],\n","            \"miscellaneous\": [\"other\"],\n","            \"moral_disputes\": [\"philosophy\"],\n","            \"moral_scenarios\": [\"philosophy\"],\n","            \"nutrition\": [\"health\"],\n","            \"philosophy\": [\"philosophy\"],\n","            \"prehistory\": [\"history\"],\n","            \"professional_accounting\": [\"other\"],\n","            \"professional_law\": [\"law\"],\n","            \"professional_medicine\": [\"health\"],\n","            \"professional_psychology\": [\"psychology\"],\n","            \"public_relations\": [\"politics\"],\n","            \"security_studies\": [\"politics\"],\n","            \"sociology\": [\"culture\"],\n","            \"us_foreign_policy\": [\"politics\"],\n","            \"virology\": [\"health\"],\n","            \"world_religions\": [\"philosophy\"],\n","        }\n","\n","    def get_model_answer(self, prompt):\n","        \"\"\"Generates an answer from the specified model.\"\"\"\n","        inputs = self.tokenizer.encode(prompt).to(self.main_model.device)\n","        outputs = self.main_model.generate(\n","            inputs['input_ids'], \n","            max_new_tokens=300,  # Limit the number of generated tokens\n","            num_return_sequences=1, \n","            temperature=self.temperature, \n","            output_scores=True, \n","            return_dict_in_generate=True\n","        )\n","        response = self.tokenizer.decode(outputs.sequences[0])\n","\n","        # Get the confidence score\n","        logits = torch.stack(outputs.scores, dim=1)\n","        probs = F.softmax(logits, dim=-1)\n","\n","        token_ids = outputs.sequences[:, inputs['input_ids'].shape[1]:]\n","        confidences = probs.gather(2, token_ids.unsqueeze(-1)).squeeze(-1).mean(dim=1).detach().cpu().numpy()\n","\n","        avg_confidence = confidences[0]\n","        return response, avg_confidence\n","\n","    def judge_answer(self, response, prompt):\n","        chat_completion = client.chat.completions.create(\n","            messages=[\n","                {\n","                    \"role\": \"user\",\n","                    \"content\": f\"\"\"\n","                        Review the user’s question and the corresponding response using the binary scoring system described below.\n","                        - 0 points: The response is incorrect or does not address the user’s question.\n","                        - 1 point: The response is correct and addresses the user’s question.\n","\n","                        User: {prompt}\n","                        Response: {response}\n","                        \"\"\"\n","                }\n","            ],\n","            model=self.judge_model_name,\n","        )\n","\n","        judge_response = chat_completion.choices[0].message.content.strip()\n","        return judge_response\n","\n","    def parse_evaluation(self, evaluation):\n","        return 1 if \"1 point\" in evaluation else 0\n","\n","    def generate_reference_text(self, prompt):\n","        inputs = self.tokenizer.encode(prompt).to(self.main_model.device)\n","        outputs = self.main_model.generate(\n","            inputs['input_ids'], \n","            attention_mask=inputs['attention_mask'],\n","            max_new_tokens=self.max_tokens, \n","            num_return_sequences=1, \n","            temperature=self.temperature, \n","            do_sample=True\n","        )\n","        reference_text = self.tokenizer.decode(outputs[0])\n","        return reference_text\n","\n","    def calculate_bertscore(self, references, candidates):\n","        P, R, F1 = score(candidates, references, lang=\"en\", model_type=\"bert-base-uncased\")\n","        return P.mean().item(), R.mean().item(), F1.mean().item()\n","\n","    def evaluate_from_csv(self, csv_file_path):\n","        # Clear data before processing each file\n","        self.prompts = []\n","        self.responses = []\n","        self.references = []\n","        self.confidences = []\n","        self.accuracies = []\n","\n","        df = pd.read_csv(csv_file_path)\n","        self.prompts = df.iloc[:, 0].tolist()  # Take only the first column (questions)\n","\n","        for prompt in self.prompts:\n","            response, confidence = self.get_model_answer(prompt)\n","            self.responses.append(response)\n","            self.confidences.append(confidence)\n","            reference_text = self.generate_reference_text(prompt)\n","            self.references.append(reference_text)\n","            judgement = self.judge_answer(response, prompt)\n","            accuracy = self.parse_evaluation(judgement)\n","            self.accuracies.append(accuracy)\n","\n","        precision, recall, f1 = self.calculate_bertscore(self.references, self.responses)\n","        print(f\"BERTScore - Precision: {precision}, Recall: {recall}, F1: {f1}\")\n","\n","        data, bins, bin_accuracies = self.calculate_ece()\n","        data.to_csv(\"results.csv\", index=False)  # Save results to CSV\n","        return data, bins, bin_accuracies\n","\n","    def evaluate_folder(self, folder_path):\n","        results = {}  # Store ECE values for each class\n","        category_results = {category: [] for category in set(cat for sublist in self.categories.values() for cat in sublist)}\n","\n","        for filename in os.listdir(folder_path):\n","            if filename.endswith(\".csv\"):\n","                filepath = os.path.join(folder_path, filename)\n","                class_name = filename[:-8]  # Extract class name from filename without \"_dev.csv\"\n","                \n","                category_name = None\n","                for key, value in self.categories.items():\n","                    if key == class_name:\n","                        category_name = value[0]\n","                        break\n","\n","                if category_name:\n","                    print(f\"Evaluating {class_name} in category {category_name}...\")\n","                    data, bins, bin_accuracies = self.evaluate_from_csv(filepath)\n","\n","                    # Align shapes and calculate ECE\n","                    bin_confidences = (bins[:-1] + bins[1:]) / 2  # Confidences for each bin\n","                    valid_bins = bin_accuracies.dropna().index  # Bins with data\n","                    bin_accuracies = bin_accuracies[valid_bins]\n","                    bin_proportions = data['bin'].value_counts(normalize=True)[valid_bins]  # Get proportions for valid bins\n","                    bin_confidences = bin_confidences[valid_bins]  # Select confidences for valid bins\n","\n","                    ece = np.sum(np.abs(bin_accuracies - bin_confidences) * bin_proportions)\n","                    category_results[category_name].append(ece)\n","                    print(f\"{class_name} ECE: {ece}\")\n","\n","        # Calculate average ECE for each category and save to CSV\n","        average_ece_results = {category: np.mean(ece_list) for category, ece_list in category_results.items()}\n","        average_ece_df = pd.DataFrame({'Category': average_ece_results.keys(), 'Average ECE': average_ece_results.values()})\n","        average_ece_df.to_csv(\"category_results.csv\", index=False)\n","\n","    def calculate_ece(self):\n","        # Ensure all lists have the same length\n","        if len(self.prompts) == len(self.responses) == len(self.confidences) == len(self.accuracies):\n","            data = pd.DataFrame({\n","                'prompt': self.prompts,\n","                'response': self.responses,\n","                'confidence': self.confidences,\n","                'rating': self.accuracies\n","            })\n","        else:\n","            raise ValueError(\"All arrays must be of the same length\")\n","\n","        # Normalize confidence scores\n","        data['confidence_normalized'] = data['confidence'] / data['confidence'].max()\n","\n","        # Bin the normalized confidence scores\n","        bins = np.linspace(0, 1, 11)\n","        data['bin'] = pd.cut(data['confidence_normalized'], bins=bins, labels=False, include_lowest=True)\n","\n","        # Calculate accuracy for each bin\n","        bin_accuracies = data.groupby('bin')['rating'].mean()\n","        bin_proportions = data['bin'].value_counts(normalize=True)\n","\n","        # Drop bins with NaN values\n","        valid_bins = bin_accuracies.dropna().index\n","        bin_accuracies = bin_accuracies[valid_bins]\n","        bin_proportions = bin_proportions[valid_bins]\n","        bin_confidences = (bins[:-1] + bins[1:]) / 2\n","        bin_confidences = bin_confidences[valid_bins]\n","\n","        # Ensure lengths match\n","        bin_confidences = bin_confidences[:len(bin_accuracies)]\n","\n","        # Compute ECE\n","        ece = np.sum(np.abs(bin_accuracies - bin_confidences) * bin_proportions)\n","        print(f\"Expected Calibration Error (ECE): {ece}\")\n","\n","        return data, bins, bin_accuracies"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T08:07:11.876735Z","iopub.status.busy":"2024-06-12T08:07:11.876354Z","iopub.status.idle":"2024-06-12T08:07:11.880888Z","shell.execute_reply":"2024-06-12T08:07:11.879978Z","shell.execute_reply.started":"2024-06-12T08:07:11.876705Z"},"trusted":true},"outputs":[],"source":["# pipeline = EvaluationPipeline(api_key=\"Your_api_key\", judge_model_name=\"llama3-70b-8192\", smaller_model_name=\"mistralai/Mistral-7B-Instruct-v0.2\")\n","# pipeline.evaluate_folder(\"/kaggle/working/data/dev\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Chain of thought"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T08:07:13.297674Z","iopub.status.busy":"2024-06-12T08:07:13.297234Z","iopub.status.idle":"2024-06-12T08:07:13.345232Z","shell.execute_reply":"2024-06-12T08:07:13.344157Z","shell.execute_reply.started":"2024-06-12T08:07:13.297640Z"},"trusted":true},"outputs":[],"source":["import os\n","import torch\n","import pandas as pd\n","import numpy as np\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","from transformers import BitsAndBytesConfig\n","import torch.nn.functional as F\n","from bert_score import score\n","\n","class EvaluationPipeline:\n","    def __init__(self, api_key, judge_model_name, smaller_model_name, temperature=0.8, max_tokens=300):\n","        self.api_key = api_key\n","        self.judge_model_name = judge_model_name\n","        self.temperature = temperature\n","        self.max_tokens = max_tokens\n","\n","        self.tokenizer = AutoTokenizer.from_pretrained(smaller_model_name)\n","        \n","        bnb_config = BitsAndBytesConfig(\n","            load_in_4bit=True,\n","            bnb_4bit_quant_type=\"nf4\",\n","            bnb_4bit_compute_dtype=torch.float16\n","        )\n","\n","        self.main_model = AutoModelForCausalLM.from_pretrained(\n","            smaller_model_name,\n","            torch_dtype=torch.float16,\n","            quantization_config=bnb_config,\n","            low_cpu_mem_usage=True,\n","            device_map=\"auto\",\n","        )\n","\n","        self.categories = {\n","            \"abstract_algebra\": [\"math\"],\n","            \"anatomy\": [\"health\"],\n","            \"astronomy\": [\"physics\"],\n","            \"business_ethics\": [\"business\"],\n","            \"clinical_knowledge\": [\"health\"],\n","            \"college_biology\": [\"biology\"],\n","            \"college_chemistry\": [\"chemistry\"],\n","            \"college_computer_science\": [\"computer science\"],\n","            \"college_mathematics\": [\"math\"],\n","            \"college_medicine\": [\"health\"],\n","            \"college_physics\": [\"physics\"],\n","            \"computer_security\": [\"computer science\"],\n","            \"conceptual_physics\": [\"physics\"],\n","            \"econometrics\": [\"economics\"],\n","            \"electrical_engineering\": [\"engineering\"],\n","            \"elementary_mathematics\": [\"math\"],\n","            \"formal_logic\": [\"philosophy\"],\n","            \"global_facts\": [\"other\"],\n","            \"high_school_biology\": [\"biology\"],\n","            \"high_school_chemistry\": [\"chemistry\"],\n","            \"high_school_computer_science\": [\"computer science\"],\n","            \"high_school_european_history\": [\"history\"],\n","            \"high_school_geography\": [\"geography\"],\n","            \"high_school_government_and_politics\": [\"politics\"],\n","            \"high_school_macroeconomics\": [\"economics\"],\n","            \"high_school_mathematics\": [\"math\"],\n","            \"high_school_microeconomics\": [\"economics\"],\n","            \"high_school_physics\": [\"physics\"],\n","            \"high_school_psychology\": [\"psychology\"],\n","            \"high_school_statistics\": [\"math\"],\n","            \"high_school_us_history\": [\"history\"],\n","            \"high_school_world_history\": [\"history\"],\n","            \"human_aging\": [\"health\"],\n","            \"human_sexuality\": [\"culture\"],\n","            \"international_law\": [\"law\"],\n","            \"jurisprudence\": [\"law\"],\n","            \"logical_fallacies\": [\"philosophy\"],\n","            \"machine_learning\": [\"computer science\"],\n","            \"management\": [\"business\"],\n","            \"marketing\": [\"business\"],\n","            \"medical_genetics\": [\"health\"],\n","            \"miscellaneous\": [\"other\"],\n","            \"moral_disputes\": [\"philosophy\"],\n","            \"moral_scenarios\": [\"philosophy\"],\n","            \"nutrition\": [\"health\"],\n","            \"philosophy\": [\"philosophy\"],\n","            \"prehistory\": [\"history\"],\n","            \"professional_accounting\": [\"other\"],\n","            \"professional_law\": [\"law\"],\n","            \"professional_medicine\": [\"health\"],\n","            \"professional_psychology\": [\"psychology\"],\n","            \"public_relations\": [\"politics\"],\n","            \"security_studies\": [\"politics\"],\n","            \"sociology\": [\"culture\"],\n","            \"us_foreign_policy\": [\"politics\"],\n","            \"virology\": [\"health\"],\n","            \"world_religions\": [\"philosophy\"],\n","        }\n","\n","    def generate_cot_prompt(self, question):\n","        # Chain of Thought prompt\n","        cot_prompt = f\"Q: {question}\\nA: Let's think through this step by step.\\n\"\n","        cot_prompt += \"First, consider the main aspects of the question. \"\n","        cot_prompt += \"Next, break down the problem into smaller parts. \"\n","        cot_prompt += \"Finally, synthesize the information to form a coherent answer.\"\n","        return cot_prompt\n","\n","    def get_model_answer(self, question):\n","        \"\"\"Generates an answer from the specified model using Chain of Thought prompting.\"\"\"\n","        prompt = self.generate_cot_prompt(question)\n","        inputs = self.tokenizer(prompt, return_tensors='pt').to(self.main_model.device)\n","        outputs = self.main_model.generate(\n","            inputs['input_ids'], \n","            max_new_tokens=300,  # Limit the number of generated tokens\n","            num_return_sequences=1, \n","            temperature=self.temperature, \n","            output_scores=True, \n","            return_dict_in_generate=True\n","        )\n","        response = self.tokenizer.decode(outputs.sequences[0], skip_special_tokens=True)\n","\n","        # Get the confidence score\n","        logits = torch.stack(outputs.scores, dim=1)\n","        probs = F.softmax(logits, dim=-1)\n","\n","        token_ids = outputs.sequences[:, inputs['input_ids'].shape[1]:]\n","        confidences = probs.gather(2, token_ids.unsqueeze(-1)).squeeze(-1).mean(dim=1).detach().cpu().numpy()\n","\n","        avg_confidence = confidences[0]\n","        return response, avg_confidence\n","\n","    def judge_answer(self, response, prompt):\n","        chat_completion = client.chat.completions.create(\n","            messages=[\n","                {\n","                    \"role\": \"user\",\n","                    \"content\": f\"\"\"\n","                        Review the user’s question and the corresponding response using the binary scoring system described below.\n","                        - 0 points: The response is incorrect or does not address the user’s question.\n","                        - 1 point: The response is correct and addresses the user’s question.\n","\n","                        User: {prompt}\n","                        Response: {response}\n","                        \"\"\"\n","                }\n","            ],\n","            model=self.judge_model_name,\n","        )\n","\n","        judge_response = chat_completion.choices[0].message.content.strip()\n","        return judge_response\n","\n","    def parse_evaluation(self, evaluation):\n","        return 1 if \"1 point\" in evaluation else 0\n","\n","    def generate_reference_text(self, prompt):\n","        inputs = self.tokenizer(prompt, return_tensors='pt').to(self.main_model.device)\n","        outputs = self.main_model.generate(\n","            inputs['input_ids'], \n","            attention_mask=inputs['attention_mask'],\n","            max_new_tokens=self.max_tokens, \n","            num_return_sequences=1, \n","            temperature=self.temperature, \n","            do_sample=True\n","        )\n","        reference_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n","        return reference_text\n","\n","    def calculate_bertscore(self, references, candidates):\n","        P, R, F1 = score(candidates, references, lang=\"en\", model_type=\"bert-base-uncased\")\n","        return P.mean().item(), R.mean().item(), F1.mean().item()\n","\n","    def evaluate_from_csv(self, csv_file_path):\n","        # Clear data before processing each file\n","        self.prompts = []\n","        self.responses = []\n","        self.references = []\n","        self.confidences = []\n","        self.accuracies = []\n","\n","        df = pd.read_csv(csv_file_path)\n","        self.prompts = df.iloc[:, 0].tolist()  # Take only the first column (questions)\n","\n","        for prompt in self.prompts:\n","            response, confidence = self.get_model_answer(prompt)\n","            self.responses.append(response)\n","            self.confidences.append(confidence)\n","            reference_text = self.generate_reference_text(prompt)\n","            self.references.append(reference_text)\n","            judgement = self.judge_answer(response, prompt)\n","            accuracy = self.parse_evaluation(judgement)\n","            self.accuracies.append(accuracy)\n","\n","        precision, recall, f1 = self.calculate_bertscore(self.references, self.responses)\n","        print(f\"BERTScore - Precision: {precision}, Recall: {recall}, F1: {f1}\")\n","\n","        data, bins, bin_accuracies = self.calculate_ece()\n","        data.to_csv(\"results.csv\", index=False)  # Save results to CSV\n","        return data, bins, bin_accuracies\n","\n","    def evaluate_folder(self, folder_path):\n","        results = {}  # Store ECE values for each class\n","        category_results = {category: [] for category in set(cat for sublist in self.categories.values() for cat in sublist)}\n","\n","        for filename in os.listdir(folder_path):\n","            if filename.endswith(\".csv\"):\n","                filepath = os.path.join(folder_path, filename)\n","                class_name = filename[:-8]  # Extract class name from filename without \"_dev.csv\"\n","                \n","                category_name = None\n","                for key, value in self.categories.items():\n","                    if key == class_name:\n","                        category_name = value[0]\n","                        break\n","\n","                if category_name:\n","                    print(f\"Evaluating {class_name} in category {category_name}...\")\n","                    data, bins, bin_accuracies = self.evaluate_from_csv(filepath)\n","\n","                    # Align shapes and calculate ECE\n","                    bin_confidences = (bins[:-1] + bins[1:]) / 2  # Confidences for each bin\n","                    valid_bins = bin_accuracies.dropna().index  # Bins with data\n","                    bin_accuracies = bin_accuracies[valid_bins]\n","                    bin_proportions = data['bin'].value_counts(normalize=True)[valid_bins]  # Get proportions for valid bins\n","                    bin_confidences = bin_confidences[valid_bins]  # Select confidences for valid bins\n","\n","                    ece = np.sum(np.abs(bin_accuracies - bin_confidences) * bin_proportions)\n","                    category_results[category_name].append(ece)\n","                    print(f\"{class_name} ECE: {ece}\")\n","\n","        # Calculate average ECE for each category and save to CSV\n","        average_ece_results = {category: np.mean(ece_list) for category, ece_list in category_results.items()}\n","        average_ece_df = pd.DataFrame({'Category': average_ece_results.keys(), 'Average ECE': average_ece_results.values()})\n","        average_ece_df.to_csv(\"category_results.csv\", index=False)\n","\n","    def calculate_ece(self):\n","        # Ensure all lists have the same length\n","        if len(self.prompts) == len(self.responses) == len(self.confidences) == len(self.accuracies):\n","            data = pd.DataFrame({\n","                'prompt': self.prompts,\n","                'response': self.responses,\n","                'confidence': self.confidences,\n","                'rating': self.accuracies\n","            })\n","        else:\n","            raise ValueError(\"All arrays must be of the same length\")\n","\n","        # Normalize confidence scores\n","        data['confidence_normalized'] = data['confidence'] / data['confidence'].max()\n","\n","        # Bin the normalized confidence scores\n","        bins = np.linspace(0, 1, 11)\n","        data['bin'] = pd.cut(data['confidence_normalized'], bins=bins, labels=False, include_lowest=True)\n","\n","        # Calculate accuracy for each bin\n","        bin_accuracies = data.groupby('bin')['rating'].mean()\n","        bin_proportions = data['bin'].value_counts(normalize=True)\n","\n","        # Drop bins with NaN values\n","        valid_bins = bin_accuracies.dropna().index\n","        bin_accuracies = bin_accuracies[valid_bins]\n","        bin_proportions = bin_proportions[valid_bins]\n","        bin_confidences = (bins[:-1] + bins[1:]) / 2\n","        bin_confidences = bin_confidences[valid_bins]\n","\n","        # Ensure lengths match\n","        bin_confidences = bin_confidences[:len(bin_accuracies)]\n","\n","        # Compute ECE\n","        ece = np.sum(np.abs(bin_accuracies - bin_confidences) * bin_proportions)\n","        print(f\"Expected Calibration Error (ECE): {ece}\")\n","\n","        return data, bins, bin_accuracies"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T08:07:14.122464Z","iopub.status.busy":"2024-06-12T08:07:14.121386Z","iopub.status.idle":"2024-06-12T10:04:06.843947Z","shell.execute_reply":"2024-06-12T10:04:06.843025Z","shell.execute_reply.started":"2024-06-12T08:07:14.122417Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"37fd59a85bf14c60808bc94248c46a04","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4591a5d806f849ddb0fea4211f593f3c","version_major":2,"version_minor":0},"text/plain":["tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d4a2b0ed62414c94a1acb32360a47f51","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a2e8e365f67c49ca8292a64974837524","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"35e0919dc78b4424bd5cfd93a1d413be","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3266c3632efa42fda315aa8e3f5a355a","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cc53bff2b1c24d55bfc07c89e87ae0ff","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a23c4737b48d4d8cba683837f7faeb93","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"46f9d28aa9664b179ef1b063a6a23b74","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3e899b72420442edae880f54184fe5bf","version_major":2,"version_minor":0},"text/plain":["model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d7c8a72838df4d869e34b5ffcb297d4e","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9d7379209118434f9227749a73434bc2","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["Evaluating prehistory in category history...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0202e6c68ad54309ab0fcc27a7035d39","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a637ea1a1ca04b64bd773cec79d3fb70","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"109863c868bf4c6dbc32911667ffe4a4","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d3229d0ba00248e78c58282119c4f5c3","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"43058e2ef3ad433d85b98984b4e28801","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6339928507804871, Recall: 0.646126389503479, F1: 0.6392560601234436\n","Expected Calibration Error (ECE): 0.44999999999999996\n","prehistory ECE: 0.44999999999999996\n","Evaluating elementary_mathematics in category math...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6837377548217773, Recall: 0.7477951049804688, F1: 0.713681161403656\n","Expected Calibration Error (ECE): 0.050000000000000044\n","elementary_mathematics ECE: 0.050000000000000044\n","Evaluating college_physics in category physics...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.7158308625221252, Recall: 0.7305806279182434, F1: 0.7228883504867554\n","Expected Calibration Error (ECE): 0.44999999999999996\n","college_physics ECE: 0.44999999999999996\n","Evaluating professional_psychology in category psychology...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.659892201423645, Recall: 0.6891579627990723, F1: 0.6739794015884399\n","Expected Calibration Error (ECE): 0.050000000000000044\n","professional_psychology ECE: 0.050000000000000044\n","Evaluating professional_accounting in category other...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6989593505859375, Recall: 0.7309845685958862, F1: 0.7142873406410217\n","Expected Calibration Error (ECE): 0.5\n","professional_accounting ECE: 0.5\n","Evaluating college_computer_science in category computer science...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.7804489731788635, Recall: 0.8155450224876404, F1: 0.797234296798706\n","Expected Calibration Error (ECE): 0.19999999999999996\n","college_computer_science ECE: 0.19999999999999996\n","Evaluating professional_medicine in category health...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.7515987157821655, Recall: 0.7363089323043823, F1: 0.7437739968299866\n","Expected Calibration Error (ECE): 0.050000000000000044\n","professional_medicine ECE: 0.050000000000000044\n","Evaluating moral_scenarios in category philosophy...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.7018132209777832, Recall: 0.8154664039611816, F1: 0.7543392181396484\n","Expected Calibration Error (ECE): 0.19999999999999996\n","moral_scenarios ECE: 0.19999999999999996\n","Evaluating high_school_mathematics in category math...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.714411735534668, Recall: 0.7361297011375427, F1: 0.7244102358818054\n","Expected Calibration Error (ECE): 0.7\n","high_school_mathematics ECE: 0.7\n","Evaluating clinical_knowledge in category health...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6294011473655701, Recall: 0.6284540295600891, F1: 0.6286017894744873\n","Expected Calibration Error (ECE): 0.19999999999999996\n","clinical_knowledge ECE: 0.19999999999999996\n","Evaluating marketing in category business...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6170973181724548, Recall: 0.6716013550758362, F1: 0.6417735815048218\n","Expected Calibration Error (ECE): 0.050000000000000044\n","marketing ECE: 0.050000000000000044\n","Evaluating management in category business...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5874842405319214, Recall: 0.6876441836357117, F1: 0.6325666904449463\n","Expected Calibration Error (ECE): 0.44999999999999996\n","management ECE: 0.44999999999999996\n","Evaluating high_school_chemistry in category chemistry...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6899381875991821, Recall: 0.7074669003486633, F1: 0.6985300779342651\n","Expected Calibration Error (ECE): 0.44999999999999996\n","high_school_chemistry ECE: 0.44999999999999996\n","Evaluating virology in category health...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6208117008209229, Recall: 0.5941415429115295, F1: 0.606736421585083\n","Expected Calibration Error (ECE): 0.44999999999999996\n","virology ECE: 0.44999999999999996\n","Evaluating moral_disputes in category philosophy...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5990657806396484, Recall: 0.6261063814163208, F1: 0.610586404800415\n","Expected Calibration Error (ECE): 0.050000000000000044\n","moral_disputes ECE: 0.050000000000000044\n","Evaluating us_foreign_policy in category politics...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6590663194656372, Recall: 0.6653509140014648, F1: 0.6602483987808228\n","Expected Calibration Error (ECE): 0.050000000000000044\n","us_foreign_policy ECE: 0.050000000000000044\n","Evaluating college_medicine in category health...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6443365812301636, Recall: 0.6429410576820374, F1: 0.6435619592666626\n","Expected Calibration Error (ECE): 0.19999999999999996\n","college_medicine ECE: 0.19999999999999996\n","Evaluating world_religions in category philosophy...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6396685838699341, Recall: 0.6598471403121948, F1: 0.6493556499481201\n","Expected Calibration Error (ECE): 0.07500000000000001\n","world_religions ECE: 0.07500000000000001\n","Evaluating public_relations in category politics...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6100300550460815, Recall: 0.7041884660720825, F1: 0.6532495021820068\n","Expected Calibration Error (ECE): 0.19999999999999996\n","public_relations ECE: 0.19999999999999996\n","Evaluating college_biology in category biology...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6936075687408447, Recall: 0.6982257962226868, F1: 0.6947707533836365\n","Expected Calibration Error (ECE): 0.44999999999999996\n","college_biology ECE: 0.44999999999999996\n","Evaluating abstract_algebra in category math...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6769496202468872, Recall: 0.6974403858184814, F1: 0.6866719126701355\n","Expected Calibration Error (ECE): 0.25000000000000006\n","abstract_algebra ECE: 0.25000000000000006\n","Evaluating philosophy in category philosophy...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6627349853515625, Recall: 0.6728911995887756, F1: 0.6667096018791199\n","Expected Calibration Error (ECE): 0.19999999999999996\n","philosophy ECE: 0.19999999999999996\n","Evaluating security_studies in category politics...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6657552719116211, Recall: 0.6864618062973022, F1: 0.67559814453125\n","Expected Calibration Error (ECE): 0.19999999999999996\n","security_studies ECE: 0.19999999999999996\n","Evaluating anatomy in category health...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6795506477355957, Recall: 0.6944300532341003, F1: 0.685681939125061\n","Expected Calibration Error (ECE): 0.050000000000000044\n","anatomy ECE: 0.050000000000000044\n","Evaluating logical_fallacies in category philosophy...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6087924242019653, Recall: 0.623183012008667, F1: 0.6146827936172485\n","Expected Calibration Error (ECE): 0.24999999999999997\n","logical_fallacies ECE: 0.24999999999999997\n","Evaluating college_mathematics in category math...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.7361247539520264, Recall: 0.7744659185409546, F1: 0.7534113526344299\n","Expected Calibration Error (ECE): 0.44999999999999996\n","college_mathematics ECE: 0.44999999999999996\n","Evaluating global_facts in category other...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6144339442253113, Recall: 0.6477363109588623, F1: 0.6284106373786926\n","Expected Calibration Error (ECE): 0.050000000000000044\n","global_facts ECE: 0.050000000000000044\n","Evaluating professional_law in category law...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.7822022438049316, Recall: 0.8072214722633362, F1: 0.7944397330284119\n","Expected Calibration Error (ECE): 0.44999999999999996\n","professional_law ECE: 0.44999999999999996\n","Evaluating high_school_computer_science in category computer science...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.72240149974823, Recall: 0.7563115358352661, F1: 0.7377078533172607\n","Expected Calibration Error (ECE): 0.19999999999999996\n","high_school_computer_science ECE: 0.19999999999999996\n","Evaluating electrical_engineering in category engineering...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.704463005065918, Recall: 0.7110668420791626, F1: 0.7075126767158508\n","Expected Calibration Error (ECE): 0.44999999999999996\n","electrical_engineering ECE: 0.44999999999999996\n","Evaluating high_school_physics in category physics...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6649301648139954, Recall: 0.7568923830986023, F1: 0.7069213390350342\n","Expected Calibration Error (ECE): 0.44999999999999996\n","high_school_physics ECE: 0.44999999999999996\n","Evaluating high_school_psychology in category psychology...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6651532053947449, Recall: 0.6891831755638123, F1: 0.676491379737854\n","Expected Calibration Error (ECE): 0.19999999999999996\n","high_school_psychology ECE: 0.19999999999999996\n","Evaluating international_law in category law...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6141598224639893, Recall: 0.6216412782669067, F1: 0.6169857978820801\n","Expected Calibration Error (ECE): 0.24999999999999997\n","international_law ECE: 0.24999999999999997\n","Evaluating astronomy in category physics...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6521729826927185, Recall: 0.6891274452209473, F1: 0.6696947813034058\n","Expected Calibration Error (ECE): 0.29999999999999993\n","astronomy ECE: 0.29999999999999993\n","Evaluating high_school_statistics in category math...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.7476105690002441, Recall: 0.7890998125076294, F1: 0.7674471139907837\n","Expected Calibration Error (ECE): 0.44999999999999996\n","high_school_statistics ECE: 0.44999999999999996\n","Evaluating econometrics in category economics...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.7505456209182739, Recall: 0.8024786710739136, F1: 0.7753179669380188\n","Expected Calibration Error (ECE): 0.7\n","econometrics ECE: 0.7\n","Evaluating high_school_biology in category biology...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6344455480575562, Recall: 0.7458221912384033, F1: 0.6854252219200134\n","Expected Calibration Error (ECE): 0.19999999999999996\n","high_school_biology ECE: 0.19999999999999996\n","Evaluating human_aging in category health...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6449713706970215, Recall: 0.6910526156425476, F1: 0.6668069362640381\n","Expected Calibration Error (ECE): 0.24999999999999997\n","human_aging ECE: 0.24999999999999997\n","Evaluating medical_genetics in category health...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6394978761672974, Recall: 0.657630205154419, F1: 0.6479019522666931\n","Expected Calibration Error (ECE): 0.050000000000000044\n","medical_genetics ECE: 0.050000000000000044\n","Evaluating high_school_world_history in category history...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.7807133793830872, Recall: 0.8330931663513184, F1: 0.8058438897132874\n","Expected Calibration Error (ECE): 0.07500000000000001\n","high_school_world_history ECE: 0.07500000000000001\n","Evaluating nutrition in category health...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5790227651596069, Recall: 0.6216880083084106, F1: 0.5979691743850708\n","Expected Calibration Error (ECE): 0.19999999999999996\n","nutrition ECE: 0.19999999999999996\n","Evaluating miscellaneous in category other...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6453812718391418, Recall: 0.7123745679855347, F1: 0.6771827340126038\n","Expected Calibration Error (ECE): 0.050000000000000044\n","miscellaneous ECE: 0.050000000000000044\n","Evaluating conceptual_physics in category physics...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6365315914154053, Recall: 0.6427524089813232, F1: 0.639305830001831\n","Expected Calibration Error (ECE): 0.5\n","conceptual_physics ECE: 0.5\n","Evaluating high_school_geography in category geography...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6304186582565308, Recall: 0.6660398244857788, F1: 0.6458275318145752\n","Expected Calibration Error (ECE): 0.09999999999999998\n","high_school_geography ECE: 0.09999999999999998\n","Evaluating business_ethics in category business...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6732578277587891, Recall: 0.7688603401184082, F1: 0.7152594327926636\n","Expected Calibration Error (ECE): 0.19999999999999996\n","business_ethics ECE: 0.19999999999999996\n","Evaluating sociology in category culture...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.629059910774231, Recall: 0.6954232454299927, F1: 0.6600255370140076\n","Expected Calibration Error (ECE): 0.19999999999999996\n","sociology ECE: 0.19999999999999996\n","Evaluating jurisprudence in category law...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6437543630599976, Recall: 0.6834267973899841, F1: 0.6619002819061279\n","Expected Calibration Error (ECE): 0.050000000000000044\n","jurisprudence ECE: 0.050000000000000044\n","Evaluating formal_logic in category philosophy...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.7114101052284241, Recall: 0.7435455918312073, F1: 0.7261021733283997\n","Expected Calibration Error (ECE): 0.19999999999999996\n","formal_logic ECE: 0.19999999999999996\n","Evaluating college_chemistry in category chemistry...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.7091479301452637, Recall: 0.72735196352005, F1: 0.7179147601127625\n","Expected Calibration Error (ECE): 0.44999999999999996\n","college_chemistry ECE: 0.44999999999999996\n","Evaluating high_school_us_history in category history...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.8610353469848633, Recall: 0.914620041847229, F1: 0.886654794216156\n","Expected Calibration Error (ECE): 0.050000000000000044\n","high_school_us_history ECE: 0.050000000000000044\n","Evaluating high_school_government_and_politics in category politics...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6286543011665344, Recall: 0.6596214175224304, F1: 0.643152117729187\n","Expected Calibration Error (ECE): 0.050000000000000044\n","high_school_government_and_politics ECE: 0.050000000000000044\n","Evaluating high_school_macroeconomics in category economics...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.655210018157959, Recall: 0.644071102142334, F1: 0.6490761041641235\n","Expected Calibration Error (ECE): 0.19999999999999996\n","high_school_macroeconomics ECE: 0.19999999999999996\n","Evaluating machine_learning in category computer science...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6514697670936584, Recall: 0.6659669280052185, F1: 0.6585547924041748\n","Expected Calibration Error (ECE): 0.44999999999999996\n","machine_learning ECE: 0.44999999999999996\n","Evaluating human_sexuality in category culture...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6180141568183899, Recall: 0.6692608594894409, F1: 0.6419561505317688\n","Expected Calibration Error (ECE): 0.050000000000000044\n","human_sexuality ECE: 0.050000000000000044\n","Evaluating high_school_microeconomics in category economics...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6687872409820557, Recall: 0.6676023006439209, F1: 0.667985200881958\n","Expected Calibration Error (ECE): 0.050000000000000044\n","high_school_microeconomics ECE: 0.050000000000000044\n","Evaluating computer_security in category computer science...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6233068704605103, Recall: 0.6450125575065613, F1: 0.6291664838790894\n","Expected Calibration Error (ECE): 0.050000000000000044\n","computer_security ECE: 0.050000000000000044\n","Evaluating high_school_european_history in category history...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.911251962184906, Recall: 0.9311766028404236, F1: 0.9210892915725708\n","Expected Calibration Error (ECE): 0.050000000000000044\n","high_school_european_history ECE: 0.050000000000000044\n"]}],"source":["pipeline = EvaluationPipeline(api_key=\"Your_api_key\", judge_model_name=\"llama3-70b-8192\", smaller_model_name=\"mistralai/Mistral-7B-Instruct-v0.2\")\n","pipeline.evaluate_folder(\"/kaggle/working/data/dev\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["   "]},{"cell_type":"markdown","metadata":{},"source":["## Few-shot prompting"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T10:04:45.537227Z","iopub.status.busy":"2024-06-13T10:04:45.536674Z","iopub.status.idle":"2024-06-13T10:04:45.584075Z","shell.execute_reply":"2024-06-13T10:04:45.583042Z","shell.execute_reply.started":"2024-06-13T10:04:45.537194Z"},"trusted":true},"outputs":[],"source":["class EvaluationPipeline:\n","    def __init__(self, api_key, judge_model_name, smaller_model_name, temperature=0.8, max_tokens=300):\n","        self.api_key = api_key\n","        self.judge_model_name = judge_model_name\n","        self.temperature = temperature\n","        self.max_tokens = max_tokens\n","\n","        self.tokenizer = AutoTokenizer.from_pretrained(smaller_model_name)\n","\n","        bnb_config = BitsAndBytesConfig(\n","            load_in_4bit=True,\n","            bnb_4bit_quant_type=\"nf4\",\n","            bnb_4bit_compute_dtype=torch.float16\n","        )\n","\n","        self.main_model = AutoModelForCausalLM.from_pretrained(\n","            smaller_model_name,\n","            torch_dtype=torch.float16,\n","            quantization_config=bnb_config,\n","            low_cpu_mem_usage=True,\n","            device_map=\"auto\",\n","        )\n","\n","        self.categories = {\n","            \"abstract_algebra\": [\"math\"],\n","            \"anatomy\": [\"health\"],\n","            \"astronomy\": [\"physics\"],\n","            \"business_ethics\": [\"business\"],\n","            \"clinical_knowledge\": [\"health\"],\n","            \"college_biology\": [\"biology\"],\n","            \"college_chemistry\": [\"chemistry\"],\n","            \"college_computer_science\": [\"computer science\"],\n","            \"college_mathematics\": [\"math\"],\n","            \"college_medicine\": [\"health\"],\n","            \"college_physics\": [\"physics\"],\n","            \"computer_security\": [\"computer science\"],\n","            \"conceptual_physics\": [\"physics\"],\n","            \"econometrics\": [\"economics\"],\n","            \"electrical_engineering\": [\"engineering\"],\n","            \"elementary_mathematics\": [\"math\"],\n","            \"formal_logic\": [\"philosophy\"],\n","            \"global_facts\": [\"other\"],\n","            \"high_school_biology\": [\"biology\"],\n","            \"high_school_chemistry\": [\"chemistry\"],\n","            \"high_school_computer_science\": [\"computer science\"],\n","            \"high_school_european_history\": [\"history\"],\n","            \"high_school_geography\": [\"geography\"],\n","            \"high_school_government_and_politics\": [\"politics\"],\n","            \"high_school_macroeconomics\": [\"economics\"],\n","            \"high_school_mathematics\": [\"math\"],\n","            \"high_school_microeconomics\": [\"economics\"],\n","            \"high_school_physics\": [\"physics\"],\n","            \"high_school_psychology\": [\"psychology\"],\n","            \"high_school_statistics\": [\"math\"],\n","            \"high_school_us_history\": [\"history\"],\n","            \"high_school_world_history\": [\"history\"],\n","            \"human_aging\": [\"health\"],\n","            \"human_sexuality\": [\"culture\"],\n","            \"international_law\": [\"law\"],\n","            \"jurisprudence\": [\"law\"],\n","            \"logical_fallacies\": [\"philosophy\"],\n","            \"machine_learning\": [\"computer science\"],\n","            \"management\": [\"business\"],\n","            \"marketing\": [\"business\"],\n","            \"medical_genetics\": [\"health\"],\n","            \"miscellaneous\": [\"other\"],\n","            \"moral_disputes\": [\"philosophy\"],\n","            \"moral_scenarios\": [\"philosophy\"],\n","            \"nutrition\": [\"health\"],\n","            \"philosophy\": [\"philosophy\"],\n","            \"prehistory\": [\"history\"],\n","            \"professional_accounting\": [\"other\"],\n","            \"professional_law\": [\"law\"],\n","            \"professional_medicine\": [\"health\"],\n","            \"professional_psychology\": [\"psychology\"],\n","            \"public_relations\": [\"politics\"],\n","            \"security_studies\": [\"politics\"],\n","            \"sociology\": [\"culture\"],\n","            \"us_foreign_policy\": [\"politics\"],\n","            \"virology\": [\"health\"],\n","            \"world_religions\": [\"philosophy\"],\n","        }\n","\n","    def get_model_answer(self, prompt):\n","        \"\"\"Generates an answer from the specified model.\"\"\"\n","        inputs = self.tokenizer(prompt, return_tensors='pt').to(self.main_model.device)\n","        outputs = self.main_model.generate(\n","            inputs.input_ids,\n","            max_new_tokens=300,  # Limit the number of generated tokens\n","            num_return_sequences=1,\n","            temperature=self.temperature,\n","            output_scores=True,\n","            return_dict_in_generate=True\n","        )\n","        response = self.tokenizer.decode(outputs.sequences[0], skip_special_tokens=True)\n","\n","        # Get the confidence score\n","        logits = torch.stack(outputs.scores, dim=1)\n","        probs = F.softmax(logits, dim=-1)\n","\n","        token_ids = outputs.sequences[:, inputs.input_ids.shape[1]:]\n","        confidences = probs.gather(2, token_ids.unsqueeze(-1)).squeeze(-1).mean(dim=1).detach().cpu().numpy()\n","\n","        avg_confidence = confidences[0]\n","        return response, avg_confidence\n","\n","#     def judge_answer(self, response, prompt):\n","#         chat_completion = client.chat.completions.create(\n","#             messages=[\n","#                 {\n","#                     \"role\": \"user\",\n","#                     \"content\": f\"\"\"\n","#                         Review the user’s question and the corresponding response using the binary scoring system described below.\n","#                         - 0 points: The response is incorrect or does not address the user’s question.\n","#                         - 1 point: The response is correct and addresses the user’s question.\n","\n","#                         User: {prompt}\n","#                         Response: {response}\n","#                         \"\"\"\n","#                 }\n","#             ],\n","#             model=self.judge_model_name,\n","#         )\n","\n","#         judge_response = chat_completion.choices[0].message.content.strip()\n","#         return judge_response\n","    def judge_answer(self, response, prompt):\n","        evaluation_prompt =  f\"\"\"\n","                        Review the user’s question and the corresponding response using the binary scoring system described below.\n","                        - 0 points: The response is incorrect or does not address the user’s question.\n","                        - 1 point: The response is correct and addresses the user’s question.\n","\n","                        User: {prompt}\n","                        Response: {response}\n","                        \"\"\"\n","        judge_response = gemini_model.generate_content(evaluation_prompt)\n","        return judge_response\n","\n","    def parse_evaluation(self, evaluation):\n","        return 1 if \"1 point\" in evaluation else 0\n","\n","    def generate_reference_text(self, prompt):\n","        inputs = self.tokenizer(prompt, return_tensors='pt').to(self.main_model.device)\n","        outputs = self.main_model.generate(\n","            inputs.input_ids,\n","            max_new_tokens=self.max_tokens,\n","            num_return_sequences=1,\n","            temperature=self.temperature,\n","            do_sample=True\n","        )\n","        reference_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n","        return reference_text\n","\n","    def calculate_bertscore(self, references, candidates):\n","        P, R, F1 = score(candidates, references, lang=\"en\", model_type=\"bert-base-uncased\")\n","        return P.mean().item(), R.mean().item(), F1.mean().item()\n","\n","    def evaluate_from_csv(self, csv_file_path):\n","        # Clear data before processing each file\n","        self.prompts = []\n","        self.responses = []\n","        self.references = []\n","        self.confidences = []\n","        self.accuracies = []\n","\n","        df = pd.read_csv(csv_file_path)\n","        self.prompts = df.iloc[:, 0].tolist()  # Take only the first column (questions)\n","\n","        for prompt in self.prompts:\n","            response, confidence = self.get_model_answer(prompt)\n","            self.responses.append(response)\n","            self.confidences.append(confidence)\n","            reference_text = self.generate_reference_text(prompt)\n","            self.references.append(reference_text)\n","            judgement = self.judge_answer(response, prompt)\n","            accuracy = self.parse_evaluation(judgement)\n","            self.accuracies.append(accuracy)\n","\n","        precision, recall, f1 = self.calculate_bertscore(self.references, self.responses)\n","        print(f\"BERTScore - Precision: {precision}, Recall: {recall}, F1: {f1}\")\n","\n","        data, bins, bin_accuracies = self.calculate_ece()\n","        data.to_csv(\"results.csv\", index=False)  # Save results to CSV\n","        return data, bins, bin_accuracies\n","\n","    def calculate_ece(self, confidences, accuracies):\n","        # Ensure all lists have the same length\n","        if len(confidences) == len(accuracies):\n","            data = pd.DataFrame({\n","                'confidence': confidences,\n","                'rating': accuracies\n","            })\n","        else:\n","            raise ValueError(\"Confidence and accuracy arrays must be of the same length\")\n","\n","        # Normalize confidence scores\n","        data['confidence_normalized'] = data['confidence'] / data['confidence'].max()\n","\n","        # Bin the normalized confidence scores\n","        bins = np.linspace(0, 1, 11)\n","        data['bin'] = pd.cut(data['confidence_normalized'], bins=bins, labels=False, include_lowest=True)\n","\n","        # Calculate accuracy for each bin\n","        bin_accuracies = data.groupby('bin')['rating'].mean()\n","        bin_proportions = data['bin'].value_counts(normalize=True)\n","\n","        # Drop bins with NaN values\n","        valid_bins = bin_accuracies.dropna().index\n","        bin_accuracies = bin_accuracies[valid_bins]\n","        bin_proportions = bin_proportions[valid_bins]\n","        bin_confidences = (bins[:-1] + bins[1:]) / 2\n","        bin_confidences = bin_confidences[valid_bins]\n","\n","        # Ensure lengths match\n","        bin_confidences = bin_confidences[:len(bin_accuracies)]\n","\n","        # Compute ECE\n","        ece = np.sum(np.abs(bin_accuracies - bin_confidences) * bin_proportions)\n","        print(f\"Expected Calibration Error (ECE): {ece}\")\n","\n","        return data, bins, bin_accuracies\n","\n","    def evaluate_folder(self, dev_folder_path, test_folder_path, few_shot_samples=5):\n","        results = {}  # Store ECE values for each class\n","        category_results = {category: [] for category in set(cat for sublist in self.categories.values() for cat in sublist)}\n","\n","        for filename in os.listdir(dev_folder_path):\n","            if filename.endswith(\".csv\"):\n","                dev_filepath = os.path.join(dev_folder_path, filename)\n","                class_name = filename[:-8]  # Extract class name from filename without \"_dev.csv\"\n","\n","                category_name = None\n","                for key, value in self.categories.items():\n","                    if key == class_name:\n","                        category_name = value[0]\n","                        break\n","\n","                if category_name:\n","                    print(f\"Evaluating {class_name} in category {category_name}...\")\n","\n","                    # 1. Load and process dev data\n","                    dev_df = pd.read_csv(dev_filepath)\n","                    dev_questions = dev_df.iloc[:, 0].tolist()  # Take only the first column (questions)\n","                    dev_answers = dev_df.iloc[:, 5].tolist()  # Take answers from column F\n","\n","                    # 2. Prepare few-shot examples\n","                    few_shot_prompts = []\n","                    few_shot_responses = []\n","                    for i, question in enumerate(dev_questions):\n","                        correct_answer_column = ord(dev_answers[i]) - ord('A') + 1  # Convert A, B, C, D to 1, 2, 3, 4\n","                        few_shot_prompts.append(question)\n","                        #few_shot_responses.append(dev_df.iloc[i, correct_answer_column])\n","                        few_shot_responses.append(dev_df.iloc[i, correct_answer_column - 1]) \n","\n","                    # 3. Load and process test data\n","                    test_filepath = os.path.join(test_folder_path, f\"{class_name}_test.csv\")\n","                    test_df = pd.read_csv(test_filepath)\n","                    test_questions = test_df.iloc[:few_shot_samples, 0].tolist()  # Take first 5 questions\n","\n","                    # 4. Generate responses using few-shot prompting\n","                    test_responses = []\n","                    test_confidences = []\n","                    test_references = []\n","                    for question in test_questions:\n","                        # Add few-shot examples to the prompt\n","                        few_shot_prompt = \"\\n\".join(f\"Q: {q}\\nA: {a}\" for q, a in zip(few_shot_prompts, few_shot_responses))\n","                        full_prompt = f\"{few_shot_prompt}\\n\\nQ: {question}\\nA:\"\n","\n","                        response, confidence = self.get_model_answer(full_prompt)\n","                        test_responses.append(response)\n","                        test_confidences.append(confidence)\n","\n","                        reference_text = self.generate_reference_text(question)  # Generate reference text for BERTscore\n","                        test_references.append(reference_text)\n","\n","                    # 5. Judge answers\n","                    test_accuracies = []\n","                    for response, question in zip(test_responses, test_questions):\n","                        judgement = self.judge_answer(response, question)\n","                        accuracy = self.parse_evaluation(judgement)\n","                        test_accuracies.append(accuracy)\n","\n","                    # 6. Calculate BERTscore\n","                    precision, recall, f1 = self.calculate_bertscore(test_references, test_responses)\n","                    print(f\"BERTScore - Precision: {precision}, Recall: {recall}, F1: {f1}\")\n","\n","                    # 7. Calculate ECE (with modified confidence list)\n","                    data, bins, bin_accuracies = self.calculate_ece(test_confidences, test_accuracies)\n","\n","                    # Align shapes and calculate ECE (same as before)\n","                    bin_confidences = (bins[:-1] + bins[1:]) / 2\n","                    valid_bins = bin_accuracies.dropna().index\n","                    bin_accuracies = bin_accuracies[valid_bins]\n","                    bin_proportions = data['bin'].value_counts(normalize=True)[valid_bins]\n","                    bin_confidences = bin_confidences[valid_bins]\n","\n","                    ece = np.sum(np.abs(bin_accuracies - bin_confidences) * bin_proportions)\n","                    category_results[category_name].append(ece)\n","                    print(f\"{class_name} ECE: {ece}\")\n","\n","        # Calculate average ECE for each category (same as before)\n","        average_ece_results = {category: np.mean(ece_list) for category, ece_list in category_results.items()}\n","        average_ece_df = pd.DataFrame({'Category': average_ece_results.keys(), 'Average ECE': average_ece_results.values()})\n","        average_ece_df.to_csv(\"category_results.csv\", index=False)"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T10:04:48.766385Z","iopub.status.busy":"2024-06-13T10:04:48.766040Z","iopub.status.idle":"2024-06-13T12:47:01.826357Z","shell.execute_reply":"2024-06-13T12:47:01.825408Z","shell.execute_reply.started":"2024-06-13T10:04:48.766357Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5d58c88f806b488f89ca4a29f2647ecf","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["Evaluating medical_genetics in category health...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.4944817125797272, Recall: 0.503717839717865, F1: 0.4985562264919281\n","Expected Calibration Error (ECE): 0.95\n","medical_genetics ECE: 0.95\n","Evaluating moral_disputes in category philosophy...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.48141852021217346, Recall: 0.5655442476272583, F1: 0.5194173455238342\n","Expected Calibration Error (ECE): 0.95\n","moral_disputes ECE: 0.95\n","Evaluating prehistory in category history...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.49757593870162964, Recall: 0.5852855443954468, F1: 0.5335210561752319\n","Expected Calibration Error (ECE): 0.95\n","prehistory ECE: 0.95\n","Evaluating world_religions in category philosophy...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.4913352429866791, Recall: 0.541679322719574, F1: 0.51507967710495\n","Expected Calibration Error (ECE): 0.95\n","world_religions ECE: 0.95\n","Evaluating high_school_world_history in category history...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.50331050157547, Recall: 0.5268734693527222, F1: 0.5146795511245728\n","Expected Calibration Error (ECE): 0.89\n","high_school_world_history ECE: 0.89\n","Evaluating college_physics in category physics...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5451294183731079, Recall: 0.6357333064079285, F1: 0.5857875943183899\n","Expected Calibration Error (ECE): 0.95\n","college_physics ECE: 0.95\n","Evaluating moral_scenarios in category philosophy...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6966349482536316, Recall: 0.6665096282958984, F1: 0.6804066896438599\n","Expected Calibration Error (ECE): 0.95\n","moral_scenarios ECE: 0.95\n","Evaluating college_medicine in category health...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.4626578390598297, Recall: 0.5632781386375427, F1: 0.5070357918739319\n","Expected Calibration Error (ECE): 0.95\n","college_medicine ECE: 0.95\n","Evaluating miscellaneous in category other...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.4444577097892761, Recall: 0.6097609400749207, F1: 0.5126628875732422\n","Expected Calibration Error (ECE): 0.95\n","miscellaneous ECE: 0.95\n","Evaluating econometrics in category economics...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5155665278434753, Recall: 0.6561673879623413, F1: 0.5769470930099487\n","Expected Calibration Error (ECE): 0.95\n","econometrics ECE: 0.95\n","Evaluating professional_law in category law...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5226927995681763, Recall: 0.5385300517082214, F1: 0.5304356813430786\n","Expected Calibration Error (ECE): 0.89\n","professional_law ECE: 0.89\n","Evaluating high_school_european_history in category history...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5066421627998352, Recall: 0.5277098417282104, F1: 0.5160042643547058\n","Expected Calibration Error (ECE): 0.79\n","high_school_european_history ECE: 0.79\n","Evaluating professional_accounting in category other...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.4762069284915924, Recall: 0.5505895018577576, F1: 0.5104140043258667\n","Expected Calibration Error (ECE): 0.95\n","professional_accounting ECE: 0.95\n","Evaluating philosophy in category philosophy...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5077736973762512, Recall: 0.5764285326004028, F1: 0.5397974252700806\n","Expected Calibration Error (ECE): 0.91\n","philosophy ECE: 0.91\n","Evaluating international_law in category law...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5145498514175415, Recall: 0.5799599885940552, F1: 0.5449473857879639\n","Expected Calibration Error (ECE): 0.95\n","international_law ECE: 0.95\n","Evaluating high_school_geography in category geography...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.4937314987182617, Recall: 0.5587372183799744, F1: 0.5228578448295593\n","Expected Calibration Error (ECE): 0.95\n","high_school_geography ECE: 0.95\n","Evaluating high_school_microeconomics in category economics...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5588499307632446, Recall: 0.6061918139457703, F1: 0.5795276761054993\n","Expected Calibration Error (ECE): 0.95\n","high_school_microeconomics ECE: 0.95\n","Evaluating high_school_mathematics in category math...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6009005904197693, Recall: 0.6805089116096497, F1: 0.6377071142196655\n","Expected Calibration Error (ECE): 0.93\n","high_school_mathematics ECE: 0.93\n","Evaluating public_relations in category politics...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.4809657037258148, Recall: 0.5872547030448914, F1: 0.5243476629257202\n","Expected Calibration Error (ECE): 0.93\n","public_relations ECE: 0.93\n","Evaluating human_sexuality in category culture...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5050601959228516, Recall: 0.5609462857246399, F1: 0.5297505855560303\n","Expected Calibration Error (ECE): 0.95\n","human_sexuality ECE: 0.95\n","Evaluating high_school_chemistry in category chemistry...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5043583512306213, Recall: 0.6035383939743042, F1: 0.5486699342727661\n","Expected Calibration Error (ECE): 0.95\n","high_school_chemistry ECE: 0.95\n","Evaluating business_ethics in category business...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6061611175537109, Recall: 0.6299975514411926, F1: 0.6168230772018433\n","Expected Calibration Error (ECE): 0.95\n","business_ethics ECE: 0.95\n","Evaluating college_computer_science in category computer science...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.49995216727256775, Recall: 0.5556989908218384, F1: 0.5261520743370056\n","Expected Calibration Error (ECE): 0.93\n","college_computer_science ECE: 0.93\n","Evaluating conceptual_physics in category physics...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5217126607894897, Recall: 0.5526703596115112, F1: 0.5364641547203064\n","Expected Calibration Error (ECE): 0.93\n","conceptual_physics ECE: 0.93\n","Evaluating college_biology in category biology...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5015072226524353, Recall: 0.5892207026481628, F1: 0.5417830944061279\n","Expected Calibration Error (ECE): 0.93\n","college_biology ECE: 0.93\n","Evaluating us_foreign_policy in category politics...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.48206695914268494, Recall: 0.5621670484542847, F1: 0.517454981803894\n","Expected Calibration Error (ECE): 0.95\n","us_foreign_policy ECE: 0.95\n","Evaluating computer_security in category computer science...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5671586394309998, Recall: 0.6609498262405396, F1: 0.6102505922317505\n","Expected Calibration Error (ECE): 0.95\n","computer_security ECE: 0.95\n","Evaluating high_school_psychology in category psychology...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.46853503584861755, Recall: 0.5505161881446838, F1: 0.5060871839523315\n","Expected Calibration Error (ECE): 0.93\n","high_school_psychology ECE: 0.93\n","Evaluating high_school_physics in category physics...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5760728120803833, Recall: 0.6845258474349976, F1: 0.6252900958061218\n","Expected Calibration Error (ECE): 0.93\n","high_school_physics ECE: 0.93\n","Evaluating high_school_us_history in category history...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5049761533737183, Recall: 0.5238852500915527, F1: 0.5136850476264954\n","Expected Calibration Error (ECE): 0.93\n","high_school_us_history ECE: 0.93\n","Evaluating professional_psychology in category psychology...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.4605686664581299, Recall: 0.5801280736923218, F1: 0.512342095375061\n","Expected Calibration Error (ECE): 0.93\n","professional_psychology ECE: 0.93\n","Evaluating professional_medicine in category health...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5400986075401306, Recall: 0.5699726343154907, F1: 0.5545991659164429\n","Expected Calibration Error (ECE): 0.95\n","professional_medicine ECE: 0.95\n","Evaluating human_aging in category health...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.4640234410762787, Recall: 0.49402618408203125, F1: 0.47794514894485474\n","Expected Calibration Error (ECE): 0.8700000000000001\n","human_aging ECE: 0.8700000000000001\n","Evaluating high_school_biology in category biology...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5039244294166565, Recall: 0.5957939624786377, F1: 0.5393799543380737\n","Expected Calibration Error (ECE): 0.95\n","high_school_biology ECE: 0.95\n","Evaluating management in category business...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5359740853309631, Recall: 0.5380391478538513, F1: 0.5364123582839966\n","Expected Calibration Error (ECE): 0.95\n","management ECE: 0.95\n","Evaluating high_school_statistics in category math...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5614379644393921, Recall: 0.6570199728012085, F1: 0.6052109003067017\n","Expected Calibration Error (ECE): 0.93\n","high_school_statistics ECE: 0.93\n","Evaluating clinical_knowledge in category health...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.48507174849510193, Recall: 0.5623006224632263, F1: 0.5204794406890869\n","Expected Calibration Error (ECE): 0.95\n","clinical_knowledge ECE: 0.95\n","Evaluating sociology in category culture...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.48917046189308167, Recall: 0.5322325825691223, F1: 0.5096436738967896\n","Expected Calibration Error (ECE): 0.95\n","sociology ECE: 0.95\n","Evaluating high_school_computer_science in category computer science...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5417710542678833, Recall: 0.6961960792541504, F1: 0.6088815927505493\n","Expected Calibration Error (ECE): 0.91\n","high_school_computer_science ECE: 0.91\n","Evaluating elementary_mathematics in category math...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5284029245376587, Recall: 0.6746370196342468, F1: 0.5921458601951599\n","Expected Calibration Error (ECE): 0.95\n","elementary_mathematics ECE: 0.95\n","Evaluating abstract_algebra in category math...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.7013205289840698, Recall: 0.7085933685302734, F1: 0.703197181224823\n","Expected Calibration Error (ECE): 0.95\n","abstract_algebra ECE: 0.95\n","Evaluating college_chemistry in category chemistry...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.537734866142273, Recall: 0.6212443709373474, F1: 0.5760563015937805\n","Expected Calibration Error (ECE): 0.95\n","college_chemistry ECE: 0.95\n","Evaluating nutrition in category health...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.48830166459083557, Recall: 0.5530050992965698, F1: 0.5183573961257935\n","Expected Calibration Error (ECE): 0.95\n","nutrition ECE: 0.95\n","Evaluating high_school_macroeconomics in category economics...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5201281905174255, Recall: 0.5834554433822632, F1: 0.5493096113204956\n","Expected Calibration Error (ECE): 0.95\n","high_school_macroeconomics ECE: 0.95\n","Evaluating college_mathematics in category math...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5760151147842407, Recall: 0.6616584062576294, F1: 0.6158018112182617\n","Expected Calibration Error (ECE): 0.95\n","college_mathematics ECE: 0.95\n","Evaluating formal_logic in category philosophy...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.6188668012619019, Recall: 0.6917294859886169, F1: 0.651607096195221\n","Expected Calibration Error (ECE): 0.93\n","formal_logic ECE: 0.93\n","Evaluating high_school_government_and_politics in category politics...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5047168731689453, Recall: 0.6098519563674927, F1: 0.550698459148407\n","Expected Calibration Error (ECE): 0.95\n","high_school_government_and_politics ECE: 0.95\n","Evaluating anatomy in category health...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5157326459884644, Recall: 0.5697611570358276, F1: 0.539932370185852\n","Expected Calibration Error (ECE): 0.95\n","anatomy ECE: 0.95\n","Evaluating virology in category health...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.47709113359451294, Recall: 0.4937059283256531, F1: 0.48447805643081665\n","Expected Calibration Error (ECE): 0.95\n","virology ECE: 0.95\n","Evaluating marketing in category business...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.518837571144104, Recall: 0.6061579585075378, F1: 0.5586507320404053\n","Expected Calibration Error (ECE): 0.93\n","marketing ECE: 0.93\n","Evaluating electrical_engineering in category engineering...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5466245412826538, Recall: 0.609437882900238, F1: 0.5758200883865356\n","Expected Calibration Error (ECE): 0.95\n","electrical_engineering ECE: 0.95\n","Evaluating security_studies in category politics...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5424862504005432, Recall: 0.6195226311683655, F1: 0.5783966779708862\n","Expected Calibration Error (ECE): 0.95\n","security_studies ECE: 0.95\n","Evaluating astronomy in category physics...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5155247449874878, Recall: 0.5444375276565552, F1: 0.5291396379470825\n","Expected Calibration Error (ECE): 0.95\n","astronomy ECE: 0.95\n","Evaluating jurisprudence in category law...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5407916307449341, Recall: 0.5943735241889954, F1: 0.5647557973861694\n","Expected Calibration Error (ECE): 0.95\n","jurisprudence ECE: 0.95\n","Evaluating global_facts in category other...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5242142081260681, Recall: 0.5461180806159973, F1: 0.5340294241905212\n","Expected Calibration Error (ECE): 0.95\n","global_facts ECE: 0.95\n","Evaluating logical_fallacies in category philosophy...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5520535707473755, Recall: 0.6328607797622681, F1: 0.5887747406959534\n","Expected Calibration Error (ECE): 0.95\n","logical_fallacies ECE: 0.95\n","Evaluating machine_learning in category computer science...\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.5269377827644348, Recall: 0.658031165599823, F1: 0.5841397047042847\n","Expected Calibration Error (ECE): 0.95\n","machine_learning ECE: 0.95\n"]}],"source":["pipeline = EvaluationPipeline(api_key=\"Your_api_key\", judge_model_name=\"llama3-70b-8192\", smaller_model_name=\"mistralai/Mistral-7B-Instruct-v0.2\")\n","pipeline.evaluate_folder(\"/kaggle/working/data/dev\", \"/kaggle/working/data/test\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["  "]},{"cell_type":"markdown","metadata":{},"source":["## FROM mike"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T12:48:17.792778Z","iopub.status.busy":"2024-06-13T12:48:17.792401Z","iopub.status.idle":"2024-06-13T12:48:17.862436Z","shell.execute_reply":"2024-06-13T12:48:17.861288Z","shell.execute_reply.started":"2024-06-13T12:48:17.792745Z"},"trusted":true},"outputs":[],"source":["class EvaluationPipeline:\n","    def __init__(self, api_key, judge_model_name, smaller_model_name, temperature=0.8, max_tokens=300, ntrain=5):\n","        self.api_key = api_key\n","        self.judge_model_name = judge_model_name\n","        self.temperature = temperature\n","        self.max_tokens = max_tokens\n","        self.ntrain = ntrain\n","\n","        self.tokenizer = AutoTokenizer.from_pretrained(smaller_model_name)\n","\n","        bnb_config = BitsAndBytesConfig(\n","            load_in_4bit=True,\n","            bnb_4bit_quant_type=\"nf4\",\n","            bnb_4bit_compute_dtype=torch.float16\n","        )\n","\n","        self.main_model = AutoModelForCausalLM.from_pretrained(\n","            smaller_model_name,\n","            torch_dtype=torch.float16,\n","            quantization_config=bnb_config,\n","            low_cpu_mem_usage=True,\n","            device_map=\"auto\",\n","        )\n","\n","        self.categories = {\n","            \"abstract_algebra\": [\"math\"],\n","            \"anatomy\": [\"health\"],\n","            \"astronomy\": [\"physics\"],\n","            \"business_ethics\": [\"business\"],\n","            \"clinical_knowledge\": [\"health\"],\n","            \"college_biology\": [\"biology\"],\n","            \"college_chemistry\": [\"chemistry\"],\n","            \"college_computer_science\": [\"computer science\"],\n","            \"college_mathematics\": [\"math\"],\n","            \"college_medicine\": [\"health\"],\n","            \"college_physics\": [\"physics\"],\n","            \"computer_security\": [\"computer science\"],\n","            \"conceptual_physics\": [\"physics\"],\n","            \"econometrics\": [\"economics\"],\n","            \"electrical_engineering\": [\"engineering\"],\n","            \"elementary_mathematics\": [\"math\"],\n","            \"formal_logic\": [\"philosophy\"],\n","            \"global_facts\": [\"other\"],\n","            \"high_school_biology\": [\"biology\"],\n","            \"high_school_chemistry\": [\"chemistry\"],\n","            \"high_school_computer_science\": [\"computer science\"],\n","            \"high_school_european_history\": [\"history\"],\n","            \"high_school_geography\": [\"geography\"],\n","            \"high_school_government_and_politics\": [\"politics\"],\n","            \"high_school_macroeconomics\": [\"economics\"],\n","            \"high_school_mathematics\": [\"math\"],\n","            \"high_school_microeconomics\": [\"economics\"],\n","            \"high_school_physics\": [\"physics\"],\n","            \"high_school_psychology\": [\"psychology\"],\n","            \"high_school_statistics\": [\"math\"],\n","            \"high_school_us_history\": [\"history\"],\n","            \"high_school_world_history\": [\"history\"],\n","            \"human_aging\": [\"health\"],\n","            \"human_sexuality\": [\"culture\"],\n","            \"international_law\": [\"law\"],\n","            \"jurisprudence\": [\"law\"],\n","            \"logical_fallacies\": [\"philosophy\"],\n","            \"machine_learning\": [\"computer science\"],\n","            \"management\": [\"business\"],\n","            \"marketing\": [\"business\"],\n","            \"medical_genetics\": [\"health\"],\n","            \"miscellaneous\": [\"other\"],\n","            \"moral_disputes\": [\"philosophy\"],\n","            \"moral_scenarios\": [\"philosophy\"],\n","            \"nutrition\": [\"health\"],\n","            \"philosophy\": [\"philosophy\"],\n","            \"prehistory\": [\"history\"],\n","            \"professional_accounting\": [\"other\"],\n","            \"professional_law\": [\"law\"],\n","            \"professional_medicine\": [\"health\"],\n","            \"professional_psychology\": [\"psychology\"],\n","            \"public_relations\": [\"politics\"],\n","            \"security_studies\": [\"politics\"],\n","            \"sociology\": [\"culture\"],\n","            \"us_foreign_policy\": [\"politics\"],\n","            \"virology\": [\"health\"],\n","            \"world_religions\": [\"philosophy\"],\n","        }\n","\n","    def format_example(self, df, idx, include_answer=True):\n","        prompt = str(df.iloc[idx, 0])\n","        for j in range(1, df.shape[1] - 1):\n","            value = df.iloc[idx, j]\n","            if pd.isna(value):\n","                value = \"\"\n","            prompt += f\"\\n{chr(64+j)}. {str(value)}\"\n","        prompt += \"\\nAnswer: \"\n","        if include_answer:\n","            answer = df.iloc[idx, df.shape[1] - 1]\n","            if pd.isna(answer):\n","                answer = \"\"\n","            prompt += f\"{str(answer)}\\n\\n\"\n","        return prompt\n","\n","    def gen_prompt(self, train_df, k=-1):\n","        prompt = \"The following are multiple choice questions (with answers).\\n\\n\"\n","        if k == -1:\n","            k = train_df.shape[0]\n","        for i in range(k):\n","            prompt += self.format_example(train_df, i)\n","        return prompt\n","\n","    def get_model_answer(self, prompt):\n","        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.main_model.device)\n","        outputs = self.main_model.generate(\n","            inputs['input_ids'],\n","            max_new_tokens=300,\n","            num_return_sequences=1,\n","            temperature=self.temperature,\n","            output_scores=True,\n","            return_dict_in_generate=True\n","        )\n","        response = self.tokenizer.decode(outputs.sequences[0], skip_special_tokens=True)\n","\n","        logits = torch.stack(outputs.scores, dim=1)\n","        probs = F.softmax(logits, dim=-1)\n","\n","        token_ids = outputs.sequences[:, inputs['input_ids'].shape[1]:]\n","        confidences = probs.gather(2, token_ids.unsqueeze(-1)).squeeze(-1).mean(dim=1).detach().cpu().numpy()\n","\n","        avg_confidence = confidences[0]\n","        return response, avg_confidence\n","\n","#     def judge_answer(self, response, prompt):\n","#         chat_completion = client.chat.completions.create(\n","#             messages=[\n","#                 {\n","#                     \"role\": \"user\",\n","#                     \"content\": f\"\"\"\n","#                         Review the user’s question and the corresponding response using the binary scoring system described below.\n","#                         - 0 points: The response is incorrect or does not address the user’s question.\n","#                         - 1 point: The response is correct and addresses the user’s question.\n","\n","#                         User: {prompt}\n","#                         Response: {response}\n","#                         \"\"\"\n","#                 }\n","#             ],\n","#             model=self.judge_model_name,\n","#         )\n","\n","#         judge_response = chat_completion.choices[0].message.content.strip()\n","#         return judge_response\n","    \n","    def judge_answer(self, response, prompt):\n","        evaluation_prompt =  f\"\"\"\n","                        Review the user’s question and the corresponding response using the binary scoring system described below.\n","                        - 0 points: The response is incorrect or does not address the user’s question.\n","                        - 1 point: The response is correct and addresses the user’s question.\n","\n","                        User: {prompt}\n","                        Response: {response}\n","                        \"\"\"\n","        judge_response = gemini_model.generate_content(evaluation_prompt)\n","        return judge_response\n","\n","    def parse_evaluation(self, evaluation):\n","        return 1 if \"1 point\" in evaluation else 0\n","\n","    def generate_reference_text(self, prompt):\n","        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.main_model.device)\n","        outputs = self.main_model.generate(\n","            inputs['input_ids'],\n","            max_new_tokens=self.max_tokens,\n","            num_return_sequences=1,\n","            temperature=self.temperature,\n","            do_sample=True\n","        )\n","        reference_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n","        return reference_text\n","\n","    def calculate_bertscore(self, references, candidates):\n","        P, R, F1 = score(candidates, references, lang=\"en\", model_type=\"bert-base-uncased\")\n","        return P.mean().item(), R.mean().item(), F1.mean().item()\n","\n","    def evaluate(self, dev_folder_path, test_folder_path, num_test_questions=5):\n","        self.prompts = []\n","        self.responses = []\n","        self.references = []\n","        self.confidences = []\n","        self.accuracies = []\n","\n","        dev_dfs = []\n","        for filename in os.listdir(dev_folder_path):\n","            if filename.endswith(\".csv\"):\n","                dev_filepath = os.path.join(dev_folder_path, filename)\n","                dev_df = pd.read_csv(dev_filepath)\n","                dev_dfs.append(dev_df)\n","\n","        dev_df = pd.concat(dev_dfs)\n","\n","        test_prompts = []\n","        for filename in os.listdir(test_folder_path):\n","            if filename.endswith(\".csv\"):\n","                test_filepath = os.path.join(test_folder_path, filename)\n","                test_df = pd.read_csv(test_filepath)\n","                test_prompts.extend(test_df.iloc[:, 0].tolist())\n","\n","        # Limit the number of test questions\n","        test_prompts = test_prompts[:num_test_questions]\n","\n","        for prompt in test_prompts:\n","            few_shot_prompt = self.gen_prompt(dev_df, k=self.ntrain) + str(prompt) + \"\\nAnswer: \"\n","            response, confidence = self.get_model_answer(few_shot_prompt)\n","            self.responses.append(response)\n","            self.confidences.append(confidence)\n","            reference_text = self.generate_reference_text(prompt)\n","            self.references.append(reference_text)\n","            judgement = self.judge_answer(response, prompt)\n","            accuracy = self.parse_evaluation(judgement)\n","            self.accuracies.append(accuracy)\n","            self.prompts.append(prompt)  # Ensure the prompt is also appended here\n","\n","        if len(self.prompts) != len(self.responses) or len(self.prompts) != len(self.confidences) or len(self.prompts) != len(self.accuracies):\n","            raise ValueError(\"All arrays must be of the same length\")\n","\n","        precision, recall, f1 = self.calculate_bertscore(self.references, self.responses)\n","        print(f\"BERTScore - Precision: {precision}, Recall: {recall}, F1: {f1}\")\n","\n","        data, bins, bin_accuracies = self.calculate_ece()\n","        data.to_csv(\"results.csv\", index=False)\n","        return data, bins, bin_accuracies\n","\n","    def evaluate_folder(self, folder_path, num_test_questions=5):\n","        results = {}  # Store ECE values for each class\n","        category_results = {category: [] for category in set(cat for sublist in self.categories.values() for cat in sublist)}\n","\n","        for filename in os.listdir(folder_path):\n","            if filename.endswith(\".csv\"):\n","                filepath = os.path.join(folder_path, filename)\n","                class_name = filename[:-8]  # Extract class name from filename without \"_dev.csv\"\n","\n","                category_name = None\n","                for key, value in self.categories.items():\n","                    if key == class_name:\n","                        category_name = value[0]\n","                        break\n","\n","                if category_name:\n","                    print(f\"Evaluating {class_name} in category {category_name}...\")\n","                    data, bins, bin_accuracies = self.evaluate(filepath, num_test_questions)\n","\n","                    # Align shapes and calculate ECE\n","                    bin_confidences = (bins[:-1] + bins[1:]) / 2  # Confidences for each bin\n","                    valid_bins = bin_accuracies.dropna().index  # Bins with data\n","                    bin_accuracies = bin_accuracies[valid_bins]\n","                    bin_proportions = data['bin'].value_counts(normalize=True)[valid_bins]  # Get proportions for valid bins\n","                    bin_confidences = bin_confidences[valid_bins]  # Select confidences for valid bins\n","\n","                    ece = np.sum(np.abs(bin_accuracies - bin_confidences) * bin_proportions)\n","                    category_results[category_name].append(ece)\n","                    print(f\"{class_name} ECE: {ece}\")\n","\n","        # Calculate average ECE for each category and save to CSV\n","        average_ece_results = {category: np.mean(ece_list) for category, ece_list in category_results.items()}\n","        average_ece_df = pd.DataFrame({'Category': average_ece_results.keys(), 'Average ECE': average_ece_results.values()})\n","        average_ece_df.to_csv(\"category_results.csv\", index=False)\n","\n","    def calculate_ece(self):\n","        data = pd.DataFrame({\n","            'prompt': self.prompts,\n","            'response': self.responses,\n","            'confidence': self.confidences,\n","            'rating': self.accuracies\n","        })\n","\n","        data['confidence_normalized'] = data['confidence'] / data['confidence'].max()\n","\n","        bins = np.linspace(0, 1, 11)\n","        data['bin'] = pd.cut(data['confidence_normalized'], bins=bins, labels=False, include_lowest=True)\n","\n","        bin_accuracies = data.groupby('bin')['rating'].mean()\n","        bin_proportions = data['bin'].value_counts(normalize=True)\n","\n","        valid_bins = bin_accuracies.dropna().index\n","        bin_accuracies = bin_accuracies[valid_bins]\n","        bin_proportions = bin_proportions[valid_bins]\n","        bin_confidences = (bins[:-1] + bins[1:]) / 2\n","        bin_confidences = bin_confidences[valid_bins]\n","\n","        bin_confidences = bin_confidences[:len(bin_accuracies)]\n","\n","        ece = np.sum(np.abs(bin_accuracies - bin_confidences) * bin_proportions)\n","        print(f\"Expected Calibration Error (ECE): {ece}\")\n","\n","        return data, bins, bin_accuracies"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T10:01:12.611307Z","iopub.status.busy":"2024-06-13T10:01:12.610818Z","iopub.status.idle":"2024-06-13T10:04:04.719208Z","shell.execute_reply":"2024-06-13T10:04:04.718311Z","shell.execute_reply.started":"2024-06-13T10:01:12.611280Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c047959999fb4ee2b9dad8d9c9dca598","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.3878081738948822, Recall: 0.4060923457145691, F1: 0.39653247594833374\n","Expected Calibration Error (ECE): 0.95\n"]},{"data":{"text/plain":["(                                              prompt  \\\n"," 0  Ms. Perez drove a total of 40 miles in 5 days....   \n"," 1                   Find the quotient of −40 ÷ (−8).   \n"," 2  A soccer team has $90.00 to buy soccer balls. ...   \n"," 3  You and three friends go to a concert. The tot...   \n"," 4  Use the expression below to answer the questio...   \n"," \n","                                             response  confidence  rating  \\\n"," 0  The following are multiple choice questions (w...    0.915953       0   \n"," 1  The following are multiple choice questions (w...    0.835674       0   \n"," 2  The following are multiple choice questions (w...    0.856325       0   \n"," 3  The following are multiple choice questions (w...    0.862580       0   \n"," 4  The following are multiple choice questions (w...    0.902784       0   \n"," \n","    confidence_normalized  bin  \n"," 0               1.000000    9  \n"," 1               0.912355    9  \n"," 2               0.934901    9  \n"," 3               0.941729    9  \n"," 4               0.985623    9  ,\n"," array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n"," bin\n"," 9    0.0\n"," Name: rating, dtype: float64)"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["pipeline = EvaluationPipeline(api_key=\"Your_api_key\", judge_model_name=\"llama3-70b-8192\", smaller_model_name=\"mistralai/Mistral-7B-Instruct-v0.2\")\n","pipeline.evaluate(dev_folder_path=\"/kaggle/working/data/dev\", test_folder_path=\"/kaggle/working/data/test\", num_test_questions=5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## NEW PIPELINE"]},{"cell_type":"markdown","metadata":{},"source":["## Zero shot prompting with livebench and mmlu"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-06-27T04:53:16.041702Z","iopub.status.busy":"2024-06-27T04:53:16.041086Z","iopub.status.idle":"2024-06-27T04:53:16.063478Z","shell.execute_reply":"2024-06-27T04:53:16.062636Z","shell.execute_reply.started":"2024-06-27T04:53:16.041667Z"},"trusted":true},"outputs":[],"source":["class EvaluationPipeline:\n","    def __init__(self, api_key, judge_model_name, smaller_model_name, temperature=0.8, max_tokens=300):\n","        self.api_key = api_key\n","        self.judge_model_name = judge_model_name\n","        self.temperature = temperature\n","        self.max_tokens = max_tokens\n","\n","        self.tokenizer = AutoTokenizer.from_pretrained(smaller_model_name)\n","\n","        bnb_config = BitsAndBytesConfig(\n","            load_in_4bit=True,\n","            bnb_4bit_quant_type=\"nf4\",\n","            bnb_4bit_compute_dtype=torch.float16\n","        )\n","\n","        self.main_model = AutoModelForCausalLM.from_pretrained(\n","            smaller_model_name,\n","            torch_dtype=torch.float16,\n","            quantization_config=bnb_config,\n","            low_cpu_mem_usage=True,\n","            device_map=\"auto\",\n","        )\n","\n","        self.categories = {\n","            \"data_analysis\": [\"data_analysis\"],\n","            \"coding\": [\"coding\"],\n","            \"language\": [\"language\"],\n","            \"reasoning\": [\"reasoning\"],\n","            \"math\": [\"math\"],\n","        }\n","\n","    def get_model_answer(self, prompt):\n","        \"\"\"Generates an answer from the specified model.\"\"\"\n","        inputs = self.tokenizer.encode(prompt).to(self.main_model.device)\n","        outputs = self.main_model.generate(\n","            inputs['input_ids'],\n","            max_new_tokens=self.max_tokens,  # Limit the number of generated tokens\n","            num_return_sequences=1,\n","            temperature=self.temperature,\n","            output_scores=True,\n","            return_dict_in_generate=True\n","        )\n","        response = self.tokenizer.decode(outputs.sequences[0])\n","\n","        # Get the confidence score\n","        logits = torch.stack(outputs.scores, dim=1)\n","        probs = torch.nn.functional.softmax(logits, dim=-1)\n","\n","        token_ids = outputs.sequences[:, inputs['input_ids'].shape[1]:]\n","        confidences = probs.gather(2, token_ids.unsqueeze(-1)).squeeze(-1).mean(dim=1).detach().cpu().numpy()\n","\n","        avg_confidence = confidences[0]\n","        return response, avg_confidence\n","\n","    def evaluate_dataset(self, dataset_name, number_of_questions=None):\n","        \"\"\"Evaluates the model on the specified dataset.\"\"\"\n","\n","        if dataset_name == \"mmlu\":\n","            # Your existing MMlu evaluation logic (unchanged from previous code)\n","            # ...\n","        elif dataset_name == \"livebench\":\n","            self.evaluate_livebench(number_of_questions)\n","        else:\n","            raise ValueError(f\"Invalid dataset name: {dataset_name}. Valid options are 'mmlu' and 'livebench'.\")\n","\n","    def evaluate_livebench(self, number_of_questions=None):\n","        \"\"\"Evaluates the model on the LiveBench dataset.\"\"\"\n","        results = []  # List to store results for each category\n","\n","        for category in self.categories.keys():\n","            file_path = f\"livebench_data/{category}.csv\"  # Replace with your actual file paths\n","            df = pd.read_csv(file_path)\n","\n","            # Drop rows with missing ground truth values\n","            if category == \"coding\":\n","                df = df.dropna(subset=[\"solution\"])\n","            else:\n","                df = df.dropna(subset=[\"ground_truth\"])\n","\n","            if number_of_questions is not None:\n","                df = df.sample(n=number_of_questions, random_state=42)  # Randomly sample questions\n","\n","            prompts = df[\"turns\"].tolist()\n","            ground_truths = df[\"ground_truth\"].tolist() if category != \"coding\" else df[\"solution\"].tolist()\n","\n","            responses = []\n","            confidences = []\n","\n","            for prompt in prompts:\n","                response, confidence = self.get_model_answer(prompt)\n","                responses.append(response)\n","                confidences.append(confidence)\n","\n","            accuracies = [1 if response.strip() == ground_truth.strip() else 0 for response, ground_truth in zip(responses, ground_truths)]\n","            \n","            # Calculate ECE\n","            data = pd.DataFrame({\n","                \"prompt\": prompts,\n","                \"response\": responses,\n","                \"confidence\": confidences,\n","                \"accuracy\": accuracies\n","            })\n","\n","            data, bins, bin_accuracies = self.calculate_ece(data)\n","            ece = np.sum(np.abs(bin_accuracies - (bins[:-1] + bins[1:]) / 2) * data['bin'].value_counts(normalize=True))\n","            print(f\"Category: {category}, ECE: {ece}\")\n","\n","            results.append({\n","                \"category\": category,\n","                \"ece\": ece\n","            })\n","\n","    # Save the results to a CSV file\n","    results_df = pd.DataFrame(results)\n","    results_df.to_csv(\"livebench_results.csv\", index=False) \n","\n","    # Return the results for each category\n","    return results \n","\n","    def calculate_ece(self, data):\n","        \"\"\"Calculates the Expected Calibration Error (ECE).\"\"\"\n","        # Normalize confidence scores\n","        data['confidence_normalized'] = data['confidence'] / data['confidence'].max()\n","\n","        # Bin the normalized confidence scores\n","        bins = np.linspace(0, 1, 11)\n","        data['bin'] = pd.cut(data['confidence_normalized'], bins=bins, labels=False, include_lowest=True)\n","\n","        # Calculate accuracy for each bin\n","        bin_accuracies = data.groupby('bin')['accuracy'].mean()\n","\n","        return data, bins, bin_accuracies"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## GPT"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T08:33:24.572643Z","iopub.status.busy":"2024-06-28T08:33:24.571910Z","iopub.status.idle":"2024-06-28T08:33:24.578871Z","shell.execute_reply":"2024-06-28T08:33:24.577907Z","shell.execute_reply.started":"2024-06-28T08:33:24.572613Z"},"trusted":true},"outputs":[],"source":["class Tokenizer:\n","    def __init__(self, model_name):\n","        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n","        self.tokenizer.pad_token = self.tokenizer.eos_token\n","\n","    def encode(self, text, max_length=1024):\n","        return self.tokenizer.encode_plus(text, return_tensors='pt', max_length=max_length, truncation=True)\n","\n","    def decode(self, tokens):\n","        return self.tokenizer.decode(tokens, skip_special_tokens=True)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T08:33:43.482670Z","iopub.status.busy":"2024-06-28T08:33:43.482117Z","iopub.status.idle":"2024-06-28T08:33:43.542602Z","shell.execute_reply":"2024-06-28T08:33:43.541668Z","shell.execute_reply.started":"2024-06-28T08:33:43.482631Z"},"trusted":true},"outputs":[],"source":["class EvaluationPipeline:\n","    def __init__(self, api_key, judge_model_name, smaller_model_name, temperature=0.8, max_tokens=300):\n","        self.api_key = api_key\n","        self.judge_model_name = judge_model_name\n","        self.smaller_model_name = smaller_model_name\n","        self.temperature = temperature\n","        self.max_tokens = max_tokens\n","\n","        self.tokenizer = AutoTokenizer.from_pretrained(smaller_model_name)\n","\n","        bnb_config = BitsAndBytesConfig(\n","            load_in_4bit=True,\n","            bnb_4bit_quant_type=\"nf4\",\n","            bnb_4bit_compute_dtype=torch.float16\n","        )\n","\n","        self.main_model = AutoModelForCausalLM.from_pretrained(\n","            smaller_model_name,\n","            torch_dtype=torch.float16,\n","            quantization_config=bnb_config,\n","            low_cpu_mem_usage=True,\n","            device_map=\"auto\",\n","        )\n","\n","        self.mmlu_categories = {\n","            \"abstract_algebra\": [\"math\"],\n","            \"anatomy\": [\"health\"],\n","            \"astronomy\": [\"physics\"],\n","            \"business_ethics\": [\"business\"],\n","            \"clinical_knowledge\": [\"health\"],\n","            \"college_biology\": [\"biology\"],\n","            \"college_chemistry\": [\"chemistry\"],\n","            \"college_computer_science\": [\"computer science\"],\n","            \"college_mathematics\": [\"math\"],\n","            \"college_medicine\": [\"health\"],\n","            \"college_physics\": [\"physics\"],\n","            \"computer_security\": [\"computer science\"],\n","            \"conceptual_physics\": [\"physics\"],\n","            \"econometrics\": [\"economics\"],\n","            \"electrical_engineering\": [\"engineering\"],\n","            \"elementary_mathematics\": [\"math\"],\n","            \"formal_logic\": [\"philosophy\"],\n","            \"global_facts\": [\"other\"],\n","            \"high_school_biology\": [\"biology\"],\n","            \"high_school_chemistry\": [\"chemistry\"],\n","            \"high_school_computer_science\": [\"computer science\"],\n","            \"high_school_european_history\": [\"history\"],\n","            \"high_school_geography\": [\"geography\"],\n","            \"high_school_government_and_politics\": [\"politics\"],\n","            \"high_school_macroeconomics\": [\"economics\"],\n","            \"high_school_mathematics\": [\"math\"],\n","            \"high_school_microeconomics\": [\"economics\"],\n","            \"high_school_physics\": [\"physics\"],\n","            \"high_school_psychology\": [\"psychology\"],\n","            \"high_school_statistics\": [\"math\"],\n","            \"high_school_us_history\": [\"history\"],\n","            \"high_school_world_history\": [\"history\"],\n","            \"human_aging\": [\"health\"],\n","            \"human_sexuality\": [\"culture\"],\n","            \"international_law\": [\"law\"],\n","            \"jurisprudence\": [\"law\"],\n","            \"logical_fallacies\": [\"philosophy\"],\n","            \"machine_learning\": [\"computer science\"],\n","            \"management\": [\"business\"],\n","            \"marketing\": [\"business\"],\n","            \"medical_genetics\": [\"health\"],\n","            \"miscellaneous\": [\"other\"],\n","            \"moral_disputes\": [\"philosophy\"],\n","            \"moral_scenarios\": [\"philosophy\"],\n","            \"nutrition\": [\"health\"],\n","            \"philosophy\": [\"philosophy\"],\n","            \"prehistory\": [\"history\"],\n","            \"professional_accounting\": [\"other\"],\n","            \"professional_law\": [\"law\"],\n","            \"professional_medicine\": [\"health\"],\n","            \"professional_psychology\": [\"psychology\"],\n","            \"public_relations\": [\"politics\"],\n","            \"security_studies\": [\"politics\"],\n","            \"sociology\": [\"culture\"],\n","            \"us_foreign_policy\": [\"politics\"],\n","            \"virology\": [\"health\"],\n","            \"world_religions\": [\"philosophy\"],\n","        }\n","\n","        self.livebench_categories = {\n","            \"data_analysis\": [\"data_analysis\"],\n","            \"coding\": [\"coding\"],\n","            \"language\": [\"language\"],\n","            \"reasoning\": [\"reasoning\"],\n","            \"math\": [\"math\"],\n","        }\n","\n","    def get_model_answer(self, prompt):\n","        inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(self.main_model.device)\n","        outputs = self.main_model.generate(\n","            inputs, \n","            max_new_tokens=300,\n","            num_return_sequences=1, \n","            temperature=self.temperature, \n","            output_scores=True, \n","            return_dict_in_generate=True\n","        )\n","        response = self.tokenizer.decode(outputs.sequences[0], skip_special_tokens=True)\n","\n","        logits = torch.stack(outputs.scores, dim=1)\n","        probs = F.softmax(logits, dim=-1)\n","\n","        token_ids = outputs.sequences[:, inputs.shape[1]:]\n","        confidences = probs.gather(2, token_ids.unsqueeze(-1)).squeeze(-1).mean(dim=1).detach().cpu().numpy()\n","\n","        avg_confidence = confidences[0]\n","        return response, avg_confidence\n","\n","    def judge_answer(self, response, prompt):\n","        chat_completion = client.chat.completions.create(\n","            messages=[\n","                {\n","                    \"role\": \"user\",\n","                    \"content\": f\"\"\"\n","                        Review the user’s question and the corresponding response using the binary scoring system described below.\n","                        - 0 points: The response is incorrect or does not address the user’s question.\n","                        - 1 point: The response is correct and addresses the user’s question.\n","\n","                        User: {prompt}\n","                        Response: {response}\n","                        \"\"\"\n","                }\n","            ],\n","            model=self.judge_model_name,\n","        )\n","\n","        judge_response = chat_completion.choices[0].message.content.strip()\n","        return judge_response\n","\n","    def parse_evaluation(self, evaluation):\n","        return 1 if \"1 point\" in evaluation else 0\n","\n","    def generate_reference_text(self, prompt):\n","        inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(self.main_model.device)\n","        outputs = self.main_model.generate(\n","            inputs,\n","            max_new_tokens=self.max_tokens,\n","            num_return_sequences=1,\n","            temperature=self.temperature,\n","            do_sample=True\n","        )\n","        reference_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n","        return reference_text\n","\n","\n","    def calculate_bertscore(self, references, candidates):\n","        references = list(references)\n","        candidates = list(candidates)\n","        P, R, F1 = score(candidates, references, lang=\"en\", model_type=\"bert-base-uncased\")\n","        return P.mean().item(), R.mean().item(), F1.mean().item()\n","\n","    def evaluate_from_csv(self, csv_file_path, dataset_type, num_questions=None):\n","        self.prompts = []\n","        self.responses = []\n","        self.references = []\n","        self.confidences = []\n","        self.accuracies = []\n","\n","        df = pd.read_csv(csv_file_path)\n","\n","        if dataset_type == \"mmlu\":\n","            self.prompts = df.iloc[:, 0].tolist()\n","            if num_questions:\n","                self.prompts = self.prompts[:num_questions]\n","                \n","            for prompt in self.prompts:\n","                response, confidence = self.get_model_answer(prompt)\n","                self.responses.append(response)\n","                self.confidences.append(confidence)\n","                reference_text = self.generate_reference_text(prompt)\n","                self.references.append(reference_text)\n","                judgement = self.judge_answer(response, prompt)\n","                accuracy = self.parse_evaluation(judgement)\n","                self.accuracies.append(accuracy)\n","                \n","        elif dataset_type == \"livebench\":\n","            if \"coding\" in csv_file_path:\n","                self.prompts = df[\"turns\"].tolist()\n","                self.references = df[\"solution\"].tolist()\n","            else:\n","                self.prompts = df[\"turns\"].tolist()\n","                self.references = df[\"ground_truth\"].tolist()\n","            \n","            # Filter out rows where \"turns\" has a value but \"ground_truth\"/\"solution\" is empty\n","            self.prompts, self.references = zip(*[\n","                (prompt, reference) for prompt, reference in zip(self.prompts, self.references) \n","                if pd.notna(prompt) and pd.notna(reference)\n","            ])\n","\n","            if num_questions:\n","                self.prompts = self.prompts[:num_questions]\n","                self.references = self.references[:num_questions]\n","\n","            for prompt, reference in zip(self.prompts, self.references):\n","                response, confidence = self.get_model_answer(prompt)\n","                self.responses.append(response)\n","                self.confidences.append(confidence)\n","                similarity = 1 - (edit_distance(response.strip(), reference.strip()) / \n","                                max(len(response.strip()), len(reference.strip()))) \n","                self.accuracies.append(similarity)\n","#                 accuracy = 1 if response.strip() == reference.strip() else 0\n","#                 self.accuracies.append(accuracy)\n","\n","        precision, recall, f1 = self.calculate_bertscore(self.references, self.responses)\n","        print(f\"BERTScore - Precision: {precision}, Recall: {recall}, F1: {f1}\")\n","\n","        data, bins, bin_accuracies = self.calculate_ece()\n","        data.to_csv(\"results.csv\", index=False)\n","        \n","        # Save BERTScore along with ECE results\n","        data['precision'] = precision\n","        data['recall'] = recall\n","        data['f1'] = f1\n","        data.to_csv(\"results.csv\", index=False)\n","        \n","        return data, bins, bin_accuracies\n","\n","    def evaluate_folder(self, folder_path, dataset_type, num_questions=None):\n","        results = {}\n","        reliability_data = {}\n","        category_results = {category: [] for category in set(cat for sublist in self.mmlu_categories.values() for cat in sublist)}\n","\n","        if dataset_type == \"livebench\":\n","            category_results = {category: [] for category in set(cat for sublist in self.livebench_categories.values() for cat in sublist)}\n","\n","        for filename in os.listdir(folder_path):\n","            if filename.endswith(\".csv\"):\n","                filepath = os.path.join(folder_path, filename)\n","                class_name = filename[:-8] \n","                data, bins, bin_accuracies = self.evaluate_from_csv(filepath, dataset_type, num_questions)\n","                results[class_name] = data\n","        \n","                \n","                # Store class-wise data for reliability diagram\n","                reliability_data[class_name] = {\n","                    'bin_confidences': (bins[:-1] + bins[1:]) / 2,\n","                    'bin_accuracies': bin_accuracies\n","                }\n","                if dataset_type == \"mmlu\":\n","                    for category_name in self.mmlu_categories.get(class_name, []):\n","                        # Calculate ECE within the category loop\n","                        bin_confidences = (bins[:-1] + bins[1:]) / 2  # Confidences for each bin\n","                        valid_bins = bin_accuracies.dropna().index  # Bins with data\n","                        bin_accuracies = bin_accuracies[valid_bins]\n","                        bin_proportions = data['bin'].value_counts(normalize=True)[valid_bins]  # Get proportions for valid bins\n","                        bin_confidences = bin_confidences[valid_bins]  # Select confidences for valid bins\n","\n","                        ece = np.sum(np.abs(bin_accuracies - bin_confidences) * bin_proportions)\n","                        category_results[category_name].append(ece)\n","                        print(f\"{class_name} ECE: {ece}\")\n","\n","                elif dataset_type == \"livebench\":\n","                    for category_name in self.livebench_categories.get(class_name, []):\n","                        # Calculate ECE within the category loop\n","                        bin_confidences = (bins[:-1] + bins[1:]) / 2  # Confidences for each bin\n","                        valid_bins = bin_accuracies.dropna().index  # Bins with data\n","                        bin_accuracies = bin_accuracies[valid_bins]\n","                        bin_proportions = data['bin'].value_counts(normalize=True)[valid_bins]  # Get proportions for valid bins\n","                        bin_confidences = bin_confidences[valid_bins]  # Select confidences for valid bins\n","\n","                        ece = np.sum(np.abs(bin_accuracies - bin_confidences) * bin_proportions)\n","                        category_results[category_name].append(ece)\n","                        print(f\"{class_name} ECE: {ece}\")\n","                        \n","                \n","                print(f\"Processed {class_name}\")\n","\n","        # Calculate average ECE for each category\n","        average_ece_results = {category: np.mean(ece_list) for category, ece_list in category_results.items()}\n","\n","        # Save average ECE results to 'category_results.csv'\n","        average_ece_df = pd.DataFrame({'Category': average_ece_results.keys(), 'Average ECE': average_ece_results.values()})\n","        average_ece_df.to_csv(\"category_results.csv\", index=False)\n","\n","        \n","        # Save BERTScore results for all classes\n","        bertscore_results = {\n","            class_name: {\n","                'precision': results[class_name]['precision'].iloc[0],\n","                'recall': results[class_name]['recall'].iloc[0],\n","                'f1': results[class_name]['f1'].iloc[0]\n","            }\n","            for class_name in results\n","        }\n","        bertscore_df = pd.DataFrame.from_dict(bertscore_results, orient='index')\n","        bertscore_df.to_csv(\"bertscore_results.csv\", index=True)\n","        \n","        # Plot reliability diagram for all classes in one figure\n","        plt.figure(figsize=(10, 6))\n","        plt.plot([0, 1], [0, 1], 'k--', label='Perfectly Calibrated')\n","\n","        # Find the maximum number of bins across all classes\n","        max_bins = max([len(data['bin_accuracies']) for data in reliability_data.values()])\n","\n","        # Pad bin_accuracies with NaN to ensure equal lengths for plotting\n","        for class_name, data in reliability_data.items():\n","            num_missing_bins = max_bins - len(data['bin_accuracies'])\n","            data['bin_accuracies'] = np.pad(data['bin_accuracies'], (0, num_missing_bins), 'constant', constant_values=np.nan)\n","\n","            plt.scatter(data['bin_confidences'][:max_bins], data['bin_accuracies'], label=class_name, s=50)\n","\n","        plt.xlabel('Confidence')\n","        plt.ylabel('Accuracy')\n","        plt.title('Reliability Diagram for All Classes')\n","        plt.legend()\n","        plt.grid(True)\n","        plt.show()\n","\n","    def calculate_ece(self):\n","        if len(self.prompts) == len(self.responses) == len(self.confidences) == len(self.accuracies):\n","            data = pd.DataFrame({\n","                'prompt': self.prompts,\n","                'response': self.responses,\n","                'confidence': self.confidences,\n","                'rating': self.accuracies\n","            })\n","        else:\n","            raise ValueError(\"All arrays must be of the same length\")\n","\n","        data['confidence_normalized'] = data['confidence'] / data['confidence'].max()\n","\n","        bins = np.linspace(0, 1, 11)\n","        data['bin'] = pd.cut(data['confidence_normalized'], bins=bins, labels=False, include_lowest=True)\n","\n","        bin_accuracies = data.groupby('bin')['rating'].mean()\n","        bin_proportions = data['bin'].value_counts(normalize=True)\n","\n","        valid_bins = bin_accuracies.dropna().index\n","        bin_accuracies = bin_accuracies[valid_bins]\n","        bin_proportions = bin_proportions[valid_bins]\n","        bin_confidences = (bins[:-1] + bins[1:]) / 2\n","        bin_confidences = bin_confidences[valid_bins]\n","\n","        bin_confidences = bin_confidences[:len(bin_accuracies)]\n","\n","        ece = np.sum(np.abs(bin_accuracies - bin_confidences) * bin_proportions)\n","        print(f\"Expected Calibration Error (ECE): {ece}\")\n","\n","        return data, bins, bin_accuracies"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T08:33:45.312841Z","iopub.status.busy":"2024-06-28T08:33:45.312425Z","iopub.status.idle":"2024-06-28T08:33:45.317683Z","shell.execute_reply":"2024-06-28T08:33:45.316778Z","shell.execute_reply.started":"2024-06-28T08:33:45.312810Z"},"trusted":true},"outputs":[],"source":["## All Models\n","models = [\n","    {'name': 'Qwen/Qwen2-7B-Instruct'},\n","    {'name': 'stabilityai/StableBeluga-7B'},\n","    {'name': 'meta-llama/Meta-Llama-3-8B'}, \n","    {'name': 'teknium/OpenHermes-2.5-Mistral-7B'}, \n","    {'name': 'mistralai/Mistral-7B-Instruct-v0.2'},  \n","    {'name': 'HuggingFaceH4/zephyr-7b-beta'},\n","]"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T08:34:38.205819Z","iopub.status.busy":"2024-06-28T08:34:38.205365Z","iopub.status.idle":"2024-06-28T09:22:00.503976Z","shell.execute_reply":"2024-06-28T09:22:00.503049Z","shell.execute_reply.started":"2024-06-28T08:34:38.205765Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ca62aef63b594d9e80c82d15c8831c27","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fb81452f654047f4910063459f1d1360","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"09e2cd492dce43f3959672a07bda7ce7","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"854e1d5094dd4768a248c030da8d1fe9","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4fb36814faf541e185eb9de01081cd71","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/663 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dbe5be030ddc45fe9b8ebb08f83cc0a2","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/27.8k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8c16074b1582483487470286e058e8d3","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5094cc5452614eb68c446c8b0c4260b5","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00004.safetensors:   0%|          | 0.00/3.95G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ca9b8475ae344c69e366055123cffd9","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a672de2575ea461986e70c4aed1da82f","version_major":2,"version_minor":0},"text/plain":["model-00003-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"447c492b984a45c387ea9649c6688da1","version_major":2,"version_minor":0},"text/plain":["model-00004-of-00004.safetensors:   0%|          | 0.00/3.56G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ed968d420b42470c99e68976f4d68ca5","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ef0d42a9f1614ecfa4d8769ea5efb170","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/243 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5f8835400a2944caadcbab870145e7c5","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1298ac22ba634f789da2f18cdc589b7e","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e710dc4b7e0941e484b1e48ff57a9bec","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"096bec094d4f4cc0b0cd33f223bdd01f","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d004c3c23bb245d8b3cf3471bfdfbe70","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.17247484624385834, Recall: 0.5036329627037048, F1: 0.25607556104660034\n","Expected Calibration Error (ECE): 0.8827504120944698\n","reasoning ECE: 0.8827504120944698\n","Processed reasoning\n","BERTScore - Precision: 0.3940548002719879, Recall: 0.5945001244544983, F1: 0.4717040956020355\n","Expected Calibration Error (ECE): 0.8229033381304475\n","data_analysis ECE: 0.8229033381304475\n","Processed data_analysis\n","BERTScore - Precision: 0.48737087845802307, Recall: 0.5981023907661438, F1: 0.5363543629646301\n","Expected Calibration Error (ECE): 0.6784741213273181\n","coding ECE: 0.6784741213273181\n","Processed coding\n","BERTScore - Precision: 0.5192601680755615, Recall: 0.7268938422203064, F1: 0.6028556823730469\n","Expected Calibration Error (ECE): 0.7120019634017969\n","math ECE: 0.7120019634017969\n","Processed math\n","BERTScore - Precision: 0.6835563778877258, Recall: 0.8247531056404114, F1: 0.7467145323753357\n","Expected Calibration Error (ECE): 0.4386239308816119\n","language ECE: 0.4386239308816119\n","Processed language\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 1000x600 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["pipeline = EvaluationPipeline(api_key=\"Your_api_key\", judge_model_name=\"llama3-70b-8192\", smaller_model_name=models[0]['name'])\n","pipeline.evaluate_folder(\"/kaggle/working/dev\", dataset_type=\"livebench\", num_questions=50) # if u control question\n","# pipeline.evaluate_folder(\"/kaggle/working/dev\", dataset_type=\"livebench\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["                 "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Chain of thoughts"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T09:31:45.303278Z","iopub.status.busy":"2024-06-28T09:31:45.302431Z","iopub.status.idle":"2024-06-28T09:31:45.309107Z","shell.execute_reply":"2024-06-28T09:31:45.308233Z","shell.execute_reply.started":"2024-06-28T09:31:45.303244Z"},"trusted":true},"outputs":[],"source":["class Tokenizer:\n","    def __init__(self, model_name):\n","        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n","        self.tokenizer.pad_token = self.tokenizer.eos_token\n","\n","    def encode(self, text, max_length=1024):\n","        return self.tokenizer.encode_plus(text, return_tensors='pt', max_length=max_length, truncation=True)\n","\n","    def decode(self, tokens):\n","        return self.tokenizer.decode(tokens, skip_special_tokens=True)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T09:31:46.587352Z","iopub.status.busy":"2024-06-28T09:31:46.587018Z","iopub.status.idle":"2024-06-28T09:31:46.650432Z","shell.execute_reply":"2024-06-28T09:31:46.649596Z","shell.execute_reply.started":"2024-06-28T09:31:46.587326Z"},"trusted":true},"outputs":[],"source":["class EvaluationPipeline:\n","    def __init__(self, api_key, judge_model_name, smaller_model_name, temperature=0.8, max_tokens=300):\n","        self.api_key = api_key\n","        self.judge_model_name = judge_model_name\n","        self.smaller_model_name = smaller_model_name\n","        self.temperature = temperature\n","        self.max_tokens = max_tokens\n","\n","        self.tokenizer = AutoTokenizer.from_pretrained(smaller_model_name)\n","\n","        bnb_config = BitsAndBytesConfig(\n","            load_in_4bit=True,\n","            bnb_4bit_quant_type=\"nf4\",\n","            bnb_4bit_compute_dtype=torch.float16\n","        )\n","\n","        self.main_model = AutoModelForCausalLM.from_pretrained(\n","            smaller_model_name,\n","            torch_dtype=torch.float16,\n","            quantization_config=bnb_config,\n","            low_cpu_mem_usage=True,\n","            device_map=\"auto\",\n","        )\n","\n","        self.mmlu_categories = {\n","            \"abstract_algebra\": [\"math\"],\n","            \"anatomy\": [\"health\"],\n","            \"astronomy\": [\"physics\"],\n","            \"business_ethics\": [\"business\"],\n","            \"clinical_knowledge\": [\"health\"],\n","            \"college_biology\": [\"biology\"],\n","            \"college_chemistry\": [\"chemistry\"],\n","            \"college_computer_science\": [\"computer science\"],\n","            \"college_mathematics\": [\"math\"],\n","            \"college_medicine\": [\"health\"],\n","            \"college_physics\": [\"physics\"],\n","            \"computer_security\": [\"computer science\"],\n","            \"conceptual_physics\": [\"physics\"],\n","            \"econometrics\": [\"economics\"],\n","            \"electrical_engineering\": [\"engineering\"],\n","            \"elementary_mathematics\": [\"math\"],\n","            \"formal_logic\": [\"philosophy\"],\n","            \"global_facts\": [\"other\"],\n","            \"high_school_biology\": [\"biology\"],\n","            \"high_school_chemistry\": [\"chemistry\"],\n","            \"high_school_computer_science\": [\"computer science\"],\n","            \"high_school_european_history\": [\"history\"],\n","            \"high_school_geography\": [\"geography\"],\n","            \"high_school_government_and_politics\": [\"politics\"],\n","            \"high_school_macroeconomics\": [\"economics\"],\n","            \"high_school_mathematics\": [\"math\"],\n","            \"high_school_microeconomics\": [\"economics\"],\n","            \"high_school_physics\": [\"physics\"],\n","            \"high_school_psychology\": [\"psychology\"],\n","            \"high_school_statistics\": [\"math\"],\n","            \"high_school_us_history\": [\"history\"],\n","            \"high_school_world_history\": [\"history\"],\n","            \"human_aging\": [\"health\"],\n","            \"human_sexuality\": [\"culture\"],\n","            \"international_law\": [\"law\"],\n","            \"jurisprudence\": [\"law\"],\n","            \"logical_fallacies\": [\"philosophy\"],\n","            \"machine_learning\": [\"computer science\"],\n","            \"management\": [\"business\"],\n","            \"marketing\": [\"business\"],\n","            \"medical_genetics\": [\"health\"],\n","            \"miscellaneous\": [\"other\"],\n","            \"moral_disputes\": [\"philosophy\"],\n","            \"moral_scenarios\": [\"philosophy\"],\n","            \"nutrition\": [\"health\"],\n","            \"philosophy\": [\"philosophy\"],\n","            \"prehistory\": [\"history\"],\n","            \"professional_accounting\": [\"other\"],\n","            \"professional_law\": [\"law\"],\n","            \"professional_medicine\": [\"health\"],\n","            \"professional_psychology\": [\"psychology\"],\n","            \"public_relations\": [\"politics\"],\n","            \"security_studies\": [\"politics\"],\n","            \"sociology\": [\"culture\"],\n","            \"us_foreign_policy\": [\"politics\"],\n","            \"virology\": [\"health\"],\n","            \"world_religions\": [\"philosophy\"],\n","        }\n","\n","        self.livebench_categories = {\n","            \"data_analysis\": [\"data_analysis\"],\n","            \"coding\": [\"coding\"],\n","            \"language\": [\"language\"],\n","            \"reasoning\": [\"reasoning\"],\n","            \"math\": [\"math\"],\n","        }\n","\n","    def generate_cot_prompt(self, question):\n","        # Chain of Thought prompt\n","        cot_prompt = f\"Q: {question}\\nA: Let's think through this step by step.\\n\"\n","        cot_prompt += \"First, consider the main aspects of the question. \"\n","        cot_prompt += \"Next, break down the problem into smaller parts. \"\n","        cot_prompt += \"Finally, synthesize the information to form a coherent answer.\"\n","        return cot_prompt\n","\n","    def get_model_answer(self, question):\n","        \"\"\"Generates an answer from the specified model using Chain of Thought prompting.\"\"\"\n","        prompt = self.generate_cot_prompt(question)\n","        inputs = self.tokenizer(prompt, return_tensors='pt').to(self.main_model.device)\n","        attention_mask = inputs[\"attention_mask\"] \n","\n","        outputs = self.main_model.generate(\n","            input_ids=inputs[\"input_ids\"], \n","            attention_mask=attention_mask, \n","            max_new_tokens=300,\n","            num_return_sequences=1, \n","            temperature=self.temperature, \n","            output_scores=True, \n","            return_dict_in_generate=True\n","        )\n","#         outputs = self.main_model.generate(\n","#             inputs['input_ids'], \n","#             max_new_tokens=300,  # Limit the number of generated tokens\n","#             num_return_sequences=1, \n","#             temperature=self.temperature, \n","#             output_scores=True, \n","#             return_dict_in_generate=True\n","#         )\n","        response = self.tokenizer.decode(outputs.sequences[0], skip_special_tokens=True)\n","\n","        # Get the confidence score\n","        logits = torch.stack(outputs.scores, dim=1)\n","        probs = F.softmax(logits, dim=-1)\n","\n","        token_ids = outputs.sequences[:, inputs['input_ids'].shape[1]:]\n","        confidences = probs.gather(2, token_ids.unsqueeze(-1)).squeeze(-1).mean(dim=1).detach().cpu().numpy()\n","\n","        avg_confidence = confidences[0]\n","        return response, avg_confidence\n","\n","    def judge_answer(self, response, prompt):\n","        chat_completion = client.chat.completions.create(\n","            messages=[\n","                {\n","                    \"role\": \"user\",\n","                    \"content\": f\"\"\"\n","                        Review the user’s question and the corresponding response using the binary scoring system described below.\n","                        - 0 points: The response is incorrect or does not address the user’s question.\n","                        - 1 point: The response is correct and addresses the user’s question.\n","\n","                        User: {prompt}\n","                        Response: {response}\n","                        \"\"\"\n","                }\n","            ],\n","            model=self.judge_model_name,\n","        )\n","\n","        judge_response = chat_completion.choices[0].message.content.strip()\n","        return judge_response\n","\n","    def parse_evaluation(self, evaluation):\n","        return 1 if \"1 point\" in evaluation else 0\n","\n","    def generate_reference_text(self, prompt):\n","        inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(self.main_model.device)\n","        outputs = self.main_model.generate(\n","            inputs,\n","            max_new_tokens=self.max_tokens,\n","            num_return_sequences=1,\n","            temperature=self.temperature,\n","            do_sample=True\n","        )\n","        reference_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n","        return reference_text\n","\n","\n","    def calculate_bertscore(self, references, candidates):\n","        references = list(references)\n","        candidates = list(candidates)\n","        P, R, F1 = score(candidates, references, lang=\"en\", model_type=\"bert-base-uncased\")\n","        return P.mean().item(), R.mean().item(), F1.mean().item()\n","\n","    def evaluate_from_csv(self, csv_file_path, dataset_type, num_questions=None):\n","        self.prompts = []\n","        self.responses = []\n","        self.references = []\n","        self.confidences = []\n","        self.accuracies = []\n","\n","        df = pd.read_csv(csv_file_path)\n","\n","        if dataset_type == \"mmlu\":\n","            self.prompts = df.iloc[:, 0].tolist()\n","            if num_questions:\n","                self.prompts = self.prompts[:num_questions]\n","                \n","            for prompt in self.prompts:\n","                response, confidence = self.get_model_answer(prompt)\n","                self.responses.append(response)\n","                self.confidences.append(confidence)\n","                reference_text = self.generate_reference_text(prompt)\n","                self.references.append(reference_text)\n","                judgement = self.judge_answer(response, prompt)\n","                accuracy = self.parse_evaluation(judgement)\n","                self.accuracies.append(accuracy)\n","                \n","        elif dataset_type == \"livebench\":\n","            if \"coding\" in csv_file_path:\n","                self.prompts = df[\"turns\"].tolist()\n","                self.references = df[\"solution\"].tolist()\n","            else:\n","                self.prompts = df[\"turns\"].tolist()\n","                self.references = df[\"ground_truth\"].tolist()\n","            \n","            # Filter out rows where \"turns\" has a value but \"ground_truth\"/\"solution\" is empty\n","            self.prompts, self.references = zip(*[\n","                (prompt, reference) for prompt, reference in zip(self.prompts, self.references) \n","                if pd.notna(prompt) and pd.notna(reference)\n","            ])\n","\n","            if num_questions:\n","                self.prompts = self.prompts[:num_questions]\n","                self.references = self.references[:num_questions]\n","\n","            for prompt, reference in zip(self.prompts, self.references):\n","                response, confidence = self.get_model_answer(prompt)\n","                self.responses.append(response)\n","                self.confidences.append(confidence)\n","                 # Calculate similarity\n","#                 similarity = 1 - (edit_distance(response.strip(), reference.strip()) / \n","#                                 max(len(response.strip()), len(reference.strip()))) \n","#                 self.accuracies.append(similarity)\n","                accuracy = 1 if response.strip() == reference.strip() else 0\n","                self.accuracies.append(accuracy)\n","\n","\n","        precision, recall, f1 = self.calculate_bertscore(self.references, self.responses)\n","        print(f\"BERTScore - Precision: {precision}, Recall: {recall}, F1: {f1}\")\n","\n","        data, bins, bin_accuracies = self.calculate_ece()\n","        data.to_csv(\"results.csv\", index=False)\n","        \n","        # Save BERTScore along with ECE results\n","        data['precision'] = precision\n","        data['recall'] = recall\n","        data['f1'] = f1\n","        data.to_csv(\"results.csv\", index=False)\n","        \n","        return data, bins, bin_accuracies\n","\n","#     def evaluate_folder(self, folder_path, dataset_type, num_questions=None):\n","#         results = {}\n","#         reliability_data = {}\n","#         category_results = {category: [] for category in set(cat for sublist in self.mmlu_categories.values() for cat in sublist)}\n","\n","#         if dataset_type == \"livebench\":\n","#             category_results = {category: [] for category in set(cat for sublist in self.livebench_categories.values() for cat in sublist)}\n","\n","#         for filename in os.listdir(folder_path):\n","#             if filename.endswith(\".csv\"):\n","#                 filepath = os.path.join(folder_path, filename)\n","#                 class_name = filename[:-8] \n","#                 data, bins, bin_accuracies = self.evaluate_from_csv(filepath, dataset_type, num_questions)\n","#                 results[class_name] = data\n","        \n","                \n","#                 # Store class-wise data for reliability diagram\n","#                 reliability_data[class_name] = {\n","#                     'bin_confidences': (bins[:-1] + bins[1:]) / 2,\n","#                     'bin_accuracies': bin_accuracies\n","#                 }\n","                \n","#                 if dataset_type == \"mmlu\":\n","#                     for category_name in self.mmlu_categories.get(class_name, []):\n","#                         print(f\"Processed {class_name}\")\n","#                         # Calculate ECE within the category loop\n","#                         bin_confidences = (bins[:-1] + bins[1:]) / 2  # Confidences for each bin\n","#                         valid_bins = bin_accuracies.dropna().index  # Bins with data\n","#                         bin_accuracies = bin_accuracies[valid_bins]\n","#                         bin_proportions = data['bin'].value_counts(normalize=True)[valid_bins]  # Get proportions for valid bins\n","#                         bin_confidences = bin_confidences[valid_bins]  # Select confidences for valid bins\n","\n","#                         ece = np.sum(np.abs(bin_accuracies - bin_confidences) * bin_proportions)\n","#                         category_results[category_name].append(ece)\n","#                         print(f\"{class_name} ECE: {ece}\")\n","\n","#                 elif dataset_type == \"livebench\":\n","#                     for category_name in self.livebench_categories.get(class_name, []):\n","#                         print(f\"Processed {class_name}\")\n","#                         # Calculate ECE within the category loop\n","#                         bin_confidences = (bins[:-1] + bins[1:]) / 2  # Confidences for each bin\n","#                         valid_bins = bin_accuracies.dropna().index  # Bins with data\n","#                         bin_accuracies = bin_accuracies[valid_bins]\n","#                         bin_proportions = data['bin'].value_counts(normalize=True)[valid_bins]  # Get proportions for valid bins\n","#                         bin_confidences = bin_confidences[valid_bins]  # Select confidences for valid bins\n","\n","#                         ece = np.sum(np.abs(bin_accuracies - bin_confidences) * bin_proportions)\n","#                         category_results[category_name].append(ece)\n","#                         print(f\"{class_name} ECE: {ece}\")\n","                        \n","\n","#         # Calculate average ECE for each category\n","#         average_ece_results = {category: np.mean(ece_list) for category, ece_list in category_results.items()}\n","\n","#         # Save average ECE results to 'category_results.csv'\n","#         average_ece_df = pd.DataFrame({'Category': average_ece_results.keys(), 'Average ECE': average_ece_results.values()})\n","#         average_ece_df.to_csv(\"category_results.csv\", index=False)\n","\n","        \n","#         # Save BERTScore results for all classes\n","#         bertscore_results = {\n","#             class_name: {\n","#                 'precision': results[class_name]['precision'].iloc[0],\n","#                 'recall': results[class_name]['recall'].iloc[0],\n","#                 'f1': results[class_name]['f1'].iloc[0]\n","#             }\n","#             for class_name in results\n","#         }\n","#         bertscore_df = pd.DataFrame.from_dict(bertscore_results, orient='index')\n","#         bertscore_df.to_csv(\"bertscore_results.csv\", index=True)\n","        \n","#         # Plot reliability diagram for all classes in one figure\n","#         plt.figure(figsize=(10, 6))\n","#         plt.plot([0, 1], [0, 1], 'k--', label='Perfectly Calibrated')\n","\n","#         # Find the maximum number of bins across all classes\n","#         max_bins = max([len(data['bin_accuracies']) for data in reliability_data.values()])\n","\n","#         # Pad bin_accuracies with NaN to ensure equal lengths for plotting\n","#         for class_name, data in reliability_data.items():\n","#             num_missing_bins = max_bins - len(data['bin_accuracies'])\n","#             data['bin_accuracies'] = np.pad(data['bin_accuracies'], (0, num_missing_bins), 'constant', constant_values=np.nan)\n","\n","#             plt.scatter(data['bin_confidences'][:max_bins], data['bin_accuracies'], label=class_name, s=50)\n","\n","#         plt.xlabel('Confidence')\n","#         plt.ylabel('Accuracy')\n","#         plt.title('Reliability Diagram for All Classes')\n","#         plt.legend()\n","#         plt.grid(True)\n","#         plt.show()\n","\n","    def evaluate_folder(self, folder_path, dataset_type, num_questions=None):\n","        results = {}\n","        reliability_data = {}\n","        category_results = {category: [] for category in set(cat for sublist in self.livebench_categories.values() for cat in sublist)}\n","\n","        color_map = {\n","            \"data_analysis\": 'blue',\n","            \"coding\": 'green',\n","            \"language\": 'orange',\n","            \"reasoning\": 'red',\n","            \"math\": 'purple',\n","        }\n","\n","        for filename in os.listdir(folder_path):\n","            if filename.endswith(\".csv\"):\n","                filepath = os.path.join(folder_path, filename)\n","                class_name = filename[:-8] \n","                data, bins, bin_accuracies = self.evaluate_from_csv(filepath, dataset_type, num_questions)\n","                results[class_name] = data\n","\n","                # Store class-wise data for reliability diagram\n","                reliability_data[class_name] = {\n","                    'bin_confidences': (bins[:-1] + bins[1:]) / 2,\n","                    'bin_accuracies': bin_accuracies\n","                }\n","\n","                for category_name in self.livebench_categories.get(class_name, []):\n","                    bin_confidences = (bins[:-1] + bins[1:]) / 2\n","                    valid_bins = bin_accuracies.dropna().index\n","                    bin_accuracies = bin_accuracies[valid_bins]\n","                    bin_proportions = data['bin'].value_counts(normalize=True)[valid_bins]\n","                    bin_confidences = bin_confidences[valid_bins]\n","\n","                    ece = np.sum(np.abs(bin_accuracies - bin_confidences) * bin_proportions)\n","                    category_results[category_name].append(ece)\n","                    print(f\"{class_name} ECE: {ece}\")\n","\n","                print(f\"Processed {class_name}\")\n","\n","        # Calculate average ECE for each category\n","        average_ece_results = {category: np.mean(ece_list) for category, ece_list in category_results.items()}\n","\n","        # Save average ECE results to 'category_results.csv'\n","        average_ece_df = pd.DataFrame({'Category': average_ece_results.keys(), 'Average ECE': average_ece_results.values()})\n","        average_ece_df.to_csv(\"Qwen2-7B_bertscore_results_cot.csv\", index=False)\n","\n","        # Save BERTScore results for all classes\n","        bertscore_results = {\n","            class_name: {\n","                'precision': results[class_name]['precision'].iloc[0],\n","                'recall': results[class_name]['recall'].iloc[0],\n","                'f1': results[class_name]['f1'].iloc[0]\n","            }\n","            for class_name in results\n","        }\n","        bertscore_df = pd.DataFrame.from_dict(bertscore_results, orient='index')\n","        bertscore_df.to_csv(\"Qwen2-7B_ece_results_cot.csv\", index=True)\n","\n","        # Plot reliability diagram for all classes in one figure\n","        plt.figure(figsize=(10, 6))\n","        plt.plot([0, 1], [0, 1], 'k--', label='Perfectly Calibrated')\n","\n","        # Find the maximum number of bins across all classes\n","        max_bins = max([len(data['bin_accuracies']) for data in reliability_data.values()])\n","\n","        # Pad bin_accuracies with NaN to ensure equal lengths for plotting\n","        for class_name, data in reliability_data.items():\n","            num_missing_bins = max_bins - len(data['bin_accuracies'])\n","            data['bin_accuracies'] = np.pad(data['bin_accuracies'], (0, num_missing_bins), 'constant', constant_values=np.nan)\n","\n","            for category_name in self.livebench_categories.get(class_name, []):\n","                plt.scatter(data['bin_confidences'][:max_bins], data['bin_accuracies'], label=category_name, s=50, color=color_map[category_name])\n","\n","        plt.xlabel('Confidence')\n","        plt.ylabel('Accuracy')\n","        plt.title('Reliability Diagram for All Classes')\n","        plt.legend()\n","        plt.grid(True)\n","        plt.show()\n","\n","\n","    def calculate_ece(self):\n","        if len(self.prompts) == len(self.responses) == len(self.confidences) == len(self.accuracies):\n","            data = pd.DataFrame({\n","                'prompt': self.prompts,\n","                'response': self.responses,\n","                'confidence': self.confidences,\n","                'rating': self.accuracies\n","            })\n","        else:\n","            raise ValueError(\"All arrays must be of the same length\")\n","\n","        data['confidence_normalized'] = data['confidence'] / data['confidence'].max()\n","\n","        bins = np.linspace(0, 1, 11)\n","        data['bin'] = pd.cut(data['confidence_normalized'], bins=bins, labels=False, include_lowest=True)\n","\n","        bin_accuracies = data.groupby('bin')['rating'].mean()\n","        bin_proportions = data['bin'].value_counts(normalize=True)\n","\n","        valid_bins = bin_accuracies.dropna().index\n","        bin_accuracies = bin_accuracies[valid_bins]\n","        bin_proportions = bin_proportions[valid_bins]\n","        bin_confidences = (bins[:-1] + bins[1:]) / 2\n","        bin_confidences = bin_confidences[valid_bins]\n","\n","        bin_confidences = bin_confidences[:len(bin_accuracies)]\n","\n","        ece = np.sum(np.abs(bin_accuracies - bin_confidences) * bin_proportions)\n","        print(f\"Expected Calibration Error (ECE): {ece}\")\n","\n","        return data, bins, bin_accuracies"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T09:31:47.755621Z","iopub.status.busy":"2024-06-28T09:31:47.754825Z","iopub.status.idle":"2024-06-28T09:31:47.760552Z","shell.execute_reply":"2024-06-28T09:31:47.759460Z","shell.execute_reply.started":"2024-06-28T09:31:47.755587Z"},"trusted":true},"outputs":[],"source":["## All Models\n","models = [\n","    {'name': 'Qwen/Qwen2-7B-Instruct'},\n","    {'name': 'stabilityai/StableBeluga-7B'},\n","    {'name': 'meta-llama/Meta-Llama-3-8B'}, \n","    {'name': 'teknium/OpenHermes-2.5-Mistral-7B'}, \n","    {'name': 'mistralai/Mistral-7B-Instruct-v0.2'},  \n","    {'name': 'HuggingFaceH4/zephyr-7b-beta'},\n","]"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T09:31:57.915939Z","iopub.status.busy":"2024-06-28T09:31:57.915095Z","iopub.status.idle":"2024-06-28T10:49:36.285823Z","shell.execute_reply":"2024-06-28T10:49:36.284819Z","shell.execute_reply.started":"2024-06-28T09:31:57.915901Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f377c05f207f41cea3969b42c1e0926b","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c36ca1ff28ff4679b676fd9ed16c9017","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0490c73f277f4a3fbd54428b58d7192a","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1592669a0d4046b7b049c34b6c6edaef","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"386ce81e43774d148d05d2abdea1581c","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/663 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5bfca1829b654f338949c86b8f048ab7","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/27.8k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a37d4327af8f4a31aeb3251dbd795702","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7f7b1d546e084341b9d9e3ee076e2f04","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00004.safetensors:   0%|          | 0.00/3.95G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"17d7b54e65ed4d4aa78542f2cc71c82b","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4592108736e94e4b926c733143a1fdee","version_major":2,"version_minor":0},"text/plain":["model-00003-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"babe69a2aadf49bb9a29bdcd96b88c5e","version_major":2,"version_minor":0},"text/plain":["model-00004-of-00004.safetensors:   0%|          | 0.00/3.56G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5eac228052f6402e99cc68b31c544f68","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"91954f0b984f4a578715a0ff6b65b5fa","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/243 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d94cefdb42ac42b7a52a1ca2bf588736","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"407cbc0e4f694e7386e17d6afeb6a866","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"83a4edc815984433981cf41cfcf56860","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"02f4d391f2dc4e809dce2c46229d78b0","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"634bc91094f04ef3b3c341ef38b16bd7","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BERTScore - Precision: 0.39285287261009216, Recall: 0.5916721224784851, F1: 0.46993568539619446\n","Expected Calibration Error (ECE): 0.8360000000000001\n","data_analysis ECE: 0.8360000000000001\n","Processed data_analysis\n","BERTScore - Precision: 0.6281354427337646, Recall: 0.8008145093917847, F1: 0.7033200263977051\n","Expected Calibration Error (ECE): 0.914\n","language ECE: 0.914\n","Processed language\n","BERTScore - Precision: 0.4878220856189728, Recall: 0.598223865032196, F1: 0.5367031097412109\n","Expected Calibration Error (ECE): 0.8552631578947368\n","coding ECE: 0.8552631578947368\n","Processed coding\n","BERTScore - Precision: 0.45353275537490845, Recall: 0.7150701284408569, F1: 0.5529400706291199\n","Expected Calibration Error (ECE): 0.922\n","math ECE: 0.922\n","Processed math\n","BERTScore - Precision: 0.16611848771572113, Recall: 0.4615837335586548, F1: 0.24311359226703644\n","Expected Calibration Error (ECE): 0.862\n","reasoning ECE: 0.862\n","Processed reasoning\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 1000x600 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["    # Example usage\n","pipeline = EvaluationPipeline(api_key=\"Your_api_key\", judge_model_name=\"llama3-70b-8192\", smaller_model_name=models[0]['name'])\n","pipeline.evaluate_folder(\"/kaggle/working/dev\", dataset_type=\"livebench\", num_questions=50) # if u control question\n","# pipeline.evaluate_folder(\"/kaggle/working/dev\", dataset_type=\"livebench\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["    "]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
