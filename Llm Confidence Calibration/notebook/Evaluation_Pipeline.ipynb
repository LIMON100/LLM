{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30732,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f92394e92af443199dc4a458db76a816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ef269eface047e981cb51a6fb9c9318",
              "IPY_MODEL_4f95693e95be4736bd89b71c02a12e85",
              "IPY_MODEL_34dbe46e47de47f7af5c4c2eb2cccf55",
              "IPY_MODEL_bd112e02942c43b3877a7d93dc4dda22"
            ],
            "layout": "IPY_MODEL_82fb80b0d7da41e586161b0199bfbbed"
          }
        },
        "9c9ed543e4244b3095912a3911437ac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a38e973028040c2b035edf28d6048aa",
            "placeholder": "​",
            "style": "IPY_MODEL_f4aac2c9b92e41a2adb9f0bb41c7d2a8",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "ae149e1f9d194cf384ced62b079a3019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_f93b1df496ae4e688bce6e54478431fa",
            "placeholder": "​",
            "style": "IPY_MODEL_da785a051ced48cd917e7d3651f424d2",
            "value": ""
          }
        },
        "999c7db0810848a2904b6f1e7235a1eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_88bdcfb352bc41d2897f5d434e88f9dd",
            "style": "IPY_MODEL_e057bb6e7a9649739045f859137ec8d6",
            "value": true
          }
        },
        "b4fd93efed414d039cb0788e7c1513ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_283928aa38af4fee89ffdcdb093ca464",
            "style": "IPY_MODEL_27755788428e4b6abbb9d9d23b28127f",
            "tooltip": ""
          }
        },
        "8f0d0696f4aa47ebbd6ef8e5c7ee5468": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42bed8a3fbb543039179976f3f1389c0",
            "placeholder": "​",
            "style": "IPY_MODEL_0d393862c0c540bc86438197cbca9ddc",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "82fb80b0d7da41e586161b0199bfbbed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "0a38e973028040c2b035edf28d6048aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4aac2c9b92e41a2adb9f0bb41c7d2a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f93b1df496ae4e688bce6e54478431fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da785a051ced48cd917e7d3651f424d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88bdcfb352bc41d2897f5d434e88f9dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e057bb6e7a9649739045f859137ec8d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "283928aa38af4fee89ffdcdb093ca464": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27755788428e4b6abbb9d9d23b28127f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "42bed8a3fbb543039179976f3f1389c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d393862c0c540bc86438197cbca9ddc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa95e4660e3843b5945584b80df19718": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_948363734948470aa3f580ccabe1d72e",
            "placeholder": "​",
            "style": "IPY_MODEL_a8d4b542a3634dab91f3cfc24bb8b06c",
            "value": "Connecting..."
          }
        },
        "948363734948470aa3f580ccabe1d72e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8d4b542a3634dab91f3cfc24bb8b06c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ef269eface047e981cb51a6fb9c9318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24907f5370a6499eaf62eb11379f6dcf",
            "placeholder": "​",
            "style": "IPY_MODEL_8335a434a1db4efc9dfeb8f0a1fc6221",
            "value": "Token is valid (permission: read)."
          }
        },
        "4f95693e95be4736bd89b71c02a12e85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d453cdc7db894c71be014ad0f47b92a1",
            "placeholder": "​",
            "style": "IPY_MODEL_f1985037a8ee4afe8a096ce80b07e60a",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "34dbe46e47de47f7af5c4c2eb2cccf55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b17d16b6fbf4765929a63ca27adfa39",
            "placeholder": "​",
            "style": "IPY_MODEL_0b168f4846cf45bea6f5288afab48a3e",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "bd112e02942c43b3877a7d93dc4dda22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78d6f6c7c5034efb8dc6ac83c4c38041",
            "placeholder": "​",
            "style": "IPY_MODEL_45b48220e82f45fba5c73cdd790a6179",
            "value": "Login successful"
          }
        },
        "24907f5370a6499eaf62eb11379f6dcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8335a434a1db4efc9dfeb8f0a1fc6221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d453cdc7db894c71be014ad0f47b92a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1985037a8ee4afe8a096ce80b07e60a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b17d16b6fbf4765929a63ca27adfa39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b168f4846cf45bea6f5288afab48a3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78d6f6c7c5034efb8dc6ac83c4c38041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45b48220e82f45fba5c73cdd790a6179": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47523e87365743d8b23899634cc66d8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b4f185f923a4fa2885b3fad46b39b54",
              "IPY_MODEL_ea68a14b2dc249adbd954233d532d795",
              "IPY_MODEL_811e32513c21430a98e887ec83c3ef31"
            ],
            "layout": "IPY_MODEL_bbfeaa0bc2014811bfe3cef60c6c8807"
          }
        },
        "7b4f185f923a4fa2885b3fad46b39b54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80c5f20efdea49d9b56441308d9e245c",
            "placeholder": "​",
            "style": "IPY_MODEL_57ddcab09fa240da993ed9c37388f7b7",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "ea68a14b2dc249adbd954233d532d795": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c508f09eaf24518b402797a61f4530a",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa9670561ec847cf8e2745616113eb5e",
            "value": 3
          }
        },
        "811e32513c21430a98e887ec83c3ef31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0c55c6884ad4e29b5febba2ab385188",
            "placeholder": "​",
            "style": "IPY_MODEL_dd5d17e68db34d478e0d68cb75ab6ed0",
            "value": " 3/3 [01:13&lt;00:00, 24.51s/it]"
          }
        },
        "bbfeaa0bc2014811bfe3cef60c6c8807": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80c5f20efdea49d9b56441308d9e245c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57ddcab09fa240da993ed9c37388f7b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c508f09eaf24518b402797a61f4530a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa9670561ec847cf8e2745616113eb5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0c55c6884ad4e29b5febba2ab385188": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd5d17e68db34d478e0d68cb75ab6ed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z52TYrKA47O",
        "outputId": "639e0262-d783-4239-c389-91ec80f02fdc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers bitsandbytes sentencepiece accelerate guidance --upgrade -qq"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-06-05T11:05:24.497843Z",
          "iopub.execute_input": "2024-06-05T11:05:24.498654Z",
          "iopub.status.idle": "2024-06-05T11:05:47.887601Z",
          "shell.execute_reply.started": "2024-06-05T11:05:24.498618Z",
          "shell.execute_reply": "2024-06-05T11:05:47.886086Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYzzxW1Q-WzP",
        "outputId": "1f692435-e158-4e72-9bec-297c40e5751b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.7/239.7 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m912.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-05T11:05:47.889917Z",
          "iopub.execute_input": "2024-06-05T11:05:47.890309Z",
          "iopub.status.idle": "2024-06-05T11:05:48.308209Z",
          "shell.execute_reply.started": "2024-06-05T11:05:47.890270Z",
          "shell.execute_reply": "2024-06-05T11:05:48.307154Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "f92394e92af443199dc4a458db76a816",
            "9c9ed543e4244b3095912a3911437ac8",
            "ae149e1f9d194cf384ced62b079a3019",
            "999c7db0810848a2904b6f1e7235a1eb",
            "b4fd93efed414d039cb0788e7c1513ac",
            "8f0d0696f4aa47ebbd6ef8e5c7ee5468",
            "82fb80b0d7da41e586161b0199bfbbed",
            "0a38e973028040c2b035edf28d6048aa",
            "f4aac2c9b92e41a2adb9f0bb41c7d2a8",
            "f93b1df496ae4e688bce6e54478431fa",
            "da785a051ced48cd917e7d3651f424d2",
            "88bdcfb352bc41d2897f5d434e88f9dd",
            "e057bb6e7a9649739045f859137ec8d6",
            "283928aa38af4fee89ffdcdb093ca464",
            "27755788428e4b6abbb9d9d23b28127f",
            "42bed8a3fbb543039179976f3f1389c0",
            "0d393862c0c540bc86438197cbca9ddc",
            "aa95e4660e3843b5945584b80df19718",
            "948363734948470aa3f580ccabe1d72e",
            "a8d4b542a3634dab91f3cfc24bb8b06c",
            "4ef269eface047e981cb51a6fb9c9318",
            "4f95693e95be4736bd89b71c02a12e85",
            "34dbe46e47de47f7af5c4c2eb2cccf55",
            "bd112e02942c43b3877a7d93dc4dda22",
            "24907f5370a6499eaf62eb11379f6dcf",
            "8335a434a1db4efc9dfeb8f0a1fc6221",
            "d453cdc7db894c71be014ad0f47b92a1",
            "f1985037a8ee4afe8a096ce80b07e60a",
            "8b17d16b6fbf4765929a63ca27adfa39",
            "0b168f4846cf45bea6f5288afab48a3e",
            "78d6f6c7c5034efb8dc6ac83c4c38041",
            "45b48220e82f45fba5c73cdd790a6179"
          ]
        },
        "id": "wcznS5vo-WzS",
        "outputId": "e87ad556-523f-4641-d7c2-a5cb1edcc563"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f92394e92af443199dc4a458db76a816"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers -qq\n",
        "!pip install accelerate\n",
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-05T09:33:05.374758Z",
          "iopub.execute_input": "2024-06-05T09:33:05.375161Z",
          "iopub.status.idle": "2024-06-05T09:33:44.194784Z",
          "shell.execute_reply.started": "2024-06-05T09:33:05.375129Z",
          "shell.execute_reply": "2024-06-05T09:33:44.193476Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qo4pxmSL-WzT",
        "outputId": "9e231b74-2286-403f-c791-15bae37493da"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.5.40)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://people.eecs.berkeley.edu/~hendrycks/data.tar"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-05T09:33:44.197242Z",
          "iopub.execute_input": "2024-06-05T09:33:44.198087Z",
          "iopub.status.idle": "2024-06-05T09:33:48.046593Z",
          "shell.execute_reply.started": "2024-06-05T09:33:44.198016Z",
          "shell.execute_reply": "2024-06-05T09:33:48.045706Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwGOkAYS-WzU",
        "outputId": "255cf97d-2e35-4587-c9e0-49880676c2fd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-06 10:06:45--  https://people.eecs.berkeley.edu/~hendrycks/data.tar\n",
            "Resolving people.eecs.berkeley.edu (people.eecs.berkeley.edu)... 128.32.244.190\n",
            "Connecting to people.eecs.berkeley.edu (people.eecs.berkeley.edu)|128.32.244.190|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 166184960 (158M) [application/x-tar]\n",
            "Saving to: ‘data.tar’\n",
            "\n",
            "data.tar            100%[===================>] 158.49M  96.2MB/s    in 1.6s    \n",
            "\n",
            "2024-06-06 10:06:46 (96.2 MB/s) - ‘data.tar’ saved [166184960/166184960]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "unzip_path = '.'\n",
        "tar = tarfile.open('data.tar')\n",
        "tar.extractall(path=unzip_path)\n",
        "tar.close()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-05T09:33:48.047910Z",
          "iopub.execute_input": "2024-06-05T09:33:48.048233Z",
          "iopub.status.idle": "2024-06-05T09:33:48.297373Z",
          "shell.execute_reply.started": "2024-06-05T09:33:48.048202Z",
          "shell.execute_reply": "2024-06-05T09:33:48.296609Z"
        },
        "trusted": true,
        "id": "2cThr7vx-WzU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers -qq\n",
        "!pip install accelerate\n",
        "!pip install groq\n",
        "!pip install bert_score"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-05T09:33:48.299805Z",
          "iopub.execute_input": "2024-06-05T09:33:48.300133Z",
          "iopub.status.idle": "2024-06-05T09:34:40.316908Z",
          "shell.execute_reply.started": "2024-06-05T09:33:48.300108Z",
          "shell.execute_reply": "2024-06-05T09:34:40.315707Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FbkxJNw-WzU",
        "outputId": "a29e7383-16d3-4633-eb42-ee1ae881ecbd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.5.40)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Collecting groq\n",
            "  Downloading groq-0.8.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from groq)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.7.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, groq\n",
            "Successfully installed groq-0.8.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0\n",
            "Collecting bert_score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.3.0+cu121)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.0.3)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.41.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert_score) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.66.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert_score) (3.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert_score) (24.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2024.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0.0->bert_score) (12.5.40)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.4.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2024.6.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\n",
            "Installing collected packages: bert_score\n",
            "Successfully installed bert_score-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification, pipeline\n",
        "from transformers import BitsAndBytesConfig\n",
        "import torch.nn.functional as F\n",
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pathlib\n",
        "import textwrap\n",
        "import google.generativeai as genai\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "import google.generativeai as genai\n",
        "from bert_score import score\n",
        "import os\n",
        "from groq import Groq\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import json\n",
        "import re\n",
        "import concurrent.futures\n",
        "from tqdm import tqdm\n",
        "from yaml import safe_load"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-05T09:34:40.318531Z",
          "iopub.execute_input": "2024-06-05T09:34:40.318896Z",
          "iopub.status.idle": "2024-06-05T09:35:00.740776Z",
          "shell.execute_reply.started": "2024-06-05T09:34:40.318857Z",
          "shell.execute_reply": "2024-06-05T09:35:00.739995Z"
        },
        "trusted": true,
        "id": "uRSM1Sf8-WzV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-05T09:35:00.741908Z",
          "iopub.execute_input": "2024-06-05T09:35:00.742470Z",
          "iopub.status.idle": "2024-06-05T09:35:00.910424Z",
          "shell.execute_reply.started": "2024-06-05T09:35:00.742444Z",
          "shell.execute_reply": "2024-06-05T09:35:00.909539Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6c4ux4b-WzW",
        "outputId": "a9faa7bf-7d19-4875-c4bc-cd641aed0d05"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define models and tokenizers\n",
        "# model_name = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
        "# tokenizer_mistral = AutoTokenizer.from_pretrained(model_name)\n",
        "# tokenizer_mistral.pad_token = tokenizer_mistral.eos_token\n",
        "\n",
        "# bnb_config = BitsAndBytesConfig(\n",
        "#     load_in_4bit=True,\n",
        "#     bnb_4bit_quant_type=\"nf4\",\n",
        "#     bnb_4bit_compute_dtype=torch.float16\n",
        "# )\n",
        "\n",
        "# mistral_model = AutoModelForCausalLM.from_pretrained(\n",
        "#     model_name,\n",
        "#     torch_dtype=torch.float16,\n",
        "#     quantization_config=bnb_config,\n",
        "#     low_cpu_mem_usage=True,\n",
        "#     device_map=\"auto\",\n",
        "# )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-05T09:35:00.911658Z",
          "iopub.execute_input": "2024-06-05T09:35:00.912005Z",
          "iopub.status.idle": "2024-06-05T09:36:45.463029Z",
          "shell.execute_reply.started": "2024-06-05T09:35:00.911973Z",
          "shell.execute_reply": "2024-06-05T09:36:45.462096Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "1c9bfeb5ecfe4f02b03323b127130e92",
            "a457366db08c4a30a7c02ba38fe3fb69",
            "9e703fbcd56041c5bd256836e00984bf",
            "b786d682bbb74fbd8fc0e29c789d8aa7",
            "06fa731d287b4ff29c86e930a983ccd7",
            "70d80319f6164f88a15f3e394e959eda",
            "8b144d1fdc804adea2b2e920a34d6234",
            "971e7882d17c42cd94dccb8d820e9cca",
            "fd6fa6519a684e6a82993a7e702e6933",
            "443da628f47c49a7a46973ace18daa8f",
            "7b5564399e1f40a0a4075a0fdb66d313",
            "dcb979a43eb54f6bb96074c597545fd6"
          ]
        },
        "id": "iJkTRlBf-WzW",
        "outputId": "899944cd-3730-4a36-dde9-5813f5e56ed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c9bfeb5ecfe4f02b03323b127130e92"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a457366db08c4a30a7c02ba38fe3fb69"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e703fbcd56041c5bd256836e00984bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b786d682bbb74fbd8fc0e29c789d8aa7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06fa731d287b4ff29c86e930a983ccd7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70d80319f6164f88a15f3e394e959eda"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b144d1fdc804adea2b2e920a34d6234"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "971e7882d17c42cd94dccb8d820e9cca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd6fa6519a684e6a82993a7e702e6933"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "443da628f47c49a7a46973ace18daa8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b5564399e1f40a0a4075a0fdb66d313"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dcb979a43eb54f6bb96074c597545fd6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_name2 = 'stabilityai/StableBeluga-13B'\n",
        "# tokenizer_beluga = AutoTokenizer.from_pretrained(model_name2)\n",
        "# tokenizer_beluga.pad_token = tokenizer_beluga.eos_token\n",
        "\n",
        "# beluga_model = AutoModelForCausalLM.from_pretrained(\n",
        "#     model_name2,\n",
        "#     torch_dtype=torch.float16,\n",
        "#     quantization_config=bnb_config,\n",
        "#     low_cpu_mem_usage=True,\n",
        "#     device_map=\"auto\",\n",
        "# )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-05T09:36:45.464789Z",
          "iopub.execute_input": "2024-06-05T09:36:45.465293Z",
          "iopub.status.idle": "2024-06-05T09:36:45.470113Z",
          "shell.execute_reply.started": "2024-06-05T09:36:45.465259Z",
          "shell.execute_reply": "2024-06-05T09:36:45.469165Z"
        },
        "trusted": true,
        "id": "Akq-vRPp-WzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
        "    return ' '.join(filtered_tokens)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-05T09:36:45.471675Z",
          "iopub.execute_input": "2024-06-05T09:36:45.471972Z",
          "iopub.status.idle": "2024-06-05T09:36:45.480944Z",
          "shell.execute_reply.started": "2024-06-05T09:36:45.471922Z",
          "shell.execute_reply": "2024-06-05T09:36:45.480004Z"
        },
        "trusted": true,
        "id": "uW8MDFV2-WzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility functions\n",
        "def load_questions(file_path):\n",
        "    questions = []\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            questions.append(json.loads(line.strip()))\n",
        "    return questions\n",
        "\n",
        "def load_model_answers(dir_path):\n",
        "    model_answers = {}\n",
        "    for file_name in os.listdir(dir_path):\n",
        "        model_name = file_name.split('.')[0]\n",
        "        model_answers[model_name] = {}\n",
        "        with open(os.path.join(dir_path, file_name), 'r') as f:\n",
        "            for line in f:\n",
        "                answer = json.loads(line.strip())\n",
        "                question_id = answer['question_id']\n",
        "                model_answers[model_name][question_id] = answer\n",
        "    return model_answers\n",
        "\n",
        "def get_endpoint(endpoint_config):\n",
        "    # Implementation depends on the format of your API config file\n",
        "    return endpoint_config\n",
        "\n",
        "def make_config(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        return safe_load(f)\n",
        "\n",
        "def chat_completion_groq(model, conv, temperature, max_tokens, api_key):\n",
        "    client = Groq(api_key=api_key)\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=conv,\n",
        "        model=model,\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens,\n",
        "    )\n",
        "    return chat_completion.choices[0].message.content\n",
        "\n",
        "def get_score(judgment, pattern, pairwise=True):\n",
        "    matches = pattern.findall(judgment)\n",
        "    matches = [m for m in matches if m != \"\"]\n",
        "    if len(set(matches)) == 0:\n",
        "        return None, True\n",
        "    elif len(set(matches)) == 1:\n",
        "        if pairwise:\n",
        "            return matches[0].strip(\"\\n\"), False\n",
        "        return int(matches[0])\n",
        "    else:\n",
        "        return None, False"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-05T09:36:45.483928Z",
          "iopub.execute_input": "2024-06-05T09:36:45.484272Z",
          "iopub.status.idle": "2024-06-05T09:36:45.497345Z",
          "shell.execute_reply.started": "2024-06-05T09:36:45.484248Z",
          "shell.execute_reply": "2024-06-05T09:36:45.496406Z"
        },
        "trusted": true,
        "id": "NXDPgSPj-WzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = Groq(api_key=\"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\")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"What is the meaning of life? How modern Ai is affeting the real life and what will be the Ai outcomes in future?\",\n",
        "        }\n",
        "\n",
        "    ],\n",
        "    model=\"llama3-70b-8192\",\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-05T09:38:07.945081Z",
          "iopub.execute_input": "2024-06-05T09:38:07.945782Z",
          "iopub.status.idle": "2024-06-05T09:38:10.547813Z",
          "shell.execute_reply.started": "2024-06-05T09:38:07.945752Z",
          "shell.execute_reply": "2024-06-05T09:38:10.546851Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRRChIbh-WzX",
        "outputId": "b0ceabb4-2901-4d67-c0f7-646035927e2d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**What is the meaning of life?**\n",
            "\n",
            "The question of the meaning of life is a timeless and deeply philosophical conundrum that has puzzled thinkers, scholars, and everyday humans for centuries. The answer, unfortunately, is not straightforward, and it's a topic of ongoing debate.\n",
            "\n",
            "There are many theories, beliefs, and perspectives on the meaning of life. Here are a few:\n",
            "\n",
            "1. **Religious and spiritual:** Many believe that the meaning of life is to fulfill a divine purpose, follow a higher power's will, or achieve spiritual enlightenment.\n",
            "2. **Existentialism:** This philosophy proposes that life has no inherent meaning, and it's up to each individual to create their own purpose and meaning.\n",
            "3. **Hedonism:** Some argue that the purpose of life is to seek pleasure, happiness, and personal fulfillment.\n",
            "4. **Eudaimonic:** This concept, rooted in Aristotelian philosophy, suggests that the meaning of life is to live a virtuous, flourishing life, cultivating one's character and achieving happiness through personal growth.\n",
            "5. **Biological and evolutionary:** From a biological perspective, the meaning of life might be to survive, reproduce, and ensure the continuation of one's genes.\n",
            "\n",
            "Ultimately, the meaning of life is a deeply personal and subjective question, and each individual's answer will vary.\n",
            "\n",
            "**How modern AI is affecting real life:**\n",
            "\n",
            "Artificial intelligence (AI) is rapidly transforming many aspects of modern life, from how we work and communicate to how we shop, travel, and interact with each other. Here are some ways AI is impacting our daily lives:\n",
            "\n",
            "1. **Automation and job displacement:** AI is increasingly taking over repetitive, mundane, and certain cognitive tasks, which can lead to job displacement in certain sectors.\n",
            "2. **Enhanced customer experience:** AI-powered chatbots, virtual assistants, and recommendation systems improve customer service, personalize experiences, and streamline interactions.\n",
            "3. **Healthcare and medicine:** AI is being used in medical diagnosis, disease detection, and personalized medicine, leading to more accurate diagnoses and better health outcomes.\n",
            "4. **Transportation and logistics:** AI is optimizing routes, schedules, and supply chains, making transportation more efficient, reducing congestion, and improving delivery times.\n",
            "5. **Cybersecurity:** AI-powered systems detect and respond to cyber threats, protecting individuals and organizations from attacks.\n",
            "\n",
            "**Future outcomes of AI:**\n",
            "\n",
            "As AI continues to evolve, we can expect to see significant advancements in various fields. Here are some potential outcomes:\n",
            "\n",
            "1. **Increased productivity:** AI will automate more tasks, freeing humans to focus on creative, high-value work.\n",
            "2. **Improved decision-making:** AI will analyze vast amounts of data, providing insights that inform better decision-making in various industries.\n",
            "3. **Enhanced education:** AI-powered adaptive learning systems will personalize education, making it more effective and accessible.\n",
            "4. **Advanced healthcare:** AI will lead to breakthroughs in medical research, disease prevention, and personalized treatment plans.\n",
            "5. **Job creation:** While AI may displace some jobs, it will also create new ones, such as AI developer, data analyst, and AI ethicist.\n",
            "\n",
            "However, there are also potential challenges and risks associated with AI, including:\n",
            "\n",
            "1. **Job displacement and inequality:** AI could exacerbate income inequality and lead to significant job losses.\n",
            "2. ** Bias and discrimination:** AI systems can perpetuate biases if they're trained on biased data, leading to unfair outcomes.\n",
            "3. **Privacy and security:** AI systems can be vulnerable to cyber attacks, and personal data may be compromised.\n",
            "4. **Autonomous decision-making:** AI systems may make decisions that are difficult to understand or challenge, leading to accountability issues.\n",
            "\n",
            "Ultimately, the future of AI will depend on how we choose to develop, deploy, and regulate these technologies.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pipeline"
      ],
      "metadata": {
        "id": "SGzhykyw-WzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EvaluationPipeline:\n",
        "    def __init__(self, api_key, judge_model, regex_pattern, temperature=0.8, max_tokens=300, pairwise=True):\n",
        "        self.api_key = api_key\n",
        "        self.judge_model = judge_model\n",
        "        self.regex_pattern = re.compile(regex_pattern)\n",
        "        self.temperature = temperature\n",
        "        self.max_tokens = max_tokens\n",
        "        self.pairwise = pairwise\n",
        "        self.prompts = []\n",
        "        self.responses = []\n",
        "        self.references = []\n",
        "        self.confidences = []\n",
        "        self.accuracies = []\n",
        "\n",
        "    def get_mistral_answer(self, prompt, include_stopwords=True):\n",
        "        inputs = tokenizer_mistral.encode_plus(\n",
        "            prompt, return_tensors='pt', max_length=1024, truncation=True, padding='max_length'\n",
        "        ).to(mistral_model.device)\n",
        "\n",
        "        outputs = mistral_model.generate(\n",
        "            inputs['input_ids'], attention_mask=inputs['attention_mask'],\n",
        "            max_new_tokens=300, num_return_sequences=1, temperature=0.8,\n",
        "            do_sample=True, output_scores=True, return_dict_in_generate=True\n",
        "        )\n",
        "\n",
        "        response_ids = outputs.sequences[0]\n",
        "        response_text = tokenizer_mistral.decode(response_ids, skip_special_tokens=True)\n",
        "\n",
        "        logits = outputs.scores  # Logits of the generated tokens\n",
        "        softmax_probs = torch.softmax(torch.stack(logits), dim=-1)\n",
        "\n",
        "        tokens = tokenizer_mistral.convert_ids_to_tokens(response_ids)\n",
        "        if include_stopwords:\n",
        "            token_confidences = [prob.max().item() for prob in softmax_probs]\n",
        "        else:\n",
        "            token_confidences = [prob.max().item() for prob, token in zip(softmax_probs, tokens) if token.lower() not in stop_words]\n",
        "\n",
        "        mean_confidence = np.mean(token_confidences)\n",
        "\n",
        "        return response_text, mean_confidence\n",
        "\n",
        "    def judge_answer(self, response, prompt):\n",
        "        chat_completion = client.chat.completions.create(\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": f\"\"\"\n",
        "                        Review the user’s question and the corresponding response using the binary scoring system described below.\n",
        "                        - 0 points: The response is incorrect or does not address the user’s question.\n",
        "                        - 1 point: The response is correct and addresses the user’s question.\n",
        "\n",
        "                        User: {prompt}\n",
        "                        Response: {response}\n",
        "                        \"\"\"\n",
        "                }\n",
        "            ],\n",
        "            model=\"llama3-70b-8192\",\n",
        "        )\n",
        "\n",
        "        llama3_response = chat_completion.choices[0].message.content.strip()\n",
        "        return llama3_response\n",
        "\n",
        "    def parse_evaluation(self, evaluation):\n",
        "        if \"1 point\" in evaluation:\n",
        "            return 1\n",
        "        return 0\n",
        "\n",
        "    def generate_reference_text(self, prompt):\n",
        "        inputs = tokenizer_mistral.encode_plus(\n",
        "            prompt, return_tensors='pt', max_length=1024, truncation=True, padding='max_length'\n",
        "        ).to(mistral_model.device)\n",
        "\n",
        "        outputs = mistral_model.generate(\n",
        "            inputs['input_ids'], attention_mask=inputs['attention_mask'],\n",
        "            max_new_tokens=300, num_return_sequences=1, temperature=0.8, do_sample=True\n",
        "        )\n",
        "\n",
        "        reference_text = tokenizer_mistral.decode(outputs[0], skip_special_tokens=True)\n",
        "        return reference_text\n",
        "\n",
        "    def calculate_bertscore(self, references, candidates):\n",
        "        P, R, F1 = score(candidates, references, lang=\"en\", model_type=\"bert-base-uncased\")\n",
        "        return P.mean().item(), R.mean().item(), F1.mean().item()\n",
        "\n",
        "    def evaluate(self, prompts):\n",
        "        self.prompts = prompts  # Ensure prompts are stored\n",
        "        for prompt in prompts:\n",
        "            response, confidence = self.get_mistral_answer(prompt)\n",
        "            self.responses.append(response)\n",
        "            self.confidences.append(confidence)\n",
        "            reference_text = self.generate_reference_text(prompt)\n",
        "            self.references.append(reference_text)\n",
        "            judgement = self.judge_answer(response, prompt)\n",
        "            accuracy = self.parse_evaluation(judgement)\n",
        "            self.accuracies.append(accuracy)\n",
        "\n",
        "        precision, recall, f1 = self.calculate_bertscore(self.references, self.responses)\n",
        "        print(f\"BERTScore - Precision: {precision}, Recall: {recall}, F1: {f1}\")\n",
        "\n",
        "    def calculate_ece(self):\n",
        "        # Ensure all lists have the same length\n",
        "        if len(self.prompts) == len(self.responses) == len(self.confidences) == len(self.accuracies):\n",
        "            data = pd.DataFrame({\n",
        "                'prompt': self.prompts,\n",
        "                'response': self.responses,\n",
        "                'confidence': self.confidences,\n",
        "                'rating': self.accuracies\n",
        "            })\n",
        "        else:\n",
        "            raise ValueError(\"All arrays must be of the same length\")\n",
        "\n",
        "        # Normalize confidence scores\n",
        "        data['confidence_normalized'] = data['confidence'] / data['confidence'].max()\n",
        "\n",
        "        # Bin the normalized confidence scores\n",
        "        bins = np.linspace(0, 1, 11)\n",
        "        data['bin'] = pd.cut(data['confidence_normalized'], bins=bins, labels=False, include_lowest=True)\n",
        "\n",
        "        # Calculate accuracy for each bin\n",
        "        bin_accuracies = data.groupby('bin')['rating'].mean()\n",
        "        bin_proportions = data['bin'].value_counts(normalize=True)\n",
        "\n",
        "        # Drop bins with NaN values\n",
        "        valid_bins = bin_accuracies.dropna().index\n",
        "        bin_accuracies = bin_accuracies[valid_bins]\n",
        "        bin_proportions = bin_proportions[valid_bins]\n",
        "        bin_confidences = (bins[:-1] + bins[1:]) / 2\n",
        "        bin_confidences = bin_confidences[valid_bins]\n",
        "\n",
        "        # Ensure lengths match\n",
        "        bin_confidences = bin_confidences[:len(bin_accuracies)]\n",
        "\n",
        "        # Compute ECE\n",
        "        ece = np.sum(np.abs(bin_accuracies - bin_confidences) * bin_proportions)\n",
        "        print(f\"Expected Calibration Error (ECE): {ece}\")\n",
        "\n",
        "        return data, bins, bin_accuracies\n",
        "\n",
        "    def plot_reliability_diagram(self, bins, bin_accuracies):\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot((bins[:-1] + bins[1:]) / 2, bin_accuracies, marker='o', label='Accuracy per bin')\n",
        "        plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfect calibration')\n",
        "        plt.xlabel('Confidence')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title('Reliability Diagram')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-05T09:38:12.363622Z",
          "iopub.execute_input": "2024-06-05T09:38:12.364018Z",
          "iopub.status.idle": "2024-06-05T09:38:12.391914Z",
          "shell.execute_reply.started": "2024-06-05T09:38:12.363988Z",
          "shell.execute_reply": "2024-06-05T09:38:12.391081Z"
        },
        "trusted": true,
        "id": "K2rn2Q_r-WzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = EvaluationPipeline(api_key=\"Your_api_key\", judge_model=\"llama3-70b-8192\", regex_pattern=r\"(correct|incorrect)\")\n",
        "prompts = [\"What is nuclear fusion?\", \"Tell me about the current AI situation in the world?\", \"How does a combustion engine work?\"]\n",
        "pipeline.evaluate(prompts)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-05T09:38:13.025298Z",
          "iopub.execute_input": "2024-06-05T09:38:13.025882Z",
          "iopub.status.idle": "2024-06-05T09:40:08.802455Z",
          "shell.execute_reply.started": "2024-06-05T09:38:13.025852Z",
          "shell.execute_reply": "2024-06-05T09:40:08.801451Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "4a215bc76f664495b445209290af45c4",
            "948c2410474e47c5bc7f1ef6fe11cf73",
            "735945e2f09f49eb8cd9d79aa6f4e619",
            "98b40942285743e39e9b3f246c6a9263",
            "0accba5fde9b43bb988a8b83d6b1f13e"
          ]
        },
        "id": "JQuY96wp-WzZ",
        "outputId": "bb4a8e77-fdc4-4467-bee6-82fdc0c83852"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a215bc76f664495b445209290af45c4"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "948c2410474e47c5bc7f1ef6fe11cf73"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "735945e2f09f49eb8cd9d79aa6f4e619"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98b40942285743e39e9b3f246c6a9263"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0accba5fde9b43bb988a8b83d6b1f13e"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "BERTScore - Precision: 0.6630645990371704, Recall: 0.6872342228889465, F1: 0.6748167872428894\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data, bins, bin_accuracies = pipeline.calculate_ece()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-05T09:58:26.595910Z",
          "iopub.execute_input": "2024-06-05T09:58:26.596665Z",
          "iopub.status.idle": "2024-06-05T09:58:26.607206Z",
          "shell.execute_reply.started": "2024-06-05T09:58:26.596631Z",
          "shell.execute_reply": "2024-06-05T09:58:26.606213Z"
        },
        "trusted": true,
        "id": "jlRaxrm9-WzZ",
        "outputId": "87df82b2-8e46-4002-979c-1fc7d857b000"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Expected Calibration Error (ECE): 0.050000000000000044\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_examples = \"\"\"\n",
        "Q: What is nuclear fusion?\n",
        "A: Nuclear fusion is a reaction in which two atomic nuclei combine to form a heavier nucleus, releasing energy in the process.\n",
        "\n",
        "Q: How does a combustion engine work?\n",
        "A: A combustion engine works by burning fuel in a combustion chamber to produce mechanical energy that drives the engine.\n",
        "\"\"\"\n",
        "\n",
        "def get_mistral_answer_few_shot(prompt):\n",
        "    few_shot_prompt = few_shot_examples + f\"\\nQ: {prompt}\\nA:\"\n",
        "    response, confidence = get_mistral_answer(few_shot_prompt)\n",
        "    return response, confidence\n",
        "\n",
        "# Example usage:\n",
        "few_shot_response, few_shot_confidence = get_mistral_answer_few_shot(\"Tell me about the current AI situation in the world.\")\n",
        "print(f\"Few-shot response: {few_shot_response}\")\n",
        "print(f\"Few-shot confidence: {few_shot_confidence}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-05T09:40:27.232603Z",
          "iopub.execute_input": "2024-06-05T09:40:27.233246Z",
          "iopub.status.idle": "2024-06-05T09:40:27.237806Z",
          "shell.execute_reply.started": "2024-06-05T09:40:27.233215Z",
          "shell.execute_reply": "2024-06-05T09:40:27.236833Z"
        },
        "trusted": true,
        "id": "n6kh__mn-WzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bGELR8Iu-Wza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Class pipeline for mmlu dataset"
      ],
      "metadata": {
        "id": "h8L1gca0-Wza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Tokenizer:\n",
        "    def __init__(self, model_name):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "    def encode(self, text, max_length=1024):\n",
        "        return self.tokenizer.encode_plus(text, return_tensors='pt', max_length=max_length, truncation=True)\n",
        "\n",
        "    def decode(self, tokens):\n",
        "        return self.tokenizer.decode(tokens, skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "5GuOOofjB5Df"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
        "tokenizer = Tokenizer(model_name)\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "mistral_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    quantization_config=bnb_config,\n",
        "    low_cpu_mem_usage=True,\n",
        "    device_map=\"auto\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "47523e87365743d8b23899634cc66d8d",
            "7b4f185f923a4fa2885b3fad46b39b54",
            "ea68a14b2dc249adbd954233d532d795",
            "811e32513c21430a98e887ec83c3ef31",
            "bbfeaa0bc2014811bfe3cef60c6c8807",
            "80c5f20efdea49d9b56441308d9e245c",
            "57ddcab09fa240da993ed9c37388f7b7",
            "9c508f09eaf24518b402797a61f4530a",
            "fa9670561ec847cf8e2745616113eb5e",
            "c0c55c6884ad4e29b5febba2ab385188",
            "dd5d17e68db34d478e0d68cb75ab6ed0"
          ]
        },
        "id": "wKQduNTTB6y2",
        "outputId": "c08d71a9-0bd0-4f7a-c0a6-80648a774839"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47523e87365743d8b23899634cc66d8d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EvaluationPipeline:\n",
        "    def __init__(self, api_key, judge_model, temperature=0.8, max_tokens=300, pairwise=True):\n",
        "        self.api_key = api_key\n",
        "        self.judge_model = judge_model\n",
        "        self.temperature = temperature\n",
        "        self.max_tokens = max_tokens\n",
        "        self.pairwise = pairwise\n",
        "\n",
        "        self.categories = {\n",
        "            \"abstract_algebra\": [\"math\"],\n",
        "            \"anatomy\": [\"health\"],\n",
        "            \"astronomy\": [\"physics\"],\n",
        "            \"business_ethics\": [\"business\"],\n",
        "            \"clinical_knowledge\": [\"health\"],\n",
        "            \"college_biology\": [\"biology\"],\n",
        "            \"college_chemistry\": [\"chemistry\"],\n",
        "            \"college_computer_science\": [\"computer science\"],\n",
        "            \"college_mathematics\": [\"math\"],\n",
        "            \"college_medicine\": [\"health\"],\n",
        "            \"college_physics\": [\"physics\"],\n",
        "            \"computer_security\": [\"computer science\"],\n",
        "            \"conceptual_physics\": [\"physics\"],\n",
        "            \"econometrics\": [\"economics\"],\n",
        "            \"electrical_engineering\": [\"engineering\"],\n",
        "            \"elementary_mathematics\": [\"math\"],\n",
        "            \"formal_logic\": [\"philosophy\"],\n",
        "            \"global_facts\": [\"other\"],\n",
        "            \"high_school_biology\": [\"biology\"],\n",
        "            \"high_school_chemistry\": [\"chemistry\"],\n",
        "            \"high_school_computer_science\": [\"computer science\"],\n",
        "            \"high_school_european_history\": [\"history\"],\n",
        "            \"high_school_geography\": [\"geography\"],\n",
        "            \"high_school_government_and_politics\": [\"politics\"],\n",
        "            \"high_school_macroeconomics\": [\"economics\"],\n",
        "            \"high_school_mathematics\": [\"math\"],\n",
        "            \"high_school_microeconomics\": [\"economics\"],\n",
        "            \"high_school_physics\": [\"physics\"],\n",
        "            \"high_school_psychology\": [\"psychology\"],\n",
        "            \"high_school_statistics\": [\"math\"],\n",
        "            \"high_school_us_history\": [\"history\"],\n",
        "            \"high_school_world_history\": [\"history\"],\n",
        "            \"human_aging\": [\"health\"],\n",
        "            \"human_sexuality\": [\"culture\"],\n",
        "            \"international_law\": [\"law\"],\n",
        "            \"jurisprudence\": [\"law\"],\n",
        "            \"logical_fallacies\": [\"philosophy\"],\n",
        "            \"machine_learning\": [\"computer science\"],\n",
        "            \"management\": [\"business\"],\n",
        "            \"marketing\": [\"business\"],\n",
        "            \"medical_genetics\": [\"health\"],\n",
        "            \"miscellaneous\": [\"other\"],\n",
        "            \"moral_disputes\": [\"philosophy\"],\n",
        "            \"moral_scenarios\": [\"philosophy\"],\n",
        "            \"nutrition\": [\"health\"],\n",
        "            \"philosophy\": [\"philosophy\"],\n",
        "            \"prehistory\": [\"history\"],\n",
        "            \"professional_accounting\": [\"other\"],\n",
        "            \"professional_law\": [\"law\"],\n",
        "            \"professional_medicine\": [\"health\"],\n",
        "            \"professional_psychology\": [\"psychology\"],\n",
        "            \"public_relations\": [\"politics\"],\n",
        "            \"security_studies\": [\"politics\"],\n",
        "            \"sociology\": [\"culture\"],\n",
        "            \"us_foreign_policy\": [\"politics\"],\n",
        "            \"virology\": [\"health\"],\n",
        "            \"world_religions\": [\"philosophy\"],\n",
        "        }\n",
        "\n",
        "\n",
        "    def get_mistral_answer(self, prompt, tokenizer, mistral_model):\n",
        "        \"\"\"Generates an answer from the Mistral-7B model.\"\"\"\n",
        "        inputs = tokenizer.encode(prompt).to(mistral_model.device)\n",
        "        outputs = mistral_model.generate(inputs['input_ids'], max_length=300, num_return_sequences=1, temperature=0.8, output_scores=True, return_dict_in_generate=True)\n",
        "        mistral7b_response = tokenizer.decode(outputs.sequences[0])\n",
        "\n",
        "        # Get the confidence score\n",
        "        logits = torch.stack(outputs.scores, dim=1)\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "        token_ids = outputs.sequences[:, inputs['input_ids'].shape[1]:]\n",
        "        confidences = probs.gather(2, token_ids.unsqueeze(-1)).squeeze(-1).mean(dim=1).detach().cpu().numpy()\n",
        "\n",
        "        avg_confidence = confidences[0]\n",
        "        return mistral7b_response, avg_confidence\n",
        "\n",
        "    def judge_answer(self, response, prompt):\n",
        "        chat_completion = client.chat.completions.create(\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": f\"\"\"\n",
        "                        Review the user’s question and the corresponding response using the binary scoring system described below.\n",
        "                        - 0 points: The response is incorrect or does not address the user’s question.\n",
        "                        - 1 point: The response is correct and addresses the user’s question.\n",
        "\n",
        "                        User: {prompt}\n",
        "                        Response: {response}\n",
        "                        \"\"\"\n",
        "                }\n",
        "            ],\n",
        "            model=self.judge_model,\n",
        "        )\n",
        "\n",
        "        llama3_response = chat_completion.choices[0].message.content.strip()\n",
        "        return llama3_response\n",
        "\n",
        "    def parse_evaluation(self, evaluation):\n",
        "        if \"1 point\" in evaluation:\n",
        "            return 1\n",
        "        return 0\n",
        "\n",
        "    def generate_reference_text(self, prompt, tokenizer, mistral_model):\n",
        "        inputs = tokenizer.encode(prompt).to(mistral_model.device)\n",
        "\n",
        "        outputs = mistral_model.generate(\n",
        "            inputs['input_ids'], attention_mask=inputs['attention_mask'],\n",
        "            max_new_tokens=300, num_return_sequences=1, temperature=0.8, do_sample=True\n",
        "        )\n",
        "\n",
        "        reference_text = tokenizer.decode(outputs[0])\n",
        "        return reference_text\n",
        "\n",
        "    def calculate_bertscore(self, references, candidates):\n",
        "        P, R, F1 = score(candidates, references, lang=\"en\", model_type=\"bert-base-uncased\")\n",
        "        return P.mean().item(), R.mean().item(), F1.mean().item()\n",
        "\n",
        "    def evaluate_from_csv(self, csv_file_path):\n",
        "        # Clear data before processing each file\n",
        "        self.prompts = []\n",
        "        self.responses = []\n",
        "        self.references = []\n",
        "        self.confidences = []\n",
        "        self.accuracies = []\n",
        "\n",
        "        df = pd.read_csv(csv_file_path)\n",
        "        self.prompts = df.iloc[:, 0].tolist()  # Take only the first column (questions)\n",
        "\n",
        "        for prompt in self.prompts:\n",
        "            response, confidence = self.get_mistral_answer(prompt, tokenizer, mistral_model)\n",
        "            self.responses.append(response)\n",
        "            self.confidences.append(confidence)\n",
        "            reference_text = self.generate_reference_text(prompt, tokenizer, mistral_model)\n",
        "            self.references.append(reference_text)\n",
        "            judgement = self.judge_answer(response, prompt)\n",
        "            accuracy = self.parse_evaluation(judgement)\n",
        "            self.accuracies.append(accuracy)\n",
        "\n",
        "        precision, recall, f1 = self.calculate_bertscore(self.references, self.responses)\n",
        "        print(f\"BERTScore - Precision: {precision}, Recall: {recall}, F1: {f1}\")\n",
        "\n",
        "        data, bins, bin_accuracies = self.calculate_ece()\n",
        "        data.to_csv(\"results.csv\", index=False)  # Save results to CSV\n",
        "        return data, bins, bin_accuracies\n",
        "\n",
        "    def evaluate_folder(self, folder_path):\n",
        "        results = {}  # Store ECE values for each class\n",
        "        category_results = {category: [] for category in set(cat for sublist in self.categories.values() for cat in sublist)}\n",
        "\n",
        "        for filename in os.listdir(folder_path):\n",
        "            if filename.endswith(\".csv\"):\n",
        "                filepath = os.path.join(folder_path, filename)\n",
        "                class_name = filename[:-8]  # Extract class name from filename without \"_dev.csv\"\n",
        "\n",
        "                category_name = None\n",
        "                for key, value in self.categories.items():\n",
        "                    if key == class_name:\n",
        "                        category_name = value[0]\n",
        "                        break\n",
        "\n",
        "                if category_name:\n",
        "                    print(f\"Evaluating {class_name} in category {category_name}...\")\n",
        "                    data, bins, bin_accuracies = self.evaluate_from_csv(filepath)\n",
        "\n",
        "                    # Align shapes and calculate ECE\n",
        "                    bin_confidences = (bins[:-1] + bins[1:]) / 2  # Confidences for each bin\n",
        "                    valid_bins = bin_accuracies.dropna().index  # Bins with data\n",
        "                    bin_accuracies = bin_accuracies[valid_bins]\n",
        "                    bin_proportions = data['bin'].value_counts(normalize=True)[valid_bins]  # Get proportions for valid bins\n",
        "                    bin_confidences = bin_confidences[valid_bins]  # Select confidences for valid bins\n",
        "\n",
        "                    ece = np.sum(np.abs(bin_accuracies - bin_confidences) * bin_proportions)\n",
        "                    category_results[category_name].append(ece)\n",
        "                    print(f\"{class_name} ECE: {ece}\")\n",
        "\n",
        "        # Calculate average ECE for each category and save to CSV\n",
        "        average_ece_results = {category: np.mean(ece_list) for category, ece_list in category_results.items()}\n",
        "        average_ece_df = pd.DataFrame({'Category': average_ece_results.keys(), 'Average ECE': average_ece_results.values()})\n",
        "        average_ece_df.to_csv(\"category_results.csv\", index=False)\n",
        "\n",
        "    def calculate_ece(self):\n",
        "        # Ensure all lists have the same length\n",
        "        if len(self.prompts) == len(self.responses) == len(self.confidences) == len(self.accuracies):\n",
        "            data = pd.DataFrame({\n",
        "                'prompt': self.prompts,\n",
        "                'response': self.responses,\n",
        "                'confidence': self.confidences,\n",
        "                'rating': self.accuracies\n",
        "            })\n",
        "        else:\n",
        "            raise ValueError(\"All arrays must be of the same length\")\n",
        "\n",
        "        # Normalize confidence scores\n",
        "        data['confidence_normalized'] = data['confidence'] / data['confidence'].max()\n",
        "\n",
        "        # Bin the normalized confidence scores\n",
        "        bins = np.linspace(0, 1, 11)\n",
        "        data['bin'] = pd.cut(data['confidence_normalized'], bins=bins, labels=False, include_lowest=True)\n",
        "\n",
        "        # Calculate accuracy for each bin\n",
        "        bin_accuracies = data.groupby('bin')['rating'].mean()\n",
        "        bin_proportions = data['bin'].value_counts(normalize=True)\n",
        "\n",
        "        # Drop bins with NaN values\n",
        "        valid_bins = bin_accuracies.dropna().index\n",
        "        bin_accuracies = bin_accuracies[valid_bins]\n",
        "        bin_proportions = bin_proportions[valid_bins]\n",
        "        bin_confidences = (bins[:-1] + bins[1:]) / 2\n",
        "        bin_confidences = bin_confidences[valid_bins]\n",
        "\n",
        "        # Ensure lengths match\n",
        "        bin_confidences = bin_confidences[:len(bin_accuracies)]\n",
        "\n",
        "        # Compute ECE\n",
        "        ece = np.sum(np.abs(bin_accuracies - bin_confidences) * bin_proportions)\n",
        "        print(f\"Expected Calibration Error (ECE): {ece}\")\n",
        "\n",
        "        return data, bins, bin_accuracies\n"
      ],
      "metadata": {
        "id": "Me7XxFDLMEEO"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = EvaluationPipeline(api_key=\"Your_api_key\", judge_model=\"llama3-70b-8192\")\n",
        "pipeline.evaluate_folder(\"/content/drive/MyDrive/fellowshipai/Confidence_Calibration/demo_data/dev_test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcsDDi7TMEJd",
        "outputId": "4474d460-4a13-4c3d-d36c-5aaea3c72552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating virology in category health...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p_r_8jy-Hfcp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}