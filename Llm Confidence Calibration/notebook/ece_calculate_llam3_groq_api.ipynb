{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-29T04:59:25.708723Z","iopub.status.busy":"2024-05-29T04:59:25.708335Z","iopub.status.idle":"2024-05-29T05:00:00.805224Z","shell.execute_reply":"2024-05-29T05:00:00.804034Z","shell.execute_reply.started":"2024-05-29T04:59:25.708690Z"},"trusted":true},"outputs":[],"source":["!pip install transformers bitsandbytes sentencepiece accelerate guidance --upgrade -qq"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T05:00:00.807920Z","iopub.status.busy":"2024-05-29T05:00:00.807492Z","iopub.status.idle":"2024-05-29T05:00:01.099511Z","shell.execute_reply":"2024-05-29T05:00:01.098630Z","shell.execute_reply.started":"2024-05-29T05:00:00.807882Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1f698b1a024b4d25a76c4bb865adb22f","version_major":2,"version_minor":0},"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"]},"metadata":{},"output_type":"display_data"}],"source":["from huggingface_hub import notebook_login\n","notebook_login()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T05:00:12.980566Z","iopub.status.busy":"2024-05-29T05:00:12.979786Z","iopub.status.idle":"2024-05-29T05:01:06.025179Z","shell.execute_reply":"2024-05-29T05:01:06.023776Z","shell.execute_reply.started":"2024-05-29T05:00:12.980537Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.30.1)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\n","Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.23.2)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"]}],"source":["!pip install --upgrade transformers -qq\n","!pip install accelerate\n","!pip install -q -U google-generativeai"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T05:30:20.745450Z","iopub.status.busy":"2024-05-29T05:30:20.745081Z","iopub.status.idle":"2024-05-29T05:30:22.347107Z","shell.execute_reply":"2024-05-29T05:30:22.346019Z","shell.execute_reply.started":"2024-05-29T05:30:20.745424Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["import torch\n","import numpy as np\n","from sklearn.isotonic import IsotonicRegression\n","from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification, pipeline\n","from transformers import BitsAndBytesConfig\n","import torch.nn.functional as F\n","from transformers import pipeline\n","import pandas as pd\n","import pathlib\n","import textwrap\n","import google.generativeai as genai\n","from IPython.display import display\n","from IPython.display import Markdown\n","import google.generativeai as genai\n","import os\n","import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T05:01:24.381150Z","iopub.status.busy":"2024-05-29T05:01:24.380651Z","iopub.status.idle":"2024-05-29T05:03:41.902014Z","shell.execute_reply":"2024-05-29T05:03:41.901101Z","shell.execute_reply.started":"2024-05-29T05:01:24.381126Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3d910d0812b341ad8b67ca9677fe1873","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9e2f607437b64d5d8d439ca63e35b90f","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"64d74264c0ed4cccb9df6f8cc27eb7b8","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2189e910bc724d818d93ba7ba4dafa46","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a9a30207016a4894a7a26cbeea16b3f2","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6577a89aa1e84fe696883b3e2f15f221","version_major":2,"version_minor":0},"text/plain":["model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7b6fbc2e690b48978b4dd9f20c8ba9ee","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8b4477e4ae1c49ddb8d41526dd810bde","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["model_name = 'mistralai/Mistral-7B-Instruct-v0.2'\n","\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.float16\n",")\n","\n","mistral_model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    torch_dtype=torch.float16,\n","    quantization_config=bnb_config,\n","    low_cpu_mem_usage=True,\n","    device_map=\"auto\",\n",")"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T05:34:43.942824Z","iopub.status.busy":"2024-05-29T05:34:43.942089Z","iopub.status.idle":"2024-05-29T05:38:53.657503Z","shell.execute_reply":"2024-05-29T05:38:53.656626Z","shell.execute_reply.started":"2024-05-29T05:34:43.942793Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"40b01c8d4c4741b9bd76184884d999d0","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9ed74fd96c6a4c749080f6c883e5debd","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/33.4k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a8913e85630f4824b9283d9af955a4d9","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ad0a806793949e8a50ccf0a7c61d60f","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00003.safetensors:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f0a671fd233443e2bc51cc966c53813b","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00003.safetensors:   0%|          | 0.00/9.90G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2eb6856763fc4923a78233984e10eec0","version_major":2,"version_minor":0},"text/plain":["model-00003-of-00003.safetensors:   0%|          | 0.00/6.18G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f9c6c94d809945a6ac2f1da5326ff746","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d47cb8e31b704e3fb9a8dc28bb181432","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["model_name2 = 'stabilityai/StableBeluga-13B'\n","\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.float16\n",")\n","\n","beluga_model = AutoModelForCausalLM.from_pretrained(\n","    model_name2,\n","    torch_dtype=torch.float16,\n","    quantization_config=bnb_config,\n","    low_cpu_mem_usage=True,\n","    device_map=\"auto\",\n",")"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T05:30:26.531726Z","iopub.status.busy":"2024-05-29T05:30:26.530765Z","iopub.status.idle":"2024-05-29T05:30:26.538815Z","shell.execute_reply":"2024-05-29T05:30:26.537498Z","shell.execute_reply.started":"2024-05-29T05:30:26.531681Z"},"trusted":true},"outputs":[],"source":["def preprocess_text(text):\n","    tokens = word_tokenize(text.lower())\n","    stop_words = set(stopwords.words('english'))\n","    filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n","    return ' '.join(filtered_tokens)"]},{"cell_type":"markdown","metadata":{},"source":["## Groq API"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["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"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T05:11:35.902025Z","iopub.status.busy":"2024-05-29T05:11:35.901623Z","iopub.status.idle":"2024-05-29T05:12:38.851292Z","shell.execute_reply":"2024-05-29T05:12:38.850138Z","shell.execute_reply.started":"2024-05-29T05:11:35.901996Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: groq in /opt/conda/lib/python3.10/site-packages (0.8.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from groq) (4.2.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from groq) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from groq) (0.27.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from groq) (2.5.3)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from groq) (1.3.0)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from groq) (4.9.0)\n","Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq) (3.6)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq) (1.2.0)\n","Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq) (2024.2.2)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq) (1.0.5)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq) (2.14.6)\n","Requirement already satisfied: langchain-groq in /opt/conda/lib/python3.10/site-packages (0.1.4)\n","Requirement already satisfied: groq<1,>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from langchain-groq) (0.8.0)\n","Requirement already satisfied: langchain-core<0.3,>=0.1.45 in /opt/conda/lib/python3.10/site-packages (from langchain-groq) (0.2.1)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from groq<1,>=0.4.1->langchain-groq) (4.2.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from groq<1,>=0.4.1->langchain-groq) (0.27.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from groq<1,>=0.4.1->langchain-groq) (2.5.3)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.0)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from groq<1,>=0.4.1->langchain-groq) (4.9.0)\n","Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.45->langchain-groq) (6.0.1)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.45->langchain-groq) (1.33)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.45->langchain-groq) (0.1.63)\n","Requirement already satisfied: packaging<24.0,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.45->langchain-groq) (23.2)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.45->langchain-groq) (8.2.3)\n","Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (3.6)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (1.2.0)\n","Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (2024.2.2)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.5)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.45->langchain-groq) (2.4)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.45->langchain-groq) (3.10.3)\n","Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.45->langchain-groq) (2.31.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (2.14.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.45->langchain-groq) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.45->langchain-groq) (1.26.18)\n","Collecting yfinance\n","  Downloading yfinance-0.2.40-py2.py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: pandas>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from yfinance) (2.1.4)\n","Requirement already satisfied: numpy>=1.16.5 in /opt/conda/lib/python3.10/site-packages (from yfinance) (1.26.4)\n","Requirement already satisfied: requests>=2.31 in /opt/conda/lib/python3.10/site-packages (from yfinance) (2.31.0)\n","Collecting multitasking>=0.0.7 (from yfinance)\n","  Downloading multitasking-0.0.11-py3-none-any.whl.metadata (5.5 kB)\n","Requirement already satisfied: lxml>=4.9.1 in /opt/conda/lib/python3.10/site-packages (from yfinance) (5.2.1)\n","Requirement already satisfied: platformdirs>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from yfinance) (4.2.0)\n","Requirement already satisfied: pytz>=2022.5 in /opt/conda/lib/python3.10/site-packages (from yfinance) (2023.3.post1)\n","Requirement already satisfied: frozendict>=2.3.4 in /opt/conda/lib/python3.10/site-packages (from yfinance) (2.4.2)\n","Collecting peewee>=3.16.2 (from yfinance)\n","  Downloading peewee-3.17.5.tar.gz (3.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n","\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n","\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.11.1 in /opt/conda/lib/python3.10/site-packages (from yfinance) (4.12.2)\n","Requirement already satisfied: html5lib>=1.1 in /opt/conda/lib/python3.10/site-packages (from yfinance) (1.1)\n","Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n","Requirement already satisfied: six>=1.9 in /opt/conda/lib/python3.10/site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n","Requirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance) (2023.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31->yfinance) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31->yfinance) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31->yfinance) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31->yfinance) (2024.2.2)\n","Downloading yfinance-0.2.40-py2.py3-none-any.whl (73 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n","Building wheels for collected packages: peewee\n","  Building wheel for peewee (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for peewee: filename=peewee-3.17.5-cp310-cp310-linux_x86_64.whl size=293378 sha256=a75c2eb57bb23e3d3682bd7da0d8a71f9104f6fe48c9bd91359d39236357575c\n","  Stored in directory: /root/.cache/pip/wheels/06/80/9b/98db0d58349a2f5c09f8406789ade4270762f97b7d26f2fa22\n","Successfully built peewee\n","Installing collected packages: peewee, multitasking, yfinance\n","Successfully installed multitasking-0.0.11 peewee-3.17.5 yfinance-0.2.40\n"]}],"source":["!pip install groq"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T05:15:31.759789Z","iopub.status.busy":"2024-05-29T05:15:31.758818Z","iopub.status.idle":"2024-05-29T05:15:31.764142Z","shell.execute_reply":"2024-05-29T05:15:31.763149Z","shell.execute_reply.started":"2024-05-29T05:15:31.759754Z"},"trusted":true},"outputs":[],"source":["import os\n","os.environ[\"GROQ_API_KEY\"] = \"Your_Api_key\""]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T05:28:19.186487Z","iopub.status.busy":"2024-05-29T05:28:19.185472Z","iopub.status.idle":"2024-05-29T05:28:21.487219Z","shell.execute_reply":"2024-05-29T05:28:21.486149Z","shell.execute_reply.started":"2024-05-29T05:28:19.186452Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["What a profound and complex set of questions!\n","\n","**What is the meaning of life?**\n","\n","The meaning of life is a philosophical question that has been debated by scholars, theologians, and thinkers for centuries. There is no one definitive answer, as it can vary greatly depending on cultural, religious, and personal beliefs. Here are a few perspectives:\n","\n","* **Biological perspective**: From a biological standpoint, the meaning of life could be to survive, reproduce, and ensure the continuation of one's genes.\n","* **Religious perspective**: Many religions offer a sense of purpose and meaning, often linked to a higher power or spiritual realm. For example, Christianity proposes that the meaning of life is to love and serve God, while Buddhism emphasizes the attainment of enlightenment and the end of suffering.\n","* **Humanistic perspective**: From a humanistic viewpoint, the meaning of life might be to seek happiness, fulfillment, and personal growth, while also contributing positively to society.\n","* **Existentialist perspective**: Existentialism suggests that life has no inherent meaning, and it's up to each individual to create their own purpose and meaning.\n","\n","Ultimately, the meaning of life is a deeply personal and subjective question that each individual must answer for themselves.\n","\n","**How is modern AI affecting real life?**\n","\n","Artificial Intelligence (AI) is transforming many aspects of modern life, with both positive and negative consequences. Some examples:\n","\n","* **Automation and job displacement**: AI has automated many routine and repetitive tasks, increasing efficiency but also displacing some jobs.\n","* **Improved healthcare**: AI is being used in medical diagnosis, personalized medicine, and healthcare analytics, leading to better health outcomes.\n","* **Enhanced customer experiences**: AI-powered chatbots and virtual assistants are revolutionizing customer service and support.\n","* **Cybersecurity threats**: AI is being used to create more sophisticated cyber attacks, while also helping to develop more effective cybersecurity measures.\n","* **Social media and misinformation**: AI-powered algorithms can spread misinformation and disinformation, contributing to the erosion of trust in institutions and the distortion of public discourse.\n","\n","**What will be the AI outcomes in the future?**\n","\n","The future of AI is uncertain, and its outcomes will depend on how we choose to develop and use AI technologies. Here are a few possible scenarios:\n","\n","* **Utopian scenario**: AI could lead to unparalleled economic growth, improved healthcare, and enhanced quality of life for all humanity.\n","* **Dystopian scenario**: Uncontrolled AI could lead to widespread job displacement, increased inequality, and even an existential threat to humanity.\n","* **Hybrid scenario**: AI could become an integral part of our lives, augmenting human capabilities while also creating new challenges and opportunities that we must navigate carefully.\n","\n","To ensure a positive future for AI, it's essential to:\n","\n","1. **Develop AI with ethical considerations**: Ensure that AI systems are designed with transparency, accountability, and fairness in mind.\n","2. **Invest in AI education and literacy**: Educate people about AI, its capabilities, and its limitations, to facilitate informed decision-making.\n","3. **Foster international cooperation**: Encourage global collaboration to establish ethical guidelines and regulations for AI development and deployment.\n","4. **Prioritize human well-being and safety**: Ensure that AI systems are designed to prioritize human well-being and safety, while also mitigating potential risks.\n","\n","Ultimately, the future of AI will be shaped by our collective choices and actions. By being aware of the potential consequences and working together, we can create a future where AI benefits all of humanity.\n"]}],"source":["import os\n","\n","from groq import Groq\n","\n","client = Groq(api_key=\"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\")\n","\n","chat_completion = client.chat.completions.create(\n","    messages=[\n","        {\n","            \"role\": \"user\",\n","            \"content\": \"What is the meaning of life? How modern Ai is affeting the real life and what will be the Ai outcomes in future?\",\n","        }\n","        \n","    ],\n","    model=\"llama3-70b-8192\",\n",")\n","\n","print(chat_completion.choices[0].message.content)"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T05:30:31.683104Z","iopub.status.busy":"2024-05-29T05:30:31.682316Z","iopub.status.idle":"2024-05-29T05:30:31.720033Z","shell.execute_reply":"2024-05-29T05:30:31.719033Z","shell.execute_reply.started":"2024-05-29T05:30:31.683067Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'profound complex set questions meaning life meaning life philosophical question debated scholars theologians thinkers centuries one definitive answer vary greatly depending cultural religious personal beliefs perspectives biological standpoint meaning life could survive reproduce ensure continuation one genes many religions offer sense purpose meaning often linked higher power spiritual realm example christianity proposes meaning life love serve god buddhism emphasizes attainment enlightenment end suffering humanistic viewpoint meaning life might seek happiness fulfillment personal growth also contributing positively society existentialism suggests life inherent meaning individual create purpose meaning ultimately meaning life deeply personal subjective question individual must answer modern ai affecting real life artificial intelligence ai transforming many aspects modern life positive negative consequences examples job ai automated many routine repetitive tasks increasing efficiency also displacing jobs ai used medical diagnosis personalized medicine healthcare analytics leading better health outcomes customer chatbots virtual assistants revolutionizing customer service support ai used create sophisticated cyber attacks also helping develop effective cybersecurity measures media algorithms spread misinformation disinformation contributing erosion trust institutions distortion public discourse ai outcomes future future ai uncertain outcomes depend choose develop use ai technologies possible scenarios ai could lead unparalleled economic growth improved healthcare enhanced quality life humanity uncontrolled ai could lead widespread job displacement increased inequality even existential threat humanity ai could become integral part lives augmenting human capabilities also creating new challenges opportunities must navigate carefully ensure positive future ai essential 1 ai ethical ensure ai systems designed transparency accountability fairness mind 2 ai education educate people ai capabilities limitations facilitate informed 3 international encourage global collaboration establish ethical guidelines regulations ai development deployment 4 human ensure ai systems designed prioritize human safety also mitigating potential risks ultimately future ai shaped collective choices actions aware potential consequences working together create future ai benefits humanity'"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["groq_response = preprocess_text(chat_completion.choices[0].message.content)\n","groq_response"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T05:56:14.577809Z","iopub.status.busy":"2024-05-29T05:56:14.577421Z","iopub.status.idle":"2024-05-29T05:56:33.830120Z","shell.execute_reply":"2024-05-29T05:56:33.828858Z","shell.execute_reply.started":"2024-05-29T05:56:14.577780Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["Expected Calibration Error (ECE): 0.8769400119781494\n"]}],"source":["def get_mistral_answer(prompt):\n","    \"\"\"Generates an answer from the Mistral-7B model.\"\"\"\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","    inputs = tokenizer.encode(prompt, return_tensors='pt', max_length=1024, truncation=True).to(mistral_model.device)\n","    outputs = mistral_model.generate(inputs, max_length=300, num_return_sequences=1, temperature=0.8, output_scores=True, return_dict_in_generate=True)\n","    mistral7b_response = tokenizer.decode(outputs.sequences[0], skip_special_tokens=True)\n","\n","    # Get the confidence score\n","    logits = torch.stack(outputs.scores, dim=1)\n","    probs = F.softmax(logits, dim=-1)\n","\n","    token_ids = outputs.sequences[:, inputs.shape[1]:]\n","    confidences = probs.gather(2, token_ids.unsqueeze(-1)).squeeze(-1).mean(dim=1).detach().cpu().numpy()\n","\n","    avg_confidence = confidences[0]\n","    return mistral7b_response, avg_confidence\n","\n","def get_llama370B_judgement(response, prompt):\n","\n","    chat_completion = client.chat.completions.create(\n","        messages=[\n","            {\n","                \"role\": \"user\",\n","                \"content\": f\"\"\"\n","                        Review the user’s question and the corresponding response using the binary scoring system described below.\n","                        - 0 points: The response is incorrect or does not address the user’s question.\n","                        - 1 point: The response is correct and addresses the user’s question.\n","\n","                        User: {prompt}\n","                        Response: {response}\n","\n","                        \"\"\"\n","            }\n","\n","        ],\n","        model=\"llama3-70b-8192\",\n","    )\n","    \n","    llama3_response = preprocess_text(chat_completion.choices[0].message.content)\n","    return llama3_response\n","\n","def calculate_expected_calibration_error(mistral_confidences, gemini_judgements):\n","    \"\"\"Calculates the Expected Calibration Error (ECE).\"\"\"\n","    num_bins = 10 \n","    bin_edges = np.linspace(0.0, 1.0, num_bins + 1)\n","    \n","    ece = 0.0\n","    for i in range(num_bins):\n","        bin_lower = bin_edges[i]\n","        bin_upper = bin_edges[i + 1]\n","        bin_indices = (mistral_confidences >= bin_lower) & (mistral_confidences < bin_upper)\n","        bin_confidences = mistral_confidences[bin_indices]\n","        bin_judgements = gemini_judgements[bin_indices]\n","\n","        if len(bin_confidences) == 0:\n","            continue  # Skip empty bins\n","\n","        accuracy_in_bin = bin_judgements.mean()\n","        avg_confidence_in_bin = bin_confidences.mean()\n","        ece += np.abs(avg_confidence_in_bin - accuracy_in_bin) * (len(bin_confidences) / len(mistral_confidences))\n","\n","    return ece\n","\n","# Example usage\n","prompt = \"What is nuclear fusion? What are the advantages of it? What danger it make on environment?\"\n","mistral_response, mistral_confidence = get_mistral_answer(prompt)\n","mistral_preprocess_response = preprocess_text(mistral_response)\n","llama3_judgement = get_llama370B_judgement(mistral_preprocess_response, prompt)\n","\n","# Convert Gemini judgement to a binary label\n","llama3_label = 1 if llama3_judgement == \"correct\" else 0\n","\n","# Collect multiple examples (prompt-response pairs) to get a good ECE calculation\n","mistral_confidences = [mistral_confidence]\n","llama3_judgement = [llama3_label]\n","\n","mistral_confidences = np.array(mistral_confidences)\n","llama3_judgement = np.array(llama3_judgement)\n","\n","ece = calculate_expected_calibration_error(mistral_confidences, llama3_judgement)\n","print(f\"Expected Calibration Error (ECE): {ece}\")"]},{"cell_type":"markdown","metadata":{},"source":["## StableBeluga13B"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T05:56:33.835078Z","iopub.status.busy":"2024-05-29T05:56:33.834780Z","iopub.status.idle":"2024-05-29T05:56:53.056780Z","shell.execute_reply":"2024-05-29T05:56:53.055910Z","shell.execute_reply.started":"2024-05-29T05:56:33.835053Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["I'm afraid I have to give this response a score of 0 points. The response appears to be a jumbled collection of words and phrases that doesn't make any sense in the context of the user's question. It doesn't address the user's question about nuclear fusion, its advantages, or its environmental impact. The response seems to be a random sequence of words and doesn't provide any meaningful or coherent information.\n","Expected Calibration Error (ECE): 0.7297741770744324\n"]}],"source":["def get_mistral_answer(prompt):\n","    \"\"\"Generates an answer from the Mistral-7B model.\"\"\"\n","    tokenizer = AutoTokenizer.from_pretrained(model_name2)\n","    inputs = tokenizer.encode(prompt, return_tensors='pt', max_length=1024, truncation=True).to(mistral_model.device)\n","    outputs = mistral_model.generate(inputs, max_length=300, num_return_sequences=1, temperature=0.8, output_scores=True, return_dict_in_generate=True)\n","    mistral7b_response = tokenizer.decode(outputs.sequences[0], skip_special_tokens=True)\n","\n","    # Get the confidence score\n","    logits = torch.stack(outputs.scores, dim=1)\n","    probs = F.softmax(logits, dim=-1)\n","\n","    token_ids = outputs.sequences[:, inputs.shape[1]:]\n","    confidences = probs.gather(2, token_ids.unsqueeze(-1)).squeeze(-1).mean(dim=1).detach().cpu().numpy()\n","\n","    avg_confidence = confidences[0]\n","    return mistral7b_response, avg_confidence\n","\n","def get_llama370B_judgement(response, prompt):\n","    chat_completion = client.chat.completions.create(\n","        messages=[\n","            {\n","                \"role\": \"user\",\n","                \"content\": f\"\"\"\n","                        Review the user’s question and the corresponding response using the binary scoring system described below.\n","                        - 0 points: The response is incorrect or does not address the user’s question.\n","                        - 1 point: The response is correct and addresses the user’s question.\n","\n","                        User: {prompt}\n","                        Response: {response}\n","\n","                        \"\"\"\n","            }\n","\n","        ],\n","        model=\"llama3-70b-8192\",\n","    )\n","    \n","    print(chat_completion.choices[0].message.content)\n","    llama3_response = preprocess_text(chat_completion.choices[0].message.content)\n","    return llama3_response\n","\n","def calculate_expected_calibration_error(mistral_confidences, gemini_judgements):\n","    \"\"\"Calculates the Expected Calibration Error (ECE).\"\"\"\n","    num_bins = 10 \n","    bin_edges = np.linspace(0.0, 1.0, num_bins + 1)\n","    \n","    ece = 0.0\n","    for i in range(num_bins):\n","        bin_lower = bin_edges[i]\n","        bin_upper = bin_edges[i + 1]\n","        bin_indices = (mistral_confidences >= bin_lower) & (mistral_confidences < bin_upper)\n","        bin_confidences = mistral_confidences[bin_indices]\n","        bin_judgements = gemini_judgements[bin_indices]\n","\n","        if len(bin_confidences) == 0:\n","            continue  # Skip empty bins\n","\n","        accuracy_in_bin = bin_judgements.mean()\n","        avg_confidence_in_bin = bin_confidences.mean()\n","        ece += np.abs(avg_confidence_in_bin - accuracy_in_bin) * (len(bin_confidences) / len(mistral_confidences))\n","\n","    return ece\n","\n","# Example usage\n","prompt = \"What is nuclear fusion? What are the advantages of it? What danger it make on environment?\"\n","mistral_response, mistral_confidence = get_mistral_answer(prompt)\n","mistral_preprocess_response = preprocess_text(mistral_response)\n","llama3_judgement = get_llama370B_judgement(mistral_preprocess_response, prompt)\n","\n","# Convert Gemini judgement to a binary label\n","llama3_label = 1 if llama3_judgement == \"correct\" else 0\n","\n","mistral_confidences = [mistral_confidence]\n","llama3_judgement = [llama3_label]\n","\n","mistral_confidences = np.array(mistral_confidences)\n","llama3_judgement = np.array(llama3_judgement)\n","\n","ece = calculate_expected_calibration_error(mistral_confidences, llama3_judgement)\n","print(f\"Expected Calibration Error (ECE): {ece}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30698,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
